<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>Matt O'Brien (dot) Me - Matt O'Brien</title><link href="http://mattobrien.me/" rel="alternate"></link><link href="http://mattobrien.me/feeds/matt-obrien.atom.xml" rel="self"></link><id>http://mattobrien.me/</id><updated>2018-01-10T00:00:00-08:00</updated><entry><title>The Donut Defense in muay thai</title><link href="http://mattobrien.me/the-donut-defense-in-muay-thai.html" rel="alternate"></link><published>2018-01-10T00:00:00-08:00</published><updated>2018-01-10T00:00:00-08:00</updated><author><name>Matt O'Brien</name></author><id>tag:mattobrien.me,2018-01-10:/the-donut-defense-in-muay-thai.html</id><summary type="html">&lt;p&gt;Fosbury Flop and muay thai&lt;/p&gt;</summary><content type="html">&lt;h4&gt;This post originally appeared on XXX&lt;/h4&gt;
&lt;p&gt;I love sports because whatever works, works. If you can figure out a smarter way to do something, and you do it, your odds of winning go up. This isn't to say that we need to run around trying to change and revolutionize everything. It's more about looking closely at what already works and then shaving off tiny bits of wasted movement. This is usually how improvement happens.  In sport science, they frame this as the &lt;a href="https://en.wikipedia.org/wiki/Degrees_of_freedom_problem"&gt;degrees of freedom problem&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;One notorious example of someone getting better by shaving off wasted movement came from a guy in Oregon named &lt;a href="https://en.wikipedia.org/wiki/Dick_Fosbury"&gt;Dick Fosbury&lt;/a&gt;. Aside from having an awesome name, he also revolutionized the sport of pole vault. He figured out a technique that is now called the  Fosbury Flop. He ultimately ended up winning the gold medal at the Olympics and setting a new record simultaneously.  &lt;/p&gt;
&lt;p&gt;I'll explain the Fosbury Flop here. Then we'll steal the idea. We'll apply it to defending against body kicks in muay thai. And we'll call our new version the Donut Defense, because that sounds like a fitting tribute to the Fosbury Flop.&lt;/p&gt;
&lt;p&gt;First, read this next paragraph three times, because it sounds like gibberish at first:  &lt;/p&gt;
&lt;p&gt;The shocking truth behind the Fosbury Flop is that our friend Dick Fosbury actually figured out how to made his center of mass go &lt;em&gt;UNDER&lt;/em&gt; the bar at the exact same time as he was jumping &lt;em&gt;OVER&lt;/em&gt; the bar. &lt;/p&gt;
&lt;p&gt;This should make no sense right now to anyone reading this, assuming you don't already know about the Fosbury Flop. But I assure you, this is the kind of forehead slapping idea that makes perfect sense once it clicks. So bear with me and just look at these pretty pictures:  &lt;/p&gt;
&lt;h4&gt;Check out the black dot. That's the center of mass of a basketball, right?&lt;/h4&gt;
&lt;p&gt;&lt;img alt="basketball" src="https://github.com/mobbSF/blog/blob/master/images/fosberry/basketball.png?raw=true" /&gt;&lt;/p&gt;
&lt;h4&gt;Check out the black dot. That's the center of mass of a donut, right?&lt;/h4&gt;
&lt;p&gt;&lt;img alt="donut" src="https://github.com/mobbSF/blog/blob/master/images/fosberry/donut.png?raw=true" /&gt;&lt;/p&gt;
&lt;p&gt;Your mind should be blown because you just admitted to yourself that the center of mass of a donut is not actually &lt;strong&gt;inside&lt;/strong&gt; the donut.&lt;/p&gt;
&lt;h4&gt;Check out the black dot. That's the center of mass of a half of a donut, after we cut off the bottom, right?&lt;/h4&gt;
&lt;p&gt;&lt;img alt="half_donut" src="https://github.com/mobbSF/blog/blob/master/images/fosberry/half_donut.png?raw=true" /&gt;&lt;/p&gt;
&lt;h4&gt;Now, what if you bent over backwards, so you looked like a half a donut? Then jumped over the bar?&lt;/h4&gt;
&lt;p&gt;&lt;img alt="fosberry" src="https://github.com/mobbSF/blog/blob/master/images/fosberry/fosberry.gif?raw=true" /&gt;&lt;/p&gt;
&lt;p&gt;Yes, this is exactly what Dick did. He figured out that he could jump over the bar, while his center of mass went &lt;strong&gt;under&lt;/strong&gt; the bar, allowing him to shave off wasted effort. Prior to this discovery, it was just basically assumed by everyone else that the jumper's center of mass always had to go &lt;strong&gt;over&lt;/strong&gt; the bar.  &lt;/p&gt;
&lt;p&gt;The bottom line...Fosbury could move the bar up higher than anyone else, and still clear it. That's Olympic gold in the bank right there. &lt;/p&gt;
&lt;p&gt;So what does any of this have to do with muay thai? And defense?&lt;/p&gt;
&lt;p&gt;First, let's see what we are trying to optimize. We are trying to optimize a pretty straightforward response to a body kick. Naturally, we asume we should step back to get out of the way:&lt;/p&gt;
&lt;p&gt;&lt;img alt="pre-donut-gif" src="https://github.com/mobbSF/blog/blob/master/images/fosberry/pre-donut-gif.gif?raw=true" /&gt;&lt;/p&gt;
&lt;p&gt;This is all fine and good, but could be better. Look at the black dots. &lt;/p&gt;
&lt;p&gt;You had to move your center of mass, two times. Once to get out of the way, and then once to get back where you started. &lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;This costs energy&lt;/li&gt;
&lt;li&gt;This takes time
As a result, you can't counterattack, because you spent all your time and energy getting out of the way.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Now let's see the Donut Defense.&lt;/p&gt;
&lt;p&gt;If Fosbury could get over the bar with his body in a donut shape, then you should consider avoiding a kick by putting your body in a donut shape too. See the images below:&lt;/p&gt;
&lt;p&gt;&lt;img alt="half-donut-gif" src="https://github.com/mobbSF/blog/blob/master/images/fosberry/half-donut-gif.gif?raw=true" /&gt;&lt;/p&gt;
&lt;p&gt;This is exactly the same thing that Fosbury did with the bar, but now the other guy's shin is going through your center of mass. And missing.&lt;/p&gt;
&lt;p&gt;The advantage of &lt;em&gt;not&lt;/em&gt; having to move your center of mass: &lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;It costs less energy&lt;/li&gt;
&lt;li&gt;It takes less time
As a result, you can counterattack immediately because you are in position to do so.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;I recommend to anyone at any level to add the Donut Defense to their shadowboxing and sparring. It's super simple. It's a good alternative to checking and catching. And it just makes a ton of sense from both theortical and practical perspectives.&lt;/p&gt;
&lt;p&gt;Once you start to catch on, you see it happening all over the place. Here's Mayweather doing something similar versus Canelo. Mayweather is evading the punch and limiting how far back he needs to move his feet / center of mass:&lt;/p&gt;
&lt;p&gt;&lt;img alt="mayweather" src="https://github.com/mobbSF/blog/blob/master/images/fosberry/mayweather.png?raw=true" /&gt;&lt;/p&gt;
&lt;p&gt;Alright, I'm going to wrap it up here because I want to keep this short. 
Thanks for reading; I hope it was worth it. And I hope that no matter what level your training you may be at right now, you feel comfortable thinking critically about what you do in the gym. Please comment below!&lt;/p&gt;</content><category term="sport"></category></entry><entry><title>Deep Learning for Sport Wagering Part 3 of 3</title><link href="http://mattobrien.me/deep-learning-for-sport-wagering-part-3-of-3.html" rel="alternate"></link><published>2017-10-09T00:00:00-07:00</published><updated>2017-10-09T00:00:00-07:00</updated><author><name>Matt O'Brien</name></author><id>tag:mattobrien.me,2017-10-09:/deep-learning-for-sport-wagering-part-3-of-3.html</id><summary type="html">&lt;p&gt;Predicting&lt;/p&gt;</summary><content type="html">&lt;h4&gt;Part 3: Prediction and Evaluation&lt;/h4&gt;
&lt;p&gt;&lt;a href="http://www.mattobrien.me/deep-learning-for-sport-wagering-part-1-of-3.html"&gt;Part 1: Characteristics of the dataset&lt;/a&gt;&lt;br /&gt;
&lt;a href="http://www.mattobrien.me/deep-learning-for-sport-wagering-part-2-of-3.html"&gt;Part 2: Modeling&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;I considered one major betting strategy during this final phase of the project. It is as follows:  &lt;/p&gt;
&lt;p&gt;If&lt;br /&gt;
$\text{predicted probability} &amp;gt; \text{some decision threshold}$, 
 and&lt;br /&gt;
$\text{predicted probability} &amp;gt; \text{sportsbook probability}$&lt;br /&gt;
then place bet  &lt;/p&gt;
&lt;p&gt;This strategy can be thought of as conservative approach. We include a parameter that indicates if we are confident that we have an edge on the casino or sportsbook or not.  &lt;/p&gt;
&lt;p&gt;Allow me a quick foray into the structure of gambling. Sportsbook odds are set, not by information, but by popular sentiment as it is revealed by &lt;a href="https://www.docsports.com/gambling-terms.html"&gt;action&lt;/a&gt;. If some Boxer A gets a large amount of action, then the sportsbook will consider Boxer A to be more likely to win, and consequently, payout on this outcome is reduced. Thus, my model is attempting to answer the question, "When does prediction based on historic data result in a confidence higher than the confidence of the sportsbook -- which is a function of popular sentiment?". In this sense, at it's most stripped down, the model is trying make a totally impartial, data driven decision, and looks for opportunities when public perception is not aligned with historically based signal.  &lt;/p&gt;
&lt;p&gt;The strategy also has the opportunity to benefit from it's built-in safeguard. Suppose the sportsbook places some Boxer A at a 10% chance of winning, and the model predicts an 11% chance of winning. Without the safeguard, the model would decide to place the bet. Wagering on such low probabilities is something we don't want. Instead, we want to see action whenever the algorithm is confident above some appropriate threshold.&lt;/p&gt;
&lt;p&gt;To be implemented, first comes acquistion of more data. Historic sportsbook odds needed to be collected so that we could compare them with model's.  &lt;/p&gt;
&lt;p&gt;In boxing, the bookmaker's odds come structured into a form which is referred to as the &lt;a href="https://en.wikipedia.org/wiki/Odds#Moneyline_odds"&gt;moneyline&lt;/a&gt;. The moneyline is a little confusing at first. Generally, one fighter who considered favored to win is assigned a negative number. The other fighter is considered the underdog, and is assigned a positive number. &lt;/p&gt;
&lt;p&gt;The best way to remember how to read the moneyline is to always start with the image of a one-hundred dollar bill in your mind.  &lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;A negative number (assocated with the favored fighter) shows how much money you need to bet to win a profit of $100.  &lt;/li&gt;
&lt;li&gt;A positive number (associated with the underdog) shows how much profit a winning wager of $100 would yield.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;So if the moneyline has Boxer A at -130, we know that Boxer A is expected to win. Further, you know you'd have to place a \$130 bet on this fighter to win \$100.&lt;br /&gt;
For Boxer B, the moneyline might have them set at +110. This mean Boxer B is the underdog, and if you placed a \$100 bet on this fighter, you'd win \$110.  &lt;/p&gt;
&lt;p&gt;Since Keras is returning the probability of a boxer winning, we now need to convert the moneyline into regular probabilities so we can compare apples to apples.  &lt;/p&gt;
&lt;p&gt;To do this, first the actual numeric values (-130 and +110, on this example above), must be converted to what are referred to as &lt;a href="https://www.sbo.net/strategy/implied-probability/"&gt;implied probabilities&lt;/a&gt; (more about implied probabilities in a second). The formula is as follows:  &lt;/p&gt;
&lt;p&gt;$\text{Implied probability for 'negative' moneyline} = \frac{ - ( \text{'negative' moneyline value})}{- ( \text{'negative' moneyline value} ) + 100}$&lt;br /&gt;
and  &lt;/p&gt;
&lt;p&gt;$\text{Implied probability for 'positive' moneyline} = \frac{100}{\text{'positive' moneyline value} + 100}$&lt;/p&gt;
&lt;p&gt;Thus, -130 is converted to 0.56, and +110 is converted to 0.50.  &lt;/p&gt;
&lt;p&gt;But what is an implied probability anyway?&lt;/p&gt;
&lt;p&gt;Implied probability is our usual notion of probability which has actually been modified by what is called either &lt;a href="https://en.wikipedia.org/wiki/Vigorish"&gt;vigorish, or juice&lt;/a&gt;. Both of these terms refer to a built-in edge, by the bookmaker, on the true odds. The modification shifts the moneyline is such a way that the sportsbooks can make their profit. Usually, the vig amounts to 20 points. It's basically the casino's cut. Fortunately, it's easy to remove the vigorish using this simple formula:  &lt;/p&gt;
&lt;p&gt;Take one of your implied probability. Divide it by the sum of both of your implied probabilities.  &lt;/p&gt;
&lt;p&gt;Thus:  &lt;/p&gt;
&lt;p&gt;$\text{Actual probability } = \frac{\text{Implied probability A}}{\text{Implied probability A} + \text{Implied probability B}}$&lt;/p&gt;
&lt;p&gt;With the math settled, I began searching for a set of historic moneylines for records which I could use in my test set. Using a variety of sources (including laborious searching of the Wayback Machine, and locating an actual broker for assistance), I collected a set of 728 moneylines. After munging, the final size was 679.  &lt;/p&gt;
&lt;p&gt;We now bring our attention back to decision thresholds. What would be the optimal value where our $\text{model probability} &amp;gt; \text{some decision threshold}$?  To determine this, it was merely a matter of looping through thresholds from $[ 0, 1 ]$ by 0.1 and collecting the resulting classifications.  &lt;/p&gt;
&lt;p&gt;The outputs collects at each of these varying decision thresholds were as follows:   &lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Total number of wagers that satisified the criteria and thus were placed  &lt;/li&gt;
&lt;li&gt;Number of wagers placed which won  &lt;/li&gt;
&lt;li&gt;Number of wagers placed which lost  &lt;/li&gt;
&lt;li&gt;A tabulation of the balance resulting from money won via successful wagers and money lost via unsuccessful wagers  &lt;/li&gt;
&lt;li&gt;ROI (return on investment): simply $\frac{\text{balance}}{\text{total investment}}$  &lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;We assumed that each bet placed was a \$100 bet. Every loss will incur a deduction of \$100, whereas each winning bet will earn a deposit depending on the sportsbook odds. This means if the model can predict 'easy' matches, it can win a smaller amount of money, but if the matches are harder to predict, the model can earn more.  &lt;/p&gt;
&lt;p&gt;Here is a plot showing the outcome for #1 on the list above:  &lt;/p&gt;
&lt;p&gt;&lt;img alt="wagers" src="https://github.com/mobbSF/blog/blob/master/images/wagers.png?raw=true" /&gt;  &lt;/p&gt;
&lt;p&gt;This gives us an intuition on where to place our decision threshold. We are interested in the point where the blue line and the green line are closest together, which means we will win the highest proportion of our placed bets. Simultaneously we would like this point to be as high as possible along the y axis, meaning the model chose to place a high net number of bets. &lt;/p&gt;
&lt;p&gt;The chart below shows the model will place the proportionately largest number of winning bets around an 0.85 to 0.94 decision threshold.  &lt;/p&gt;
&lt;p&gt;&lt;img src="https://github.com/mobbSF/blog/blob/master/images/chart_002.png" width="200"&gt;&lt;/p&gt;
&lt;p&gt;&lt;img alt="chart_001" src="https://github.com/mobbSF/blog/blob/master/images/chart_001.png?raw=true" /&gt;  &lt;/p&gt;
&lt;p&gt;It looks like roughly 0.90 is a reasonable place to set the threshold.  &lt;/p&gt;
&lt;p&gt;Now that we've got a feel for where our threshold might be, we can look forward to the bottom line -- did we turn a profit?  &lt;/p&gt;
&lt;p&gt;Here is a plot showing the outcome for #5 (ROI) on the list above:  &lt;/p&gt;
&lt;p&gt;&lt;img alt="ROI" src="https://github.com/mobbSF/blog/blob/master/images/ROI.png?raw=true" /&gt;  &lt;/p&gt;
&lt;p&gt;This chart shows the ROI values at the regions of interest we saw in the first plot:  &lt;/p&gt;
&lt;p&gt;&lt;img alt="chart_002" src="https://github.com/mobbSF/blog/blob/master/images/chart_002.png?raw=true" /&gt;  &lt;/p&gt;
&lt;p&gt;This chart shows we can get an ROI of roughly 22.5% if we set the decision threshold to 0.90. We could push it up to 24.8% if we choose 0.94 as the threshold, but notice the precipitous drop starting at 0.95 on the plot above. Better to be wary of the presence of variance and/or noise and choose to focus on a more median value.&lt;/p&gt;
&lt;p&gt;To unpack the ROI value, we can look at the actual dollar amount earned:  &lt;/p&gt;
&lt;p&gt;&lt;img alt="cash" src="https://github.com/mobbSF/blog/blob/master/images/cash.png?raw=true" /&gt;  &lt;/p&gt;
&lt;p&gt;We are seeing that when we stick with 0.90 we earn \$292.00, from a net investment of \$1,300.&lt;/p&gt;
&lt;p&gt;Finally, let's see what the plot looks like when we view most of these results simultaneously:  &lt;/p&gt;
&lt;p&gt;&lt;img alt="functions" src="https://github.com/mobbSF/blog/blob/master/images/functions.png?raw=true" /&gt;  &lt;/p&gt;
&lt;p&gt;Here we can see the sweet spot of 0.90 clearly. &lt;/p&gt;
&lt;p&gt;However, modeling like this isn't always deterministic. Small variations in inputs such that occur during randomly selecting test and validation sets can ripple through the pipeline and give different results.  &lt;/p&gt;
&lt;p&gt;I reran the project from top to bottom a few times, and found that indeed the threshold is a pretty fragile spot. These three images show that the 0.9 threshold might not always be the optimum.  &lt;/p&gt;
&lt;p&gt;&lt;img alt="functions" src="https://github.com/mobbSF/blog/blob/master/images/slate.png?raw=true" /&gt; &lt;/p&gt;
&lt;p&gt;To visually get a feel for the variance, I made a plot of these 100 models:  &lt;/p&gt;
&lt;p&gt;&lt;img alt="functions" src="https://github.com/mobbSF/blog/blob/master/images/cash_100.png?raw=true" /&gt; &lt;/p&gt;
&lt;p&gt;That's quite a lot of varaiance. How to mitigate this? The idea is akin to ensembling the model with many different versions of itself. I decided to create 100 models, evaluate each of them, and take average for ROI, bets placed, cash balance, etc.  &lt;/p&gt;
&lt;p&gt;Here's a plot of the average:&lt;/p&gt;
&lt;p&gt;&lt;img alt="functions" src="https://github.com/mobbSF/blog/blob/master/images/functions_100_mean.png?raw=true" /&gt; &lt;/p&gt;
&lt;p&gt;Notice how much smoother the line is than on the other plots. It seems like the choice of 0.90 is still pretty conservative. But in gambling, perhaps conservative is okay.&lt;/p&gt;
&lt;p&gt;With the bulk of the work now done, we can claim success.  &lt;/p&gt;
&lt;p&gt;The outcome can be summed up in this elevator pitch sized statement:  &lt;/p&gt;
&lt;p&gt;&lt;strong&gt;"The model, with a decision threshold of 0.90, chose to place thirteen bets, winning all but one. With an initial investment of 
\$1,300, it won \$292, which represents a ROI of 22.5%."&lt;/strong&gt;  &lt;/p&gt;
&lt;p&gt;This system performed much better than I expected. My initial hope was simply to build a MLP which had accuracy better than a coinflip. But the fact that the model can turn a profit when swimming with the Vegas sharks is very exciting.&lt;/p&gt;
&lt;p&gt;The next step is to put the model to use, see how it performs over a few month time period, and then see what improvements can be made. This is the true test -- putting my real money where my mouth is! I will report back with a Part 4 of this blog post series when I have had enough wagering experience to infer what can be improved. &lt;/p&gt;
&lt;p&gt;Thank you for reading this far. Please comment if you have the inclination!&lt;/p&gt;&lt;script type= "text/javascript"&gt;
    if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) {
        var mathjaxscript = document.createElement('script');
        mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#';
        mathjaxscript.type = 'text/javascript';
        mathjaxscript.src = 'https:' == document.location.protocol
                ? 'https://c328740.ssl.cf1.rackcdn.com/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML'
                : 'http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML';
        mathjaxscript[(window.opera ? "innerHTML" : "text")] =
            "MathJax.Hub.Config({" +
            "    config: ['MMLorHTML.js']," +
            "    TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'AMS' } }," +
            "    jax: ['input/TeX','input/MathML','output/HTML-CSS']," +
            "    extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js']," +
            "    displayAlign: 'center'," +
            "    displayIndent: '0em'," +
            "    showMathMenu: true," +
            "    tex2jax: { " +
            "        inlineMath: [ ['$','$'] ], " +
            "        displayMath: [ ['$$','$$'] ]," +
            "        processEscapes: true," +
            "        preview: 'TeX'," +
            "    }, " +
            "    'HTML-CSS': { " +
            "        styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'black ! important'} }" +
            "    } " +
            "}); ";
        (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript);
    }
&lt;/script&gt;
</content><category term="deep learning"></category><category term="sport"></category><category term="wagering"></category></entry><entry><title>Deep Learning for Sport Wagering Part 2 of 3</title><link href="http://mattobrien.me/deep-learning-for-sport-wagering-part-2-of-3.html" rel="alternate"></link><published>2017-09-16T00:00:00-07:00</published><updated>2017-09-16T00:00:00-07:00</updated><author><name>Matt O'Brien</name></author><id>tag:mattobrien.me,2017-09-16:/deep-learning-for-sport-wagering-part-2-of-3.html</id><summary type="html">&lt;p&gt;Modeling&lt;/p&gt;</summary><content type="html">&lt;h4&gt;Part 2: Modeling&lt;/h4&gt;
&lt;p&gt;&lt;a href="http://www.mattobrien.me/deep-learning-for-sport-wagering-part-1-of-3.html"&gt;Part 1: Characteristics of the dataset&lt;/a&gt;&lt;br /&gt;
&lt;a href="http://www.mattobrien.me/deep-learning-for-sport-wagering-part-3-of-3.html"&gt;Part 3: Modeling&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;I was fortunate enough to have attended Jeremy Howard's awesome &lt;a href="https://www.usfca.edu/data-institute/certificates/deep-learning-part-one"&gt;deep learning certification program&lt;/a&gt; at University of San Francisco. One of the many insightful things Jeremy said was, and I quote verbatium, &lt;a href="https://youtu.be/1-NYPQw5THU?t=1h19m11s"&gt;"The first thing I do, is try to get a feature importance plot printed."&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Being just smart enough to recognize when smarter people have smart ideas, this is exactly what I did.&lt;/p&gt;
&lt;p&gt;I built a straightforward Random Forest in scikit-learn, using CV to select hyperparameters and using general best procedures. I retrieved this plot:&lt;/p&gt;
&lt;p&gt;&lt;img alt="VIP" src="https://github.com/mobbSF/blog/blob/master/images/VIP.png?raw=true" /&gt;&lt;/p&gt;
&lt;p&gt;The plot doesn't have a strong inflection point, making it difficult to decide where to draw a line in the sand about what is important to include and what isn't. Let's see if we can deduce where this cutoff might fall, by first let's look at what isn't important:  &lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;We see that the number of Draw outcomes isn't important, which makes sense, as these are rare outcomes and are fairly irrelevant. The number of draws a boxer has doesn't have much bearing on the rest of their records.  &lt;/li&gt;
&lt;li&gt;We see that the permutations of stances across opponents (complimentary or opposite, &lt;a href="https://en.wikipedia.org/wiki/Southpaw_stance"&gt;southpaw&lt;/a&gt; or &lt;a href="https://en.wikipedia.org/wiki/Orthodox_stance"&gt;orthodox&lt;/a&gt;) isn't relevant.  &lt;/li&gt;
&lt;li&gt;Finally, the indicator columns aren't useful, which isn't a major surprise. &lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Next, let's look at what &lt;em&gt;is&lt;/em&gt; important. But first, let's take a little detour to think ahead about what might feel right. Let's ignore the variable importance plot for a moment.&lt;/p&gt;
&lt;p&gt;There is a fundamental axiom in boxing: "Hit and don't get hit." For boxers who fail to adhere to this basic principle, careers will be unnecesarily short, as physical damage sustained will quickly accumulate. So the idea of wear and tear on the body accumulated by a boxer over time seems like a naturally important component of what influences the outcome of a fight. &lt;/p&gt;
&lt;p&gt;This being considered, it should come as no great surprise that the most important feature in the Random Forest is &lt;code&gt;P1_days_since_ff&lt;/code&gt;. Recall, this variable reflects how long it has been since a boxer's career began. This perspective on career length turns out to be a natural fit.&lt;/p&gt;
&lt;p&gt;However, it's possible a boxer could fight once, then fight once again 10 years later. In this scenario,&lt;code&gt;P1_days_since_ff&lt;/code&gt; would be a value around 3,650, but this wouldn't be an accurate measurement of that boxer's accumulated wear and tear. The boxer would only have fought twice within that period. Fortunately for us, the next most important features on the plot corresponds to the aggregated number of rounds the opponents have fought. A long 'ring life' can clearly play a large role in a fighter's success (see &lt;a href="https://www.youtube.com/watch?v=Ja9iovR9B3E"&gt;Ali vs Holmes&lt;/a&gt; for a tragic example). Conversely, too few rounds can also play a role in predicting losing.&lt;/p&gt;
&lt;p&gt;Getting back to the variable importance plot, the two Quality of Opposition (&lt;code&gt;QOO&lt;/code&gt;) metrics are shown to be important, which is nice not at the very least because they took a lot of effort to construct!&lt;/p&gt;
&lt;p&gt;The &lt;code&gt;last6_L&lt;/code&gt; and &lt;code&gt;last6_W&lt;/code&gt; variables have a large amounts of variance as evidenced by the bars. This most likely ties into the discussion about how records, as they stand alone, don't adequately reflect the quality of the opposition. For some boxers, the last 6 are very important; for some, they aren't. This makes sense.&lt;/p&gt;
&lt;p&gt;Content with the plot and with these features in mind, I experimented with various subsets of features and various configurations when fitting multilayer perceptrons in Keras.&lt;/p&gt;
&lt;p&gt;On a positive note, because of the small file size of the flat dataset (only 1.85 GB), there were no heavy demands on IO or memory. Thus I could rip through each epoch on a basic AWS cloud GPU painlessly, and iterate on models easily. &lt;/p&gt;
&lt;p&gt;Regarding the actual deep architecture of the MLP, I didn't have major overfitting issues, thus didn't get any advantage with a copious amount of dropout. Batch Normalization didn't give me any advantage, so I discarded it. Fundamentally, it's a remarkably simple dataset and most models I built performed very similarly. Epochs around 10 performed just fine.&lt;/p&gt;
&lt;p&gt;A decent final configuration looked like this: &lt;/p&gt;
&lt;pre&gt;&lt;code&gt;mlp_004 = Sequential()
mlp_004.add(Dense(64, activation='relu', input_dim=13))
mlp_004.add(Dense(64, activation='relu'))
mlp_004.add(Dense(64, activation='relu'))
mlp_004.add(Dropout(0.2))
mlp_004.add(Dense(64, activation='relu'))
mlp_004.add(Dense(1, activation='sigmoid'))

mlp_004.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['accuracy'])

mlp_004.fit(X_train, y_train, batch_size=64, validation_split=0.2, nb_epoch=10)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The validation set accuracy returned was 73%. &lt;/p&gt;
&lt;p&gt;Here's the confusion matrix:&lt;/p&gt;
&lt;p&gt;&lt;img alt="CM" src="https://github.com/mobbSF/blog/blob/master/images/CM.png?raw=true" /&gt;&lt;/p&gt;
&lt;p&gt;Here's the ROC curve:  &lt;/p&gt;
&lt;p&gt;&lt;img alt="ROC" src="https://github.com/mobbSF/blog/blob/master/images/ROC.png?raw=true" /&gt;&lt;/p&gt;
&lt;p&gt;OK, so how should I feel about such relatively modest scores, in this age of a solved MNIST, self-driving cars, and &lt;a href="https://www.cnbc.com/2017/08/11/elon-musk-issues-a-stark-warning-about-a-i-calls-it-a-bigger-threat-than-north-korea.html"&gt;Elon Musk's dire warnings&lt;/a&gt; of &lt;a href="https://www.youtube.com/watch?v=-WIwQlMesr0"&gt;Arnold coming baaack&lt;/a&gt;?&lt;/p&gt;
&lt;p&gt;I must admit, I feel pretty good about it. It's useful to take a step back here and reiterate that the purpose of this project is to make money gambling on boxing. If we were to use this algorithm to indicate when to place a bet, then we would prefer a larger precision at the expense of recall. What this means it that it's better to avoid betting and miss out on opportunities to win (lower recall), as long as we are more confident that when we &lt;em&gt;DO&lt;/em&gt; bet, we will win. More in the third post about this approach.&lt;/p&gt;
&lt;p&gt;Meanwhile, allow me to wander a bit (yet again!) and discuss one of the many experiments I ran that didn't pay off. I went ahead and went for a moonshot. The reality is that as far as wagering on boxing go, it's one thing to wager on a W or L outcome. But if you can win a bet by predicting a more granular types of outcomes, the payouts are several orders of magnitude better. The actual type of outcome -- either a judges decision, or an actual knockout, or a technical knockout -- that's where the big bucks are. And when it comes to knockouts, if it's possible to predict the actual round? The payouts are huge. &lt;/p&gt;
&lt;p&gt;I changed the labels to represent the granular outcomes mentioned above, and I rebuilt the model and crossed my fingers. Unfortunately, and not too surprisingly, accuracy dropped to around 30%. Hummm...well...worth a shot. And definitely worth revisiting again later.&lt;/p&gt;
&lt;p&gt;Next up...prediction time!  &lt;/p&gt;
&lt;p&gt;&lt;a href="http://www.mattobrien.me/deep-learning-for-sport-wagering-part-3-of-3.html"&gt;Part 3: Modeling&lt;/a&gt;&lt;/p&gt;</content><category term="deep learning"></category><category term="sport"></category><category term="wagering"></category></entry><entry><title>Deep Learning for Sport Wagering Part 1 of 3</title><link href="http://mattobrien.me/deep-learning-for-sport-wagering-part-1-of-3.html" rel="alternate"></link><published>2017-09-15T00:00:00-07:00</published><updated>2017-09-15T00:00:00-07:00</updated><author><name>Matt O'Brien</name></author><id>tag:mattobrien.me,2017-09-15:/deep-learning-for-sport-wagering-part-1-of-3.html</id><summary type="html">&lt;p&gt;Characteristics of the dataset&lt;/p&gt;</summary><content type="html">&lt;h4&gt;Part 1: Characteristics of the dataset&lt;/h4&gt;
&lt;p&gt;&lt;a href="http://www.mattobrien.me/deep-learning-for-sport-wagering-part-2-of-3.html"&gt;Part 2: Modeling&lt;/a&gt;&lt;br /&gt;
&lt;a href="http://www.mattobrien.me/deep-learning-for-sport-wagering-part-3-of-3.html"&gt;Part 3: Prediction and Evaluation&lt;/a&gt;  &lt;/p&gt;
&lt;p&gt;Not long ago, I was reading Nate Silver's blog, where there was some discussion about basketball. In particular, my hometown's team, the Golden State Warriors. At the time of the writing, the Warriors were surging towards the status of present-day dynasty, and the blog post was examining ways that the team performed that were revolutionary in the sport.&lt;/p&gt;
&lt;p&gt;One particular line in &lt;a href="https://fivethirtyeight.com/features/how-the-golden-state-warriors-are-breaking-the-nba/"&gt;the blog post&lt;/a&gt; stuck out for me: "It’s as if at some point in the past few years, the Warriors solved contemporary basketball..."&lt;/p&gt;
&lt;p&gt;Solved? A bit heavy on the hyperbole, but maybe not too far off.&lt;/p&gt;
&lt;p&gt;This got me thinking about other sports, and their capacity to be understood via data science, analytics, and deep learning. In particular, I became interested in the somewhat marginal and obscure (by major American sport standards, anyway) sport of boxing. I began to think that boxing could lend itself to being 'solved' nicely, because it has many characteristics that lend it to straightforward analysis and modeling.&lt;/p&gt;
&lt;p&gt;At it's heart, boxing has a simple structure.  Unlike many popular sports, it's not a team sport -- so there isn't a dynamic interplay between multiple individuals. It's also not new: the sport became standardized in the late 1600s, via the &lt;a href="https://en.wikipedia.org/wiki/Marquess_of_Queensberry_Rules"&gt;Marquess of Queensberry Rules&lt;/a&gt;. Thus, there is plenty of data available.  Fortunately for me, much of it is available online.&lt;/p&gt;
&lt;p&gt;To make the project more impactful, I decided to set a very specific goal. I've found that often, personal projects such as these will get more attention on the evenings and weekends if there is the possibility of a good payoff at the end --  so I figured, why not try to build an algorithm that would allow me to win money in Vegas? Thus I set the goal of creating a tool for successful wagering on boxing.&lt;/p&gt;
&lt;p&gt;After quite a long process of collecting, reshaping, and modeling a dataset, I came into posession a what I consider to be a very model. &lt;strong&gt;The tl;dr is that the model returned a 22.5% return on investment.&lt;/strong&gt; This is really exciting and shows the power of deep learning in a tangible manner. &lt;/p&gt;
&lt;p&gt;So, if you make it through these (hopefully not painful to read) blog posts, then I invite you to go ahead and check on some upcoming fights. Ask me where to put your money, and I might be able to provide you with the 'nap.' In case you didn't know, the term 'nap' refers to a highly confident bet. That's been a fun side-effect from this project -- I learned a lot of cool new slang. &lt;/p&gt;
&lt;p&gt;There will be 3 parts to this blog post:&lt;/p&gt;
&lt;p&gt;1) &lt;a href="http://www.mattobrien.me/deep-learning-for-sport-wagering-part-1-of-3.html"&gt;Characteristics of the dataset&lt;/a&gt;&lt;br /&gt;
2) &lt;a href="http://www.mattobrien.me/deep-learning-for-sport-wagering-part-2-of-3.html"&gt;Modeling&lt;/a&gt;
3) &lt;a href="http://www.mattobrien.me/deep-learning-for-sport-wagering-part-3-of-3.html"&gt;Prediction and Evaluation&lt;/a&gt;  &lt;/p&gt;
&lt;p&gt;Part 1 is fairly dry and reflect the laborous truth that the majority of data science work is often dominated by collection and transforming data.  &lt;/p&gt;
&lt;p&gt;Part 2 is short and has some interesting forays into feature engineering vis-à-vis graph databases.  &lt;/p&gt;
&lt;p&gt;Part 3 is the most exciting, since we finally get to talk money! &lt;/p&gt;
&lt;p&gt;It might not be a bad idea to actually read these posts in reverse order.   &lt;/p&gt;
&lt;h3&gt;Characteristics of the data&lt;/h3&gt;
&lt;p&gt;The project was built on a very substantial dataset. The were two major sources of data. First, I aquired metadata on 373,415 individual boxers. Second, I had a collection of over 3.5 million fights (3,529,624 to be exact). Both were imported into MySQL tables. Interestingly, the dataset spanned the entire history of the sport. It was really fun to dig into. There were fighters from every corner of the globe, competing from the very beginning of the sport to the present day. There were boxers in every weight class from minimumweight upward, possessing all skill levels. They came in all ages, and exhibited all levels of success. Casually perusing revealed some quite obscure fighters: a boxer from Accra, Ghana, who fought only once back in 1966 (unfortunately losing by knockout). There was data on all the modern day multimillionaire champions. There were was, for example, &lt;a href="https://en.wikipedia.org/wiki/Wladimir_Klitschko"&gt;Wladamir Klitchko&lt;/a&gt;, nicknamed 'Dr Steelhammer.' The dataset definitely possessed depth. &lt;/p&gt;
&lt;p&gt;Looking specifically at the breadth of features for the metadata on each fighter, I had:&lt;/p&gt;
&lt;h5&gt;boxer data&lt;/h5&gt;
&lt;p&gt;name&lt;br /&gt;
sex&lt;br /&gt;
birth_date&lt;br /&gt;
division&lt;br /&gt;
stance&lt;br /&gt;
height&lt;br /&gt;
reach&lt;br /&gt;
country&lt;br /&gt;
residence&lt;br /&gt;
birth_place&lt;br /&gt;
world_rank&lt;br /&gt;
total_wins&lt;br /&gt;
ko_wins&lt;br /&gt;
total_losses&lt;br /&gt;
ko_losses&lt;br /&gt;
draws&lt;br /&gt;
rounds&lt;br /&gt;
ko_percent  &lt;/p&gt;
&lt;p&gt;At this point it was time to begin evaluating the features. Although elements like a boxer's weight are extremely important in real life boxing, this particular feature was not applicable because weight usually changes across a boxer's career. For example, Manny Pacquiao's first fight was at 98 pounds, but his &lt;a href="https://www.youtube.com/watch?v=OdvxQDVP4WI"&gt;most recent fight&lt;/a&gt; was at 146 pounds. So a single value pulled from the metadata table would only reflect the most recent weight, not the weight at each fight.&lt;/p&gt;
&lt;p&gt;It was simple to keep stance (orthodox or southpaw) as a categorical variable.&lt;/p&gt;
&lt;p&gt;The dataset was balanced: 55% Wins, 45% Losses.&lt;/p&gt;
&lt;p&gt;More useful was the second source of data, which was the specific data for each boxing match:  &lt;/p&gt;
&lt;h5&gt;fight data&lt;/h5&gt;
&lt;p&gt;boxer_id&lt;br /&gt;
date&lt;br /&gt;
location&lt;br /&gt;
rounds_planned&lt;br /&gt;
rounds_happened&lt;br /&gt;
boxer1_mass&lt;br /&gt;
boxer2_mass&lt;br /&gt;
boxer2_wins&lt;br /&gt;
boxer2_loses&lt;br /&gt;
boxer2_draws&lt;br /&gt;
boxer2_last6_wins&lt;br /&gt;
boxer2_last6_loses&lt;br /&gt;
boxer2_last6_draws&lt;br /&gt;
outcome&lt;br /&gt;
outcome_type&lt;br /&gt;
rating&lt;br /&gt;
time&lt;br /&gt;
referee&lt;br /&gt;
judge1&lt;br /&gt;
judge2&lt;br /&gt;
judge3&lt;br /&gt;
judge1_score&lt;br /&gt;
judge2_score&lt;br /&gt;
judge3_score&lt;br /&gt;
titles&lt;br /&gt;
comments  &lt;/p&gt;
&lt;p&gt;As with the metadata for the boxer, I discarded some features of the fights. Much of it was nice but not functionally applicable, such as the names of the referee and judges, and comments, etc.&lt;/p&gt;
&lt;p&gt;With that being settled, the first important decision I made with respect to transformation of the data was to do a self-join within the fight table in MySQL. Thus each record in the dataset represented one fight. There would be a Boxer 1 and a Boxer 2 . The target for each row would be Win, Lose, or Draw, with respect to Boxer 1. There would also be the granular outcome information: the type of W, L or D. After all, there are many ways for a boxing match to end: points, knockout, disqualification, waved off via accidental headbut, quitting on the stool, etc, etc.&lt;/p&gt;
&lt;p&gt;Quick note on a detail of the sport itself: Notice that although boxing is an individual sport, each fighter also has a whole team behind them. During competition, there is a coach in the corner, and there is also the &lt;a href="https://en.wikipedia.org/wiki/Cutman"&gt;cutman&lt;/a&gt;. The cutman handles the first aid between rounds. These two team members are called the 'secondaries' -- so in boxing, we'll refer to the 2 actual fighters 'primaries'. I quickly renamed Boxer 1 and Boxer 2 to P1 and P2.&lt;/p&gt;
&lt;p&gt;Looking at these data, all seemed promising. But after some more reflection, I started to be concerned with what this rectangular representation was missing.  &lt;/p&gt;
&lt;p&gt;In truth, these fights are all sequences of events that happen for a boxer -- they start with fight #1, then continue forward until the end of their careers. This made me interested in engineering 4 temporal variables, which I proceed to do in Pandas. Now, each row had these features:  &lt;/p&gt;
&lt;p&gt;P1_ageAtFight&lt;br /&gt;
P2_ageAtFight&lt;br /&gt;
P1_rounds_fought&lt;br /&gt;
P2_rounds_fought  &lt;/p&gt;
&lt;p&gt;These variables are rather self-explanatory given their names.  &lt;/p&gt;
&lt;p&gt;Another engineered feature was basically 'career length', or how many days it had been since the boxer's debut. These became:  &lt;/p&gt;
&lt;p&gt;P1_days_since_ff&lt;br /&gt;
P2_days_since_ff  &lt;/p&gt;
&lt;p&gt;where 'ff' is just short for 'first fight'.&lt;/p&gt;
&lt;p&gt;Some boxers were missing a birthdate, so I imputed these birthdates by assuming that each boxer's debut was on their 20th birthday. This was a simple subtraction from of 20 years from the date of the first fight.&lt;/p&gt;
&lt;p&gt;But beyond the sequential, temporal perspective, there was still something more to be done. I realized this dataset could also be realized as a graph, with nodes for the boxers and the fights. I could set nodes for the boxers' professional W, L, D records at the time of each fight. So I exported my dataset out of SQL and into Neo4J.&lt;/p&gt;
&lt;p&gt;Once this was done (and it took quite some time, given I had never used Neo4J before), I had a new way of conceptualizing these competitions. The schema is, in ASCI art:&lt;/p&gt;
&lt;p&gt;(A boxer, call them 'P1')--[had a record (W, L, D) on some date] --&amp;gt;(and there was a Fight at some location, with some outcome).&lt;/p&gt;
&lt;p&gt;Now, going the other direction,  &lt;/p&gt;
&lt;p&gt;(and there was a Fight at some location, with some outcome)&amp;lt;--[the opponent had a record, (W, L, D) on that same date]---(The opponent, call them 'P2')&lt;/p&gt;
&lt;p&gt;This actually is more clear when you look at the actual Neo4J graph itself:&lt;/p&gt;
&lt;p&gt;&lt;img alt="Neo4J graph" src="https://github.com/mobbSF/blog/blob/master/images/Neo_000.png?raw=true" /&gt;&lt;/p&gt;
&lt;p&gt;Here you see the blue boxer nodes, their records at a given time (red node), the fight node (green), and the complementary information for their opponents. Note that this particular boxer had a few rematches which are visible when two edges touch the same blue P2 (P2 being the opponent), node.&lt;/p&gt;
&lt;p&gt;Actually, it's interesting to see how the graph can be expanded. Take a look a Muhammad Ali's and his career:&lt;/p&gt;
&lt;p&gt;&lt;img alt="Neo4J graph 1" src="https://github.com/mobbSF/blog/blob/master/images/Neo_001.png?raw=true" /&gt;&lt;/p&gt;
&lt;p&gt;and here's &lt;a href="https://www.youtube.com/watch?v=-FZBzGhxERg"&gt;Ali's fight with Archie Moore&lt;/a&gt;, and Archie Moore's career: &lt;/p&gt;
&lt;p&gt;&lt;img alt="Neo4J graph 2" src="https://github.com/mobbSF/blog/blob/master/images/Neo_002.png?raw=true" /&gt;&lt;/p&gt;
&lt;p&gt;...and here's &lt;a href="https://www.youtube.com/watch?v=MUT71-jyY2s"&gt;Archie Moore's fight with Jimmy Slade&lt;/a&gt;,&lt;/p&gt;
&lt;p&gt;&lt;img alt="Neo4J graph 3" src="https://github.com/mobbSF/blog/blob/master/images/Neo_003.png?raw=true" /&gt;&lt;/p&gt;
&lt;p&gt;and so forth.&lt;/p&gt;
&lt;p&gt;Envisioned as a graph, it is insightful to see the interconnectedness of the sport as a whole. Here's a few examples:  &lt;/p&gt;
&lt;p&gt;&lt;img alt="Neo4J graph 4" src="https://github.com/mobbSF/blog/blob/master/images/Neo_004.png?raw=true" /&gt;  &lt;/p&gt;
&lt;p&gt;&lt;img alt="Neo4J graph 5" src="https://github.com/mobbSF/blog/blob/master/images/Neo_005.png?raw=true" /&gt;  &lt;/p&gt;
&lt;p&gt;Now that now that the Neo4J database was built, the first metric I focused on creating using Cypher was a 'quality of opposition' (QOO) score.&lt;/p&gt;
&lt;p&gt;QOO is necessary to suss out boxers with inflated records. Interestingly enough, boxing is the only sport (that I am aware of, at least) where a boxer actually gets to choose their opponent. There are no tournaments...no leagues...just arrangements between two boxers and the businesspeople around them, to hold an event. So what is stopping a boxer from inflating their record with &lt;a href="http://boxrec.com/en/boxer/4741"&gt;lousy opposition&lt;/a&gt;? Not much. And this happens often in practice.  &lt;/p&gt;
&lt;p&gt;It all really comes down to the quality of a boxer's opponents. If a boxer (say P1) has been beating up on &lt;a href="https://en.wikipedia.org/wiki/Tomato_can_(sports_idiom)"&gt;tomato cans&lt;/a&gt;, then we need to acknowledge this. 
Because if during that same time, another boxer (say P2) was battling top-quality opposition, then you'd be wise to put your money on P2. Because both P1 and P2 could have records of 20 Wins, 0 losses. In short, W L D records can be misleading.  &lt;/p&gt;
&lt;p&gt;(In reality, most successful fighters start competing relatively frequently, against somewhat weak opposition. Later, they increase the quality of opposition as they decrease the frequency of competition. So the above scenario is an exaggeration, in most cases).&lt;/p&gt;
&lt;p&gt;To show how the metric works, let's first start with this made up, simplified visual scenario:&lt;/p&gt;
&lt;p&gt;&lt;img alt="QOO 1" src="https://github.com/mobbSF/blog/blob/master/images/QOO_001.png?raw=true" /&gt;&lt;/p&gt;
&lt;p&gt;As you can see, P1 has fought 3 opponents (they live in 'Layer 1'), and each of those opponents had fought 3 opponents themselves (they live in 'Layer 2').&lt;/p&gt;
&lt;p&gt;Now consider Layer 2. For each group of 3 fights, sum up these fighters' records as : count(Wins) / count(fights).&lt;/p&gt;
&lt;p&gt;&lt;img alt="QOO 2" src="https://github.com/mobbSF/blog/blob/master/images/QOO_002.png?raw=true" /&gt;&lt;/p&gt;
&lt;p&gt;Now, recursively running back up the graph, let's see how the boxer in Layer 1 performed against this group. This will be count(Wins) / count(opponents) from above, but now multiplied by the previously calculated value. Voila; we have the QOO metric.&lt;/p&gt;
&lt;p&gt;&lt;img alt="QOO 3" src="https://github.com/mobbSF/blog/blob/master/images/QOO_003.png?raw=true" /&gt;&lt;/p&gt;
&lt;p&gt;After setting a QOO score for all fights on the nodes in Neo4J, it was easy to put together another quick and dirty metric: QOOP, which for lack of better nomenclature, is 'Quality of opposition prime'. Here, I just took the mean of all a boxer's opponents' QOOs and wrote it to the record node.&lt;/p&gt;
&lt;p&gt;Indicator columns with 0 or 1 were included, in case the QOO metrics couldn't be built. This could happen if, say, a fight was a boxer's debut.&lt;/p&gt;
&lt;p&gt;There are still many other ways to extract value from the Neo4J implementation. For example, implementing an &lt;a href="https://en.wikipedia.org/wiki/Elo_rating_system"&gt;elo rating&lt;/a&gt; (as borrowed from chess) could result in a valuable datum for the state of each boxer during each match. But this was a good enough start and took me pretty far.&lt;/p&gt;
&lt;p&gt;Now that the data were all cleaned up ready to go, it was time to (finally!) get to the fun part...building some deep learning models.  &lt;/p&gt;
&lt;p&gt;&lt;a href="http://www.mattobrien.me/deep-learning-for-sport-wagering-part-2-of-3.html"&gt;Part 2: Modeling&lt;/a&gt;&lt;/p&gt;</content><category term="deep learning"></category><category term="sport"></category><category term="wagering"></category></entry><entry><title>The 80 Best Boxers; A Career Viewer</title><link href="http://mattobrien.me/the-80-best-boxers-a-career-viewer.html" rel="alternate"></link><published>2016-06-05T00:00:00-07:00</published><updated>2016-06-05T00:00:00-07:00</updated><author><name>Matt O'Brien</name></author><id>tag:mattobrien.me,2016-06-05:/the-80-best-boxers-a-career-viewer.html</id><summary type="html">&lt;p&gt;A visualization of the careers of the top 80 boxers in the last 80 years&lt;/p&gt;</summary><content type="html">&lt;h1&gt;The 80 Best Boxers; A Career Viewer&lt;/h1&gt;
&lt;p&gt;A few years back, the Ring Magazine compiled a list of &lt;a href="http://boxing.about.com/od/history/a/ring_80_best.htm"&gt;The 80 Best Boxers of the Last 80 Years&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;This is a solid list, compiled by the definitive boxing authority. But it is fundamentally just..well, a list. Which is a bit boring. It got me thinking of ways to get a better feel for what these boxers' accomplished throughout the duration of their careers.&lt;/p&gt;
&lt;p&gt;To do that, I created an app which allows us to see where in the world these 80 pugilists plied their trade. We can explore chronologically, or by their opponent's names, and see how the top guys wrecked shop all over the world. There are big 'W', 'L', or 'D' letters plotted directly on a zoomable map, to indicate what happened and where.   &lt;/p&gt;
&lt;p&gt;Here's a screenshot:  &lt;/p&gt;
&lt;p&gt;&lt;img alt="screenshot" src="https://raw.githubusercontent.com/mobbSF/blog/master/content/sport/image_007.png" /&gt;&lt;/p&gt;
&lt;p&gt;But you can &lt;a href="https://mattobriendotme.shinyapps.io/top_80_career_viewer/"&gt;click here&lt;/a&gt; to play with it yourself, which is a lot more fun than looking at my screenshots.&lt;/p&gt;
&lt;p&gt;Speaking of screenshots, you can see below, that some fighters travelled all over the place. This is the career of the Old Mongoose himself, &lt;a href="https://en.wikipedia.org/wiki/Archie_Moore"&gt;Archie Moore&lt;/a&gt;: &lt;/p&gt;
&lt;p&gt;&lt;img alt="Archie Moore's career" src="https://raw.githubusercontent.com/mobbSF/blog/master/content/sport/image_005.png" /&gt;&lt;/p&gt;
&lt;p&gt;Then we have guys like &lt;a href="https://en.wikipedia.org/wiki/Rocky_Marciano"&gt;Rocky Marciano&lt;/a&gt;, who stuck pretty much to his own backyard during the duration of his short but undefeated career: &lt;/p&gt;
&lt;p&gt;&lt;img alt="Rocky Marcian's career" src="https://raw.githubusercontent.com/mobbSF/blog/master/content/sport/image_006.png" /&gt;&lt;/p&gt;
&lt;p&gt;Have a look at &lt;a href="https://mattobriendotme.shinyapps.io/top_80_career_viewer/"&gt;the app&lt;/a&gt; and play with it! Let me know what you think in the comments. I'd also appreciate a heads up on any bugs you might find.  &lt;/p&gt;</content><category term="sport science"></category><category term="boxing"></category></entry><entry><title>A nation by nation look at knockouts in boxing</title><link href="http://mattobrien.me/a-nation-by-nation-look-at-knockouts-in-boxing.html" rel="alternate"></link><published>2016-05-31T00:00:00-07:00</published><updated>2016-05-31T00:00:00-07:00</updated><author><name>Matt O'Brien</name></author><id>tag:mattobrien.me,2016-05-31:/a-nation-by-nation-look-at-knockouts-in-boxing.html</id><summary type="html">&lt;p&gt;Aggregating boxing outcomes by nation of origin&lt;/p&gt;</summary><content type="html">&lt;h1&gt;A nation by nation look at knockouts in boxing&lt;/h1&gt;
&lt;p&gt;Here's a question for you: Who scores more knockouts as a whole, Mexican fighters or Philipino fighters?  &lt;/p&gt;
&lt;p&gt;(tl;dr: click &lt;a href="https://mattobriendotme.shinyapps.io/ko_by_countries/" title="Knockouts by Nation"&gt;here&lt;/a&gt; to find out yourself.)&lt;/p&gt;
&lt;p&gt;It's a good question...and it's one that could certainly stir up some impassioned debate on various online forums. Unfortunately, we'd all be stuck debating based on our intuition. It is impossible to answer this kind of question without looking directly at the numbers. But unlike other sports such as baseball or basketball, the cold hard facts are sometimes harder to come across in boxing. &lt;/p&gt;
&lt;p&gt;In order to answer this question, I collected over 4 million records of fights from all over the world, from all eras. I looked at what country the winners were from, and how they won the fights. I created a tool to help visualize the results. You can play around with it yourself &lt;a href="https://mattobriendotme.shinyapps.io/ko_by_countries/" title="Knockouts by Nation"&gt;by clicking here&lt;/a&gt;. With it, you can compare any number of countries, side by side, and see which one has produced the most knockouts.  &lt;/p&gt;
&lt;p&gt;Forget about compairing Mexico and the Philipines for a second. How about...Ghana and Austrailia?  &lt;/p&gt;
&lt;p&gt;(Now might be a good time to take a break and rewatch the the Ring Magazine's offical 'Upset of the Year' way back in 1992! Yes, of course I'm talking about the rematch between &lt;a href="https://www.youtube.com/watch?v=QsqmNOAw1Sk"&gt;Jeff Fenech and Azumah Nelson&lt;/a&gt;.)  &lt;/p&gt;
&lt;p&gt;Turns out that Austraila, as a whole, doesn't seem to be producing a whole slew of knockout punchers. Their percent of stoppages is well below 50...but on the other hand, Ghana is around 60%.  &lt;/p&gt;
&lt;p&gt;&lt;img alt="Ghana vs. Austraila" src="https://raw.githubusercontent.com/mobbSF/blog/master/content/sport/image_001.png" /&gt;  &lt;/p&gt;
&lt;p&gt;&lt;em&gt;Notice that "Other" on the far right of the graph, contains stuff like Draws, No Contests, and other non-definitive outcomes.&lt;/em&gt;  &lt;/p&gt;
&lt;p&gt;The tool gets more fun when you look at side-by-side comparisons between more than 2 nations (the dropdown on the left has over 100 countries to choose from):  &lt;/p&gt;
&lt;p&gt;&lt;img alt="Jamacia, Switzerland, Isreal" src="https://raw.githubusercontent.com/mobbSF/blog/master/content/sport/image_002.png" /&gt;  &lt;/p&gt;
&lt;p&gt;Appears that the Israelis have the advantage. Historically, Jamacia doesn't seem to be doing a while lot of winning by KO.  &lt;/p&gt;
&lt;p&gt;What do you think? Did you find this useful or interesting? Let me know in the comments section if you find anything surprising.  &lt;/p&gt;</content><category term="sport science"></category><category term="visualization"></category></entry><entry><title>An analysis of stoppages in boxing</title><link href="http://mattobrien.me/an-analysis-of-stoppages-in-boxing.html" rel="alternate"></link><published>2016-05-18T00:00:00-07:00</published><updated>2016-05-18T00:00:00-07:00</updated><author><name>Matt O'Brien</name></author><id>tag:mattobrien.me,2016-05-18:/an-analysis-of-stoppages-in-boxing.html</id><summary type="html">&lt;p&gt;Some perspectives on knockouts&lt;/p&gt;</summary><content type="html">&lt;h1&gt;An analysis of stoppages in boxing&lt;/h1&gt;
&lt;p&gt;Knockouts are truly the most dramatic, exciting, terrifying, heartbreaking and exhilarating outcome of any sporting event.  Along with the basic knockout, there is also the TKO that occurs when the ref waves it off. A fighter can also retire in between rounds if the fighter (or more likely, their corner) has seen enough and knows there is no decent chance of winning.  &lt;/p&gt;
&lt;p&gt;But what do we really know about these stoppages? No, I don't mean in terms of brain injury and health (that's another topic for another time), but from the big picture?  &lt;/p&gt;
&lt;p&gt;I collected a gigantic set of over 3.3 million boxing matches that spanned all eras of the sport, in every division, with all countries included. I filtered out how many fights ended by knockout, and dove in to see what I could find out. Of these 3.3 million fights, 1,275,316 of them ended in a stoppage.  &lt;/p&gt;
&lt;p&gt;&lt;em&gt;This resulting dataset is a large enough so that we should be confident that insights found within can safely extend to the whole of the sport.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;My three main questions are:  &lt;/p&gt;
&lt;p&gt;1) What percent of fights end in a stoppage?&lt;br /&gt;
1) What round do knockout happen more frequently?  &lt;br /&gt;
2) What weight classes see the most knockouts?  &lt;/p&gt;
&lt;hr /&gt;
&lt;p&gt;&lt;h1&gt;#1:&lt;/h1&gt; &lt;/p&gt;
&lt;p&gt;The first question is the simplest. Clearly not every fight ends in a knockout. I'd say that stoppages are a minority. If you are a boxing fan (and you probably are if you are reading this), then you probably already have a pretty good number in your head. Maybe 20%? 40%?  &lt;/p&gt;
&lt;p&gt;Looking at the data, the number I got was [1275316 /  3330197] * 100  = 38.  &lt;/p&gt;
&lt;p&gt;&lt;strong&gt;So the percentage then is thirty eight.&lt;/strong&gt;  &lt;/p&gt;
&lt;p&gt;Does this match your intuition? For me, it sounds about right. &lt;/p&gt;
&lt;hr /&gt;
&lt;p&gt;&lt;h1&gt;#2:&lt;/h1&gt;  &lt;/p&gt;
&lt;p&gt;Next up, let's look at how stoppages are distributed across rounds. Of these 1,275,316 stoppages, here's &lt;em&gt;when&lt;/em&gt; they happen:  &lt;/p&gt;
&lt;p&gt;&lt;img alt="stoppages across rounds" src="https://raw.githubusercontent.com/mobbSF/blog/master/content/sport/image_003.png" /&gt; 
&lt;em&gt;The x-axis is the round, and the y-axis is the count.&lt;/em&gt;  &lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Stoppages happen most often in the second round.&lt;/strong&gt;   &lt;/p&gt;
&lt;p&gt;Why might this be? Maybe you could argue that most boxing matches that end in stoppage are by definition a mismatch -- and it happens quick, mostly within 4 rounds.  Maybe it's harder to get a knockout later, because familiarity between fighters grow, and the fight becomes a pattern.  I can only use the numbers to supply the outcome, not the cause. &lt;/p&gt;
&lt;p&gt;No matter what the reason, it's clear that those Chavez Sr vs Taylor 12 round endings are extremely rare indeed!  &lt;/p&gt;
&lt;p&gt;&lt;a href="https://www.youtube.com/watch?v=AgenYK7VaxY"&gt;&lt;img alt="Chavez Sr vs Taylor 12" src="http://img.youtube.com/vi/AgenYK7VaxY/0.jpg" /&gt;&lt;/a&gt;&lt;br /&gt;
&lt;em&gt;Julio Cesar Chavez Jr KO12 Meldrick Taylor&lt;/em&gt;&lt;/p&gt;
&lt;hr /&gt;
&lt;p&gt;&lt;h1&gt;#3:&lt;/h1&gt;  &lt;/p&gt;
&lt;p&gt;Finally, what about weight classes? Which division is the most dangerous, where the most knockouts happen? I wouldn't be surprised if the first reaction for most people is 'heavyweight.' Let's see what the numbers say:  &lt;/p&gt;
&lt;p&gt;&lt;img alt="stoppages by division" src="https://raw.githubusercontent.com/mobbSF/blog/master/content/sport/image_004.png" /&gt; 
&lt;em&gt;The x-axis is the weight class, and the y-axis is the count.&lt;/em&gt;  &lt;/p&gt;
&lt;p&gt;Turns out, by separating all fights that end in stoppage into their divisions, we find that &lt;strong&gt;welterweight and lightweight, both individually, barely beat out the big guys.&lt;/strong&gt;  &lt;/p&gt;
&lt;p&gt;That's a bit surprising, especially since the heavyweight class includes both cruiserweights and light heavies, which covers a big span of possible weights.  &lt;/p&gt;
&lt;p&gt;It's unfortunate that, to quote  Rishad Marquardt from boxingnews24.com, &lt;a href="http://www.boxingnews24.com/2016/05/revival-interest-heavyweight-division-still-hot-air-least-now/"&gt;"The heavyweight division in boxing has, historically speaking, been the premier division within the sport."&lt;/a&gt;  The big fighters historically tend to dominate mainstream news coverage, but you can get more explosive action (and bigger headlines) if you also set your sights down to include a few more weight classes.&lt;/p&gt;
&lt;p&gt;(Recall, lightweight is between 130 lbs and less than 140 lbs.  Welterweight is between 140 and less than 154 lbs. 'Super' and 'Light' subclasses were folded in.)&lt;/p&gt;
&lt;hr /&gt;
&lt;p&gt;&lt;h1&gt;So what does it all mean?&lt;/h1&gt; 
 Well, here's two take-home messages. &lt;/p&gt;
&lt;p&gt;Say you just lost all your money playing craps in Vegas, and you've only got $5 left in your pocket.  Go to the nearest sportsbook, and wager $5 on the next lightweight matchup. Pick a knockout in the 2nd round. That's your best chance for a decent payoff.  &lt;/p&gt;
&lt;p&gt;But if you want a safer bet, albeit a smaller payout? Recall that historically, only 38% of boxing matches end prematurely. You'd actually be better off putting your money on a 12 round decision on a pair of 105 lb combatants...so look for a minimumweight fight!  &lt;/p&gt;
&lt;p&gt;Here's another take-home. Say you are a coach. If you want your fighter to be a kayo artist, then consider training them to perform best in the second round (and to be sharpest on defense at that time as well).  Work on interval training where the highest workloads are early. Later intervals could focus more on endurance, footwork and jabs. After all, if there hasn't been a knockout by round 4, then probabistically speaking, the fight is probably going to the cards. Time to pile up points and impress the judges.&lt;/p&gt;&lt;script type= "text/javascript"&gt;
    if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) {
        var mathjaxscript = document.createElement('script');
        mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#';
        mathjaxscript.type = 'text/javascript';
        mathjaxscript.src = 'https:' == document.location.protocol
                ? 'https://c328740.ssl.cf1.rackcdn.com/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML'
                : 'http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML';
        mathjaxscript[(window.opera ? "innerHTML" : "text")] =
            "MathJax.Hub.Config({" +
            "    config: ['MMLorHTML.js']," +
            "    TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'AMS' } }," +
            "    jax: ['input/TeX','input/MathML','output/HTML-CSS']," +
            "    extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js']," +
            "    displayAlign: 'center'," +
            "    displayIndent: '0em'," +
            "    showMathMenu: true," +
            "    tex2jax: { " +
            "        inlineMath: [ ['$','$'] ], " +
            "        displayMath: [ ['$$','$$'] ]," +
            "        processEscapes: true," +
            "        preview: 'TeX'," +
            "    }, " +
            "    'HTML-CSS': { " +
            "        styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'black ! important'} }" +
            "    } " +
            "}); ";
        (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript);
    }
&lt;/script&gt;
</content><category term="sport science"></category></entry><entry><title>a csv defined Shiny structure</title><link href="http://mattobrien.me/a-csv-defined-shiny-structure.html" rel="alternate"></link><published>2016-04-16T00:00:00-07:00</published><updated>2016-04-16T00:00:00-07:00</updated><author><name>Matt O'Brien</name></author><id>tag:mattobrien.me,2016-04-16:/a-csv-defined-shiny-structure.html</id><summary type="html">&lt;p&gt;automatically generate a Shiny visualization in R&lt;/p&gt;</summary><content type="html">&lt;p&gt;This project allows you to use 2 csvs (containing IDs, variables, names, and values) to automatically generate a Shiny structure that you can further customize.&lt;/p&gt;
&lt;p&gt;To fork the project, go to the GitHub page &lt;a href="https://github.com/mobbSF/csv-defined-Shiny-structure"&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Use a csv ('chart_settings.csv') in a form similar to this:  &lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;variable&lt;/th&gt;
&lt;th align="center"&gt;x_axis_labels&lt;/th&gt;
&lt;th align="right"&gt;tab_name&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;var1&lt;/td&gt;
&lt;td align="center"&gt;some_name_var1&lt;/td&gt;
&lt;td align="right"&gt;tab1&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;var2&lt;/td&gt;
&lt;td align="center"&gt;some_name_var2&lt;/td&gt;
&lt;td align="right"&gt;tab1&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;var3&lt;/td&gt;
&lt;td align="center"&gt;some_name_var3&lt;/td&gt;
&lt;td align="right"&gt;tab2&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;var4&lt;/td&gt;
&lt;td align="center"&gt;some_name_var4&lt;/td&gt;
&lt;td align="right"&gt;tab3&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;var5&lt;/td&gt;
&lt;td align="center"&gt;some_name_var5&lt;/td&gt;
&lt;td align="right"&gt;tab3&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;is used along with a csv containing variables and values ('IDs_to_examine.csv'): &lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;ID&lt;/th&gt;
&lt;th align="center"&gt;Date&lt;/th&gt;
&lt;th align="center"&gt;var1&lt;/th&gt;
&lt;th align="center"&gt;var2&lt;/th&gt;
&lt;th align="center"&gt;var3&lt;/th&gt;
&lt;th align="center"&gt;var4&lt;/th&gt;
&lt;th align="center"&gt;var5&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;td align="center"&gt;1/1/11&lt;/td&gt;
&lt;td align="center"&gt;1&lt;/td&gt;
&lt;td align="center"&gt;20&lt;/td&gt;
&lt;td align="center"&gt;5&lt;/td&gt;
&lt;td align="center"&gt;50&lt;/td&gt;
&lt;td align="center"&gt;50&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;td align="center"&gt;1/1/11&lt;/td&gt;
&lt;td align="center"&gt;15&lt;/td&gt;
&lt;td align="center"&gt;3&lt;/td&gt;
&lt;td align="center"&gt;45&lt;/td&gt;
&lt;td align="center"&gt;88&lt;/td&gt;
&lt;td align="center"&gt;100&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;2&lt;/td&gt;
&lt;td align="center"&gt;1/1/13&lt;/td&gt;
&lt;td align="center"&gt;97&lt;/td&gt;
&lt;td align="center"&gt;16&lt;/td&gt;
&lt;td align="center"&gt;5&lt;/td&gt;
&lt;td align="center"&gt;5&lt;/td&gt;
&lt;td align="center"&gt;8&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;2&lt;/td&gt;
&lt;td align="center"&gt;1/1/14&lt;/td&gt;
&lt;td align="center"&gt;55&lt;/td&gt;
&lt;td align="center"&gt;15&lt;/td&gt;
&lt;td align="center"&gt;90&lt;/td&gt;
&lt;td align="center"&gt;75&lt;/td&gt;
&lt;td align="center"&gt;35&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;3&lt;/td&gt;
&lt;td align="center"&gt;1/1/15&lt;/td&gt;
&lt;td align="center"&gt;1&lt;/td&gt;
&lt;td align="center"&gt;76&lt;/td&gt;
&lt;td align="center"&gt;66&lt;/td&gt;
&lt;td align="center"&gt;22&lt;/td&gt;
&lt;td align="center"&gt;1&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;...to create a Shiny with any number of tabs; in this case, 3 ('tab1' to 'tab3').  &lt;/p&gt;
&lt;p&gt;Each tab contains one ggplot, featuring the variables; in this case 'var1' to 'var5'.&lt;/p&gt;
&lt;p&gt;Click &lt;a href="https://mattobriendotme.shinyapps.io/csv-defined-Shiny-structure/"&gt;here&lt;/a&gt; to see it in action.  &lt;/p&gt;
&lt;hr /&gt;
&lt;p&gt;Examine the screenshot and map trace each element back to the appropriate csv. For the sake of simplicity and to avoid creating any unnecessarily customized features, the inputs show only two large, unsized and unmodified variables plotted as a histogram:  &lt;/p&gt;
&lt;p&gt;&lt;img alt="alt text" src="https://github.com/mobbSF/csv-defined-Shiny-structure/blob/master/screenshot.png?raw=true" title="Logo Title Text 2" /&gt;&lt;/p&gt;</content><category term="visualization"></category><category term="R"></category></entry><entry><title>Mike Tyson's Punchout! as a Neo4j graph</title><link href="http://mattobrien.me/mike-tysons-punchout-as-a-neo4j-graph.html" rel="alternate"></link><published>2016-03-16T00:00:00-07:00</published><updated>2016-03-16T00:00:00-07:00</updated><author><name>Matt O'Brien</name></author><id>tag:mattobrien.me,2016-03-16:/mike-tysons-punchout-as-a-neo4j-graph.html</id><summary type="html">&lt;p&gt;a simple example of a graph database&lt;/p&gt;</summary><content type="html">&lt;p&gt;&lt;img alt="Mike Tyson's Punchout!!" src="http://underratedretro.com/press/wp-content/uploads/2014/08/Mike-Tysons-Punchout.jpg" title="Mike Tyson's Punchout!!" /&gt;&lt;/p&gt;
&lt;p&gt;This is a quick and fun little graph of the classic Nintendo game, Mike Tyson's Punch-Out!!.  &lt;/p&gt;
&lt;p&gt;The information for the graph comes directly from the &lt;a href="http://punchout.wikia.com/wiki/Punch-Out_Wiki"&gt;Punchout Wiki&lt;/a&gt;. The graph is based off the NES console from 1987 as opposed to the earlier arcade games or the later release for the Wii. &lt;/p&gt;
&lt;p&gt;I took the liberty of having Little Mac win all his fights by knockout. But then he went up against Iron Mike...  &lt;/p&gt;
&lt;p&gt;&lt;em&gt;Notice that the dataset is read in painlessly via Google Docs as outlined &lt;a href="http://blog.bruggen.com/2014/07/using-loadcsv-to-import-data-from.html"&gt;here&lt;/a&gt;.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;```
Query 1&lt;/p&gt;
&lt;p&gt;LOAD CSV WITH HEADERS FROM
'https://docs.google.com/spreadsheets/u/0/d/1Jr5ABoLMrUPQ3Vm9GTOzVmNucfnWq1ELTxv2WxOYOx0/export?format=csv&amp;amp;id=1Jr5ABoLMrUPQ3Vm9GTOzVmNucfnWq1ELTxv2WxOYOx0&amp;amp;gid=0' AS line
MERGE (b1:boxer {
                    boxer_id: line.boxer_id,
                    name: line.name
                })
MERGE (b2:boxer {boxer_id: line.fought
                })
MERGE (f:fight  { fight_id: line.fight_id,
                  notes: line.notes,
                  outcome: line.outcome
                })
//CREATE (b1)-[:AGAINST]-&amp;gt;(b2)
CREATE (b1)-[r:BOXER_STATUS {
                  total_fights: line.total_fights,
                  wins: line.wins,
                  wins_by_KO: line.wins_by_KO,
                  losses: line.losses,
                  weight: line.weight,
                  height: line.height,
                  nationality: line.nationality,
                  age: line.age,
                  rank: line.rank
                         } ]-&amp;gt;(f);  &lt;/p&gt;
&lt;p&gt;```&lt;/p&gt;
&lt;p&gt;Here's what it looks like:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;MATCH (n)
RETURN n&lt;/code&gt;
&lt;img alt="mtpo" src="https://github.com/mobbSF/blog/blob/master/publicfolder/mtpo.png?raw=true" /&gt;&lt;/p&gt;
&lt;p&gt;Here's some simple queries to practice with:  &lt;/p&gt;
&lt;p&gt;Query 1: What happened when Little Mac fought opponents ranked #1?  &lt;/p&gt;
&lt;p&gt;&lt;code&gt;MATCH (result) &amp;lt;-[r:BOXER_STATUS]- (boxer)
WHERE toInt(r.rank) = 1
RETURN result.outcome, result.notes&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;Query 2: Did Little Mac lose twice to anyone? Or win twice against anyone?
&lt;code&gt;START n=node(*), m=node(*)
WHERE
  n.outcome=m.outcome AND
  ID(n) &amp;lt;ID(m)
RETURN n, m&lt;/code&gt;&lt;/p&gt;</content><category term="visualization"></category></entry><entry><title>Measurability Proof</title><link href="http://mattobrien.me/measurability-proof.html" rel="alternate"></link><published>2016-01-28T00:00:00-08:00</published><updated>2016-01-28T00:00:00-08:00</updated><author><name>Matt O'Brien</name></author><id>tag:mattobrien.me,2016-01-28:/measurability-proof.html</id><summary type="html">&lt;p&gt;Proof by induction&lt;/p&gt;</summary><content type="html">&lt;p&gt;Note: I can't finish this till I get Dr Ov's book so I can use Thm 2.4i, 2.4iii, 2.48&lt;/p&gt;
&lt;h3&gt;Prove that a function $f $on $[a,b]$ is measurable iff $f$ inverse($U$) is measurable for any open set $U$ of $R$.&lt;/h3&gt;
&lt;p&gt;$\Rightarrow$
\newline
By Theorem 2.4i, and Theorem 2.4iii, we have 2 open sets:
\newline
$ J = { x:  f(x) &lt;j \}$
\newline
$K = \{ x:  f(x) &gt; k } ,$ where $j&lt;k$.
\newline
Consider $J \cap K$ which is also open.
\newline
Let $U = J \bigcap K = \bigcup_{i=1}^{n}. (j_i, k_i)$, so that $f^{-1} \left( \bigcup \{ x \in [a, b] : f(x) \in U  \} \right) = f^{-}(U)$. 
\newline
\newline
$\Leftarrow$
\newline
Let $f^{-1}(U)$ be measurable.
\newline
Let $U = \left( c, \infty \right)$.
\newline
Then, $f^{-1}(U)$ measurable $\rightarrow \left\{x: f(x) &gt; c \right}$ is measurable.
\newline
By Theorem 2.48, $f$ is measurable.&lt;/p&gt;&lt;script type= "text/javascript"&gt;
    if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) {
        var mathjaxscript = document.createElement('script');
        mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#';
        mathjaxscript.type = 'text/javascript';
        mathjaxscript.src = 'https:' == document.location.protocol
                ? 'https://c328740.ssl.cf1.rackcdn.com/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML'
                : 'http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML';
        mathjaxscript[(window.opera ? "innerHTML" : "text")] =
            "MathJax.Hub.Config({" +
            "    config: ['MMLorHTML.js']," +
            "    TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'AMS' } }," +
            "    jax: ['input/TeX','input/MathML','output/HTML-CSS']," +
            "    extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js']," +
            "    displayAlign: 'center'," +
            "    displayIndent: '0em'," +
            "    showMathMenu: true," +
            "    tex2jax: { " +
            "        inlineMath: [ ['$','$'] ], " +
            "        displayMath: [ ['$$','$$'] ]," +
            "        processEscapes: true," +
            "        preview: 'TeX'," +
            "    }, " +
            "    'HTML-CSS': { " +
            "        styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'black ! important'} }" +
            "    } " +
            "}); ";
        (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript);
    }
&lt;/script&gt;
</content><category term="in progress"></category></entry><entry><title>Functions of unbounded variation</title><link href="http://mattobrien.me/functions-of-unbounded-variation.html" rel="alternate"></link><published>2015-11-11T00:00:00-08:00</published><updated>2015-11-11T00:00:00-08:00</updated><author><name>Matt O'Brien</name></author><id>tag:mattobrien.me,2015-11-11:/functions-of-unbounded-variation.html</id><summary type="html">&lt;p&gt;Proof regarding a function of bounded variation&lt;/p&gt;</summary><content type="html">&lt;p&gt;This proof relies on the fact that a harmonic series is divergent.  &lt;/p&gt;
&lt;p&gt;Title:  Functions of unbounded variation
Date: 2015-11-11
Tags: math
Summary: Proof regarding a function of bounded variation&lt;/p&gt;
&lt;p&gt;This is a nice proof that relies on the fact that a harmonic series is divergent.  &lt;/p&gt;
&lt;h3&gt;Show that the function&lt;/h3&gt;
&lt;p&gt;$f(x) = 
\begin{cases}
xcos\frac{\pi}{x}&amp;amp; \text{if }x \in (0,1] \\
0, &amp;amp; \text{if } x =0
\end{cases}$ &lt;/p&gt;
&lt;h3&gt;is not a function of bounded variation.&lt;/h3&gt;
&lt;p&gt;To show this function is not BV, we construct a sequence of partitions as follows:&lt;/p&gt;
&lt;p&gt;For each $m \in \mathbb{N}$ define $P_m = {0, \frac{1}{2m}, \frac{1}{2m-1}, \dots, \frac{1}{3}, \frac{1}{2}, 1 }$.  To check the function we evaluate it at those partition points and find $f(P_m) = {0, \frac{1}{2m}, \frac{1}{2m-1}, \dots, -\frac{1}{3}, -\frac{1}{2}, -1 }$ &lt;/p&gt;
&lt;p&gt;Next we consider the variation of $f$:  &lt;/p&gt;
&lt;p&gt;$\begin{align*}
\sum_{i=1}^{n} \left| f(x_i) - f(x_{i-1} \right| &amp;amp;= \left| \frac{1}{2m} - 0) \right| + \left|-\frac{1}{2m-1} - \frac{1}{2m} \right| + \left|\frac{1}{2m-2} \right| + \dots + \left| -\frac{1}{3} - \frac{1}{4} \right| + \left| \frac{1}{2} + \frac{1}{3} \right| + \left| -1 -\frac{1}{2} \right|
\\ &amp;amp;= \frac{1}{2m} + \frac{1}{2m-1} + \frac{1}{2m} + \frac{1}{2m} + \frac{1}{2m-2m} + \frac{1}{2m-1} + \dots + \frac{1}{3} + \frac{1}{4} + \frac{1}{2} + \frac{1}{3} + 1 + \frac{1}{2}
\\ &amp;amp;= 2(\frac{1}{2m} + \frac{1}{2m-1} + \dots +  \frac{1}{2}) + 1
\end{align*} $  &lt;/p&gt;
&lt;p&gt;This is a harmonic series in the form of $\sum_{n=2}^{\infty} \frac{1}{n}$ which is divergent.  So no matter what $M$ we choose for a bound, we can construct a partition for which the variation is unbounded.&lt;/p&gt;&lt;script type= "text/javascript"&gt;
    if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) {
        var mathjaxscript = document.createElement('script');
        mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#';
        mathjaxscript.type = 'text/javascript';
        mathjaxscript.src = 'https:' == document.location.protocol
                ? 'https://c328740.ssl.cf1.rackcdn.com/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML'
                : 'http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML';
        mathjaxscript[(window.opera ? "innerHTML" : "text")] =
            "MathJax.Hub.Config({" +
            "    config: ['MMLorHTML.js']," +
            "    TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'AMS' } }," +
            "    jax: ['input/TeX','input/MathML','output/HTML-CSS']," +
            "    extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js']," +
            "    displayAlign: 'center'," +
            "    displayIndent: '0em'," +
            "    showMathMenu: true," +
            "    tex2jax: { " +
            "        inlineMath: [ ['$','$'] ], " +
            "        displayMath: [ ['$$','$$'] ]," +
            "        processEscapes: true," +
            "        preview: 'TeX'," +
            "    }, " +
            "    'HTML-CSS': { " +
            "        styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'black ! important'} }" +
            "    } " +
            "}); ";
        (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript);
    }
&lt;/script&gt;
</content><category term="math"></category></entry><entry><title>Proof by induction</title><link href="http://mattobrien.me/proof-by-induction.html" rel="alternate"></link><published>2015-11-11T00:00:00-08:00</published><updated>2015-11-11T00:00:00-08:00</updated><author><name>Matt O'Brien</name></author><id>tag:mattobrien.me,2015-11-11:/proof-by-induction.html</id><summary type="html">&lt;p&gt;Proof by induction&lt;/p&gt;</summary><content type="html">&lt;p&gt;Good example of a proof by induction. The problem is from a chapter in the book &lt;a href="http://bulletin.sfsu.edu/sfstatebulletin/courses/40444"&gt;The Art of Proof&lt;/a&gt;.&lt;/p&gt;
&lt;h3&gt;For $x\not = 1$ and $k \in\mathbb{Z_{{\geq}0}}$, prove that $\displaystyle\sum\limits_{j=0}^k x^j =\frac {1-x^{k+1}}{1-x}$&lt;/h3&gt;
&lt;p&gt;We proceed by proof by Induction.&lt;br /&gt;
Let $P(k)$ denote the statement  $\displaystyle\sum\limits_{j=0}^k x^j =\frac {1-x^{k+1}}{1-x}$.&lt;br /&gt;
Checking the base case, in this case $k=0$, we show that  \begin{align*}&lt;br /&gt;
P(0) &amp;amp;=\displaystyle\sum\limits_{j=0}^0 x^j \\
&amp;amp;=\frac {1-x^{0+1}}{1-x}\\
&amp;amp;=\frac {1-x}{1-x}\\
&amp;amp;=1.
\end{align*}
Now, we assume $P(k)$ to be true, that is $\displaystyle\sum\limits_{j=0}^k x^j =\frac {1-x^{k+1}}{1-x}$. 
Next we show  $P(k+1)$ to be true, that is
\begin{align*}
\displaystyle\sum\limits_{j=0}^{k+1} x^j &amp;amp;= \displaystyle\sum\limits_{j=0}^k x^j + x^{k+1}\\
&amp;amp;= \frac {1-x^{k+1}}{1-k} +   {x^{k+1}}   \text{             by the induction hypothesis}\\
&amp;amp;=  \frac {1-x^{k+1}}{1-x} +  \frac {x^{k+1}*({1-x})}{1-x}\\
&amp;amp;=\frac{1-x^{k+1}+x^{k+1}-x^{k+1+1}}{1-x}\\
&amp;amp;=\frac{1-x^{k+2}}{1-x}.\\
\end{align*}. &lt;/p&gt;&lt;script type= "text/javascript"&gt;
    if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) {
        var mathjaxscript = document.createElement('script');
        mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#';
        mathjaxscript.type = 'text/javascript';
        mathjaxscript.src = 'https:' == document.location.protocol
                ? 'https://c328740.ssl.cf1.rackcdn.com/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML'
                : 'http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML';
        mathjaxscript[(window.opera ? "innerHTML" : "text")] =
            "MathJax.Hub.Config({" +
            "    config: ['MMLorHTML.js']," +
            "    TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'AMS' } }," +
            "    jax: ['input/TeX','input/MathML','output/HTML-CSS']," +
            "    extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js']," +
            "    displayAlign: 'center'," +
            "    displayIndent: '0em'," +
            "    showMathMenu: true," +
            "    tex2jax: { " +
            "        inlineMath: [ ['$','$'] ], " +
            "        displayMath: [ ['$$','$$'] ]," +
            "        processEscapes: true," +
            "        preview: 'TeX'," +
            "    }, " +
            "    'HTML-CSS': { " +
            "        styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'black ! important'} }" +
            "    } " +
            "}); ";
        (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript);
    }
&lt;/script&gt;
</content><category term="math"></category></entry><entry><title>Convex Optimization #1</title><link href="http://mattobrien.me/convex-optimization-1.html" rel="alternate"></link><published>2015-02-08T00:00:00-08:00</published><updated>2015-02-08T00:00:00-08:00</updated><author><name>Matt O'Brien</name></author><id>tag:mattobrien.me,2015-02-08:/convex-optimization-1.html</id><summary type="html">&lt;p&gt;Convext Optimization proof #1&lt;/p&gt;</summary><content type="html">&lt;p&gt;I don't think this is an exceptionally groundbreaking proof, but I was going through some papers from when I took &lt;a href="http://bulletin.sfsu.edu/sfstatebulletin/courses/40444"&gt;mathematical modeling&lt;/a&gt; some time ago.&lt;/p&gt;
&lt;h3&gt;Show from first principles that if $f^1$, $f^2$,...,$f^k$ : $\mathbb{R^n} \rightarrow \mathbb{R}$ are convex (concave) functions with the same domain, and if $\omega_1$,...,$\omega_k$ are non-negative scalars, then the function $\omega_1 f^1 +$...$+ \omega_k f^k$ is also convex (concave).&lt;/h3&gt;
&lt;p&gt;Given $f^1$, $f^2$,...,$f^k$ as convex functions and $\omega_1$,...,$\omega_k$ as non-negative scalars, we need to show that $\omega_1 f^1 +$...$+ \omega_k f^k$ is also convex; that is, $\sum_{i = 1}^k \omega_i f_i$ is a convex function.&lt;/p&gt;
&lt;p&gt;Using first principles, we consider a linear combination $\lambda x + (1 - \lambda)y$ where $\lambda \in [0, 1]$, $x, y \in $ the domain of all $f^k$.&lt;/p&gt;
&lt;p&gt;$$\begin{align*}
f(\lambda x + (1 - \lambda)y &amp;amp;= \sum_{i=1}^k \omega_i f_i (\lambda x + (1 - \lambda )y) 
\\ &amp;amp;\leq \sum_{i=1}^k \omega_i (\lambda f_i (x) + (1- \lambda) f_i(y)) 
\\ &amp;amp;= \lambda \sum_{i =1}^k \omega_i f_i(x) = (1 - \lambda) \sum_{i =1}^k \omega f_i(y)
\\ &amp;amp;= \lambda f(x) + (1 - \lambda) f(x).
\end{align*}$$&lt;/p&gt;
&lt;p&gt;Thus we have shown that convexity holds under this operation.&lt;/p&gt;&lt;script type= "text/javascript"&gt;
    if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) {
        var mathjaxscript = document.createElement('script');
        mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#';
        mathjaxscript.type = 'text/javascript';
        mathjaxscript.src = 'https:' == document.location.protocol
                ? 'https://c328740.ssl.cf1.rackcdn.com/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML'
                : 'http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML';
        mathjaxscript[(window.opera ? "innerHTML" : "text")] =
            "MathJax.Hub.Config({" +
            "    config: ['MMLorHTML.js']," +
            "    TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'AMS' } }," +
            "    jax: ['input/TeX','input/MathML','output/HTML-CSS']," +
            "    extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js']," +
            "    displayAlign: 'center'," +
            "    displayIndent: '0em'," +
            "    showMathMenu: true," +
            "    tex2jax: { " +
            "        inlineMath: [ ['$','$'] ], " +
            "        displayMath: [ ['$$','$$'] ]," +
            "        processEscapes: true," +
            "        preview: 'TeX'," +
            "    }, " +
            "    'HTML-CSS': { " +
            "        styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'black ! important'} }" +
            "    } " +
            "}); ";
        (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript);
    }
&lt;/script&gt;
</content><category term="math"></category></entry><entry><title>Lebesgue measure #2</title><link href="http://mattobrien.me/lebesgue-measure-2.html" rel="alternate"></link><published>2014-07-17T00:00:00-07:00</published><updated>2014-07-17T00:00:00-07:00</updated><author><name>Matt O'Brien</name></author><id>tag:mattobrien.me,2014-07-17:/lebesgue-measure-2.html</id><summary type="html">&lt;p&gt;Lebesgue measure #2&lt;/p&gt;</summary><content type="html">&lt;p&gt;This is a proof of basic closure-type properties with respect to functions of bounded variation. I had the chance to study these when I took a class by Dr. Ovchinnikov, who was in the process of writing a &lt;a href="http://www.amazon.com/Measure-Integral-Derivative-Lebesgues-Universitext/dp/1461471958"&gt;book&lt;/a&gt; on the subject at the time.  &lt;/p&gt;
&lt;h3&gt;Show that the sum, difference and product of two BV-functions is a BV-function.&lt;/h3&gt;
&lt;p&gt;Let  $f$, $g$, be two BV functions over $[a, b]$.  Define a partition, $P = {x_i = 1 \leq i \leq n }.$  Then,  &lt;/p&gt;
&lt;p&gt;$
\begin{align*}
\sum_{i = 1}^{n} | (f + g )(x_i) - (f + g)(x_{i-1}) | &amp;amp;= \sum_{i = 1}^{n} | { f(x_i) + g(x_i) } - { f(x_{i - 1}) + g(x_{i-1}) } | \\  &amp;amp;\leq \sum_{i = 1}^{n} | f(x_i) - f(x_{i - 1}) | + \sum_{i = 1}^{n} | g(x_i) - g(x_{i - 1})|
\\  &amp;amp;\leq  V(f, P) + V(g, P)
\end{align*}$&lt;/p&gt;
&lt;p&gt;$\Rightarrow V(f + g, P) \leq V(f, P) + V(g, P) \leq V(f, P) + V(g, P)
\Rightarrow V(f + g, P) \leq V(f, P) + V(g, P).
$  &lt;/p&gt;
&lt;p&gt;Thus, $(f + g)$ is a function of bounded variation.&lt;/p&gt;
&lt;p&gt;To show that $(f - g)$ is of bounded variation, the proof is the same and $V(f - g) \leq V(f) + V(g)$&lt;/p&gt;
&lt;p&gt;To show that the product of two functions of bounded variation is also of bounded variation, notice that both $f$ and $g$ are bounded, and thus there exists $K \in \mathbb{N}$ such that
$|f(x)| \leq k, |g(x) | \leq k, \forall x \in P$.&lt;/p&gt;
&lt;p&gt;Thus, 
$$\begin{align*}
\sum_{i = 1}^{n} | (fg)(x_i) - (fg)(x_{i - 1}|&amp;amp;= \sum_{i = 1}^{n} | f(x_i)g(x_i) - f(x_{i -1})g(x{i - 1})|
\\ &amp;amp;= \sum_{i = 1}^{n} |f(x_i) {g(x_i) - g(x_{i - 1}) } + g(x_{i-1}) { f(x_i) - f(x_{i - 1}) } |
\\ &amp;amp;\leq \sum_{i = 1}^{n} { | f(x_i) | |g(x_i)  - g(x_{i - 1}) | + | g(x_{i - 1}) | | f(x_i) - f(x_{i - 1}) | }
\\ &amp;amp;\leq k \sum_{i = 1}^{n} |g(x_i) - g(x_{i-1}) | + k \sum_{i = 1}^{n} | f(x_i) - f(x_{i -1})|
\\ &amp;amp;\leq k V(g) + kV(f).
\end{align*}$$
and so the product of two functions of bounded variation is also of bounded variation.&lt;/p&gt;&lt;script type= "text/javascript"&gt;
    if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) {
        var mathjaxscript = document.createElement('script');
        mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#';
        mathjaxscript.type = 'text/javascript';
        mathjaxscript.src = 'https:' == document.location.protocol
                ? 'https://c328740.ssl.cf1.rackcdn.com/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML'
                : 'http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML';
        mathjaxscript[(window.opera ? "innerHTML" : "text")] =
            "MathJax.Hub.Config({" +
            "    config: ['MMLorHTML.js']," +
            "    TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'AMS' } }," +
            "    jax: ['input/TeX','input/MathML','output/HTML-CSS']," +
            "    extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js']," +
            "    displayAlign: 'center'," +
            "    displayIndent: '0em'," +
            "    showMathMenu: true," +
            "    tex2jax: { " +
            "        inlineMath: [ ['$','$'] ], " +
            "        displayMath: [ ['$$','$$'] ]," +
            "        processEscapes: true," +
            "        preview: 'TeX'," +
            "    }, " +
            "    'HTML-CSS': { " +
            "        styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'black ! important'} }" +
            "    } " +
            "}); ";
        (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript);
    }
&lt;/script&gt;
</content><category term="math"></category></entry><entry><title>Word frequencies for web pages</title><link href="http://mattobrien.me/word-frequencies-for-web-pages.html" rel="alternate"></link><published>2014-06-20T00:00:00-07:00</published><updated>2014-06-20T00:00:00-07:00</updated><author><name>Matt O'Brien</name></author><id>tag:mattobrien.me,2014-06-20:/word-frequencies-for-web-pages.html</id><summary type="html">&lt;p&gt;Using a few select Python packages, it's fairly painless to find top word counts&lt;/p&gt;</summary><content type="html">&lt;p&gt;This script will take any particular webpage (in this case, the wikipedia page for Machine Learning) and do a quick a dirty scrape then count of the words on the page. It is not particularly sophisticated and can be further customized and improved for whatever your purpose may be. &lt;/p&gt;
&lt;pre&gt;&lt;code&gt;:::python
import urllib
from bs4 import BeautifulSoup
from nltk.corpus import stopwords
from collections import Counter

## read contents from webpage
f = urllib.urlopen('http://en.wikipedia.org/wiki/Machine_learning')
contents = f.read()

# create BS object
soup = BeautifulSoup(contents)

# clean text: lower case, remove trailing commas, remove words less than 2 characters long 
mytext = soup.get_text()
mytext = mytext.lower()
mytext = mytext.replace(",", " ")
mytext = ' '.join(word for word in mytext.split() if len(word)&amp;gt;2)

# remove stopwords
filtered_words = [w for w in mytext.split() if not w in stopwords.words('english')]

# return counts using counter object
mycounts = Counter(filtered_words)
print mycounts.most_common(10)
&lt;/code&gt;&lt;/pre&gt;</content><category term="text"></category><category term="python"></category></entry><entry><title>pbinom for binomial distribution in R</title><link href="http://mattobrien.me/pbinom-for-binomial-distribution-in-r.html" rel="alternate"></link><published>2014-06-05T00:00:00-07:00</published><updated>2014-06-05T00:00:00-07:00</updated><author><name>Matt O'Brien</name></author><id>tag:mattobrien.me,2014-06-05:/pbinom-for-binomial-distribution-in-r.html</id><summary type="html">&lt;p&gt;A quick pop quiz to test your memory for working with probability distributions in R&lt;/p&gt;</summary><content type="html">&lt;p&gt;I love R. But it does has some things that are a bit irksome.  For example, I have found it somewhat difficult to remember which prefix corresponds to which function, when working with distributions. &lt;/p&gt;
&lt;p&gt;Here is a quick quiz:  &lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Given a binomial distribution:&lt;/strong&gt;&lt;br /&gt;
&lt;strong&gt;dbinom ---&amp;gt; ?&lt;/strong&gt;&lt;br /&gt;
&lt;strong&gt;pbinom ---&amp;gt;  ?&lt;/strong&gt;  &lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;probability mass function&lt;br /&gt;
cumulative distribution function&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;cumulative distribution function&lt;br /&gt;
 probability mass function  &lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;em&gt;Answer:  1&lt;/em&gt;  &lt;/p&gt;
&lt;p&gt;I am temped to choose 2, since pbinom feels like it should correspond with pdf.  After all, ‘p’ is the first initial of the first word in the phrase “probability mass function.”  However, that is not the case.&lt;/p&gt;</content><category term="statistics"></category><category term="R"></category></entry><entry><title>Lebesgue measure #1</title><link href="http://mattobrien.me/lebesgue-measure-1.html" rel="alternate"></link><published>2014-05-29T00:00:00-07:00</published><updated>2014-05-29T00:00:00-07:00</updated><author><name>Matt O'Brien</name></author><id>tag:mattobrien.me,2014-05-29:/lebesgue-measure-1.html</id><summary type="html">&lt;p&gt;Lebesgue measure #1&lt;/p&gt;</summary><content type="html">&lt;p&gt;Here is a fun proof that illuminates an important property of Lebesgue measure.  Note that the function $m()$ refers to measure.&lt;/p&gt;
&lt;h3&gt;Let $X$ be a closed subset of $[0,1]$ such that $m(X) = 1$.  Prove that $X = [0, 1]$.&lt;/h3&gt;
&lt;p&gt;Let $X$ be closed subset of $[0,1]$ such that $m(X) = 1$.  We need to show that $X= [0,1]$.  Let $a=inf(X)$ and let $b=sup(X)$.  Suppose, by contradiction, that $X \neq [0, 1]$.  Then, there are 3 cases for which $X=[0, 1]$.  &lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Case 1:&lt;/strong&gt;  $a &amp;gt; 0$.  By definition of measure, $m(X) = (b -a) - m([a, b]\backslash X) = 1$, but $(b - a) &amp;lt; 1$ and $m(X)$ cannot equal $1$.  &lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Case 2:&lt;/strong&gt;  $b &amp;gt; 1$.  Again, be definition of measure, we fnd that $(b - a) &amp;lt; 1$ and $m(X)$ cannot equal $1$.  &lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Case 3:&lt;/strong&gt;  $a = 0$, and b = $0$, since $b - a = 1$, and since $X = [0, 1]$, then $[0, 1]$ \ $X = 0$ which implies that $X$ must be equal to $[0, 1]$.&lt;/p&gt;&lt;script type= "text/javascript"&gt;
    if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) {
        var mathjaxscript = document.createElement('script');
        mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#';
        mathjaxscript.type = 'text/javascript';
        mathjaxscript.src = 'https:' == document.location.protocol
                ? 'https://c328740.ssl.cf1.rackcdn.com/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML'
                : 'http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML';
        mathjaxscript[(window.opera ? "innerHTML" : "text")] =
            "MathJax.Hub.Config({" +
            "    config: ['MMLorHTML.js']," +
            "    TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'AMS' } }," +
            "    jax: ['input/TeX','input/MathML','output/HTML-CSS']," +
            "    extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js']," +
            "    displayAlign: 'center'," +
            "    displayIndent: '0em'," +
            "    showMathMenu: true," +
            "    tex2jax: { " +
            "        inlineMath: [ ['$','$'] ], " +
            "        displayMath: [ ['$$','$$'] ]," +
            "        processEscapes: true," +
            "        preview: 'TeX'," +
            "    }, " +
            "    'HTML-CSS': { " +
            "        styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'black ! important'} }" +
            "    } " +
            "}); ";
        (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript);
    }
&lt;/script&gt;
</content><category term="math"></category></entry><entry><title>Muay Thai kick to the body</title><link href="http://mattobrien.me/muay-thai-kick-to-the-body.html" rel="alternate"></link><published>2014-05-21T00:00:00-07:00</published><updated>2014-05-21T00:00:00-07:00</updated><author><name>Matt O'Brien</name></author><id>tag:mattobrien.me,2014-05-21:/muay-thai-kick-to-the-body.html</id><summary type="html">&lt;p&gt;Biomechanics of a body kick&lt;/p&gt;</summary><content type="html">&lt;p&gt;My interest in human movement led me to doing some 3D modeling. I purchased an 8 strobe Optitrack system and asked an amateur fighter to put on the reflective suit and demonstrate his body kick. After I captured the movement, I discussed some of the findings in this animation.  &lt;/p&gt;
&lt;p&gt;The most interesting thing about the clip is the overhead view. I realized that nobody has ever considered what a kick looks like from the top: when you observe it from this position, it quickly becomes clear that the kick is generated from the top down -- the shoulder girdle clearly rotates first and reaches it's peak torque prior to the completion of the rotation of the pelvis. If you go train in muay thai, it's not uncommon to hear a reguritated coaching dogma, namely, "Turn your hip over", which is somewhat true but really just betrays a lack of ability to consider the kick as a movement that is fundamentally a top-down kinetic chain.   &lt;/p&gt;
&lt;p&gt;&lt;a href="http://www.youtube.com/watch?feature=player_embedded&amp;v=OPdRX5Poqo4
" target="_blank"&gt;&lt;img src="http://img.youtube.com/vi/OPdRX5Poqo4/0.jpg" 
alt="muay thai kick tutorial" width="240" height="180" border="10" /&gt;&lt;/a&gt;&lt;/p&gt;</content><category term="sport science"></category></entry><entry><title>Visualization in RShiny</title><link href="http://mattobrien.me/visualization-in-rshiny.html" rel="alternate"></link><published>2014-05-18T00:00:00-07:00</published><updated>2014-05-18T00:00:00-07:00</updated><author><name>Matt O'Brien</name></author><id>tag:mattobrien.me,2014-05-18:/visualization-in-rshiny.html</id><summary type="html">&lt;p&gt;Visualizing and interacting with data science jobs in the United States&lt;/p&gt;</summary><content type="html">&lt;p&gt;Using data from a popular job search website, I gathered a set of 2036 jobs for positions open for individuals proficient in data science. The motivation for this project is to visualize where data science jobs are in the United States as well as how much they pay.  &lt;/p&gt;
&lt;p&gt;You can find this visualization hosted &lt;a href="https://mattobriendotme.shinyapps.io/shinyapp/"&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;h1&gt;THE PROJECT:&lt;/h1&gt;
&lt;p&gt;Using data from a popular job search website, I gathered a set of 2036 jobs for positions open for individuals proficient in data science.   &lt;/p&gt;
&lt;p&gt;The fields in the data consisted of job description, company name, salary, city, state and zipcode.  &lt;/p&gt;
&lt;p&gt;The motivation for this project is to visualize where data science jobs are in the United States as well as how much they pay.  &lt;/p&gt;
&lt;h1&gt;VISUALIZATION #1: COUNTRY MAP&lt;/h1&gt;
&lt;p&gt;The first visualization is of a map of the continental United States.  The idea here was to obtain a broad overview of which areas in which states have the most jobs.  &lt;/p&gt;
&lt;p&gt;You can interact with this map in a number of ways:  &lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Select which states you want to see and don't want to see  &lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Use a slider to narrow the results down to jobs that pay within a specific salary range&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;You can manage overplotting by adjusting the alpha value&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;You can mange overplotting by introducing jitter to the points&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The data began as zipcode information.  Using the &lt;code&gt;library(zipcode)&lt;/code&gt; package, the zipcode data was transformed into longitude and latitude coordinates.  &lt;/p&gt;
&lt;p&gt;The data showed me that most of the jobs reside in the Bay Area of California.  There aren't many jobs in the Midwest or South, and there are a good amount of jobs in Washington and Texas.  &lt;/p&gt;
&lt;p&gt;Originally I was using red dots (it looked like the map had chicken pox).  I changed to circles and changed the color to green.  I also added state initials, even though it required me to post a question on StackOverflow which you can view &lt;a href="http://stackoverflow.com/questions/23447760/include-borders-and-state-abbreviations-when-using-the-map-function-with-the-map"&gt;here&lt;/a&gt;.  &lt;/p&gt;
&lt;p&gt;This map has good data density and data-to-ink ratio.  The lie factor is increased when the jitter is used, considerably.  Sometimes, some points in Washington jump into Canada.  &lt;/p&gt;
&lt;p&gt;The interactivity enhances the visualization in the sense that it makes the locations visible and simple to view.  &lt;/p&gt;
&lt;p&gt;I also am happy all four methods of interaction.  Here is a screenshot of the visualization with and without jitter:  &lt;/p&gt;
&lt;p&gt;&lt;img alt="vis" src="https://github.com/mobbSF/msan622/blob/master/final-project/001.png?raw=true" /&gt;&lt;/p&gt;
&lt;p&gt;One problem is the inability to adjust all states.  I chose a checkbox for the States, and as much as I wanted to, I wasn't able include all 48 states due, simply, to lack of space.  A better control would have allowed me to subset on certain important States.  To me, this is a major, major flaw in my visualization.  The question remains, how can a user intuitively and easily select any combination of 48 states when there is limited space on the graphic?  My solution is to remove control from the user, which is not ideal.  &lt;/p&gt;
&lt;h1&gt;VISUALIZATION #2:  CLOROPLETH&lt;/h1&gt;
&lt;p&gt;This map is a cloropleth, which is somewhat of a combination of a heatmap and geographic map.  &lt;/p&gt;
&lt;p&gt;&lt;img alt="vis" src="https://github.com/mobbSF/msan622/blob/master/final-project/002.png?raw=true" /&gt;&lt;/p&gt;
&lt;p&gt;When you think of a cloropleth, or even a heatmap in general, trying to incorporate interactivity can be a difficult task.  After all, a heatmap pretty much shows everything...perhaps the granularity of binning can be adjusted, but what else?  &lt;/p&gt;
&lt;p&gt;I chose to approach this in a way that made sense to me.  The way this map works, is the view all of the states together to see how they relate to each other.  Now, we slow remove states, one by one, and each time, watch the choropleth regenerate, and rescale itself to show how the remaining states are distributed.  So, if you didn't want to live in CA, you could remove it, and see a "new" heatmap, based on the remaining parts of the country.  &lt;/p&gt;
&lt;p&gt;Here, the colors are mapped to the total sum of all salaries.  For example, there is about 5 million dollars worth of salary to be earned in California, which makes the color dark green.  &lt;/p&gt;
&lt;p&gt;This plot is really another attempt to see how many jobs in each state exist.  The first visualization, naturally suffers from intense overplotting.  The choropleth generalizes the jobs to fit within a state, not just a tiny point surrounded by a hollow circle.  In retrospect, this plot is a little more general in nature than plot 1, and maybe I should have switched the order of these plots to guarantee that the plots are in general --&amp;gt; specific order.   &lt;/p&gt;
&lt;p&gt;I like the creative way to burrow deep into specific combinations of jobs, depending on which states you choose to exclude.  Once you get used to this idea, it makes a lot of sense.  &lt;/p&gt;
&lt;p&gt;I had to use the &lt;code&gt;choroplethr&lt;/code&gt; package, which is so different than the first plot.  Making the two of them match was difficult.  Even matching the colors (which is still imperfect) was a major challenge and required me to get creative.  &lt;/p&gt;
&lt;h1&gt;VISUALIZATION #3: SINGLE STATE BUBBLEPLOT&lt;/h1&gt;
&lt;p&gt;Visualization 3 moves us into looking at single states, where we can see more clearly exactly where the jobs reside.  Here is an example of just one of the states you can zoom in on, Washington:  &lt;/p&gt;
&lt;p&gt;&lt;img alt="vis" src="https://github.com/mobbSF/msan622/blob/master/final-project/003.png?raw=true" /&gt;&lt;/p&gt;
&lt;p&gt;Here, we have:  &lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Selecting the particular state in a dropdown menu  &lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Adjusting salary as in the first map  &lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Adjusting alpha  &lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Adding jitter &lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The data was encoded in the same way as the first plot, just further subsetted by state, and more importantly, salary was mapped to the size of the circular point.  &lt;/p&gt;
&lt;p&gt;This visualization is nice, since now we get a better feel for which specific areas these jobs are in.  As the visualizations go, they attempt to get more and granular in nature, and this plot makes a big jump in that direction.  Also, it is really important to realize this is a bubbleplot, and now we can see the salary related to specific jobs, which was prior not easy to see on such an individualized basis.  &lt;/p&gt;
&lt;p&gt;Since the states are just simple polygons, they aren't very exciting.  I added some fill as color (grey90) which helped.  &lt;/p&gt;
&lt;p&gt;This plot, due to the lack of color and texture, clearly has a fantastic data to ink ratio. The lie factor is fine and the data density is good too.  In retrospect, I could have removed the jitter option, which would have kept the lie factor down.  I am not convinced that jitter is useful at this level anyways.  It could easily move a job from one city to another.  &lt;/p&gt;
&lt;p&gt;The alpha is always necessary, I suspect, except for sparse states like Kansas where there aren't any overlapping jobs.  The ability to zoom in by selecting a particular state is crucial.  Jitter, as mentioned prior, isn't exceptionally important.  &lt;/p&gt;
&lt;p&gt;The plot generates single states, which is a somewhat unorthodox way to create a plot.  I like the dropdown menu and I am glad that I was able to make all the plots resize to fill up the space, even though I finally had to post another StackOverflow question &lt;a href="http://stackoverflow.com/questions/23449033/how-to-resize-a-state-when-using-the-map-function-in-the-mapproj-library-in-r"&gt;here&lt;/a&gt;.  &lt;/p&gt;
&lt;p&gt;I originally wanted to find some way to 'grey out' the controls that aren't being used in this plot, since it's hard to even find the dropdown menu way at the bottom.  &lt;/p&gt;
&lt;h1&gt;VISUALIZATION #4: BAR PLOT&lt;/h1&gt;
&lt;p&gt;This chart can be sorted as seen below:  &lt;/p&gt;
&lt;p&gt;&lt;img alt="vis" src="https://github.com/mobbSF/msan622/blob/master/final-project/004.png?raw=true" /&gt;  &lt;/p&gt;
&lt;p&gt;The data was summed and encoded as scalars with which to plot the number of jobs in each state.  &lt;/p&gt;
&lt;p&gt;Strangely enough, a simple bar chart might be the most interesting plot of all 4.  Why? Because, finally, we get a numeric representation of the distribution of jobs out there.  Up until now, we've had to rely on color, shape, and space to do so.  Now, we finally hit the nail on the head and with this bar chart, we can see exactly what the job market looked like at this given time, across the country.  &lt;/p&gt;
&lt;p&gt;Of course ordering in a bar chart is always a good idea when it comes to interactivity (or at least I suspect this is true).  It only takes a glance to see the relationship between the states and how they come together.  &lt;/p&gt;
&lt;p&gt;I was glad that I was able to remove that annoying area between the x and y axis, remove the tickmarks as I wanted, and otherwise to the customary cleanup on ggplot that we've practiced up to now.  &lt;/p&gt;
&lt;p&gt;There is no end to how much work you can put into a good visualization -- this project provided me with lots of appreciation as to how difficult a good vis really is to construct.  For example, was it worth the hours it took to figure out how to give this custom error message?  &lt;/p&gt;
&lt;p&gt;&lt;img alt="vis" src="https://github.com/mobbSF/msan622/blob/master/final-project/005.gif?raw=true" /&gt;  &lt;/p&gt;
&lt;p&gt;Who knows.  But, I also now have more appreciation for why lots of visualizations are hard to read.  This is a large and deep field.  &lt;/p&gt;</content><category term="visualization"></category></entry><entry><title>sentiment prediction with Naive Bayes</title><link href="http://mattobrien.me/sentiment-prediction-with-naive-bayes.html" rel="alternate"></link><published>2014-05-01T00:00:00-07:00</published><updated>2014-05-01T00:00:00-07:00</updated><author><name>Matt O'Brien</name></author><id>tag:mattobrien.me,2014-05-01:/sentiment-prediction-with-naive-bayes.html</id><summary type="html">&lt;p&gt;Predicting positive or negative Amazon movie reviews&lt;/p&gt;</summary><content type="html">&lt;p&gt;This project consists of two sets of labelled text reviews (&lt;a href="https://www.dropbox.com/sh/n2r4e929ahzx84o/AABdDVQ1Rlygs-XkjTytn3bAa"&gt;positive&lt;/a&gt; and &lt;a href="https://www.dropbox.com/sh/scnnjiotbltm2za/AAAGz7NsEoG61ojzgZZQPfV-a"&gt;negative&lt;/a&gt;) for movies.  &lt;/p&gt;
&lt;p&gt;These are used as the training set; the words are split into unigrams, and the words are classified as either positive or negative given their frequencies. &lt;/p&gt;
&lt;p&gt;Once the model is built, the test set is used to help determine the accuracy of the model.  &lt;/p&gt;
&lt;p&gt;This is an early project I did some time ago, please forgive some of the less graceful elements.  &lt;/p&gt;
&lt;p&gt;The algorithm uses these steps:  &lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;For each iteration&lt;br /&gt;
(a) Randomly divide your data in training and testing using 1/3 for
testing and 2/3 for training.&lt;br /&gt;
(b) Use the training set to estimate the parameters $P(w|c)$ and $P(c)$ as per the naive bayes statement&lt;br /&gt;
(c) For every document in the training set use the equation $$c^{*}=argmax_{c}log(P(c)) + \sum_{i=1}^{M}n_{i}(d) * log(P(w_{i}|c))$$ to compute $P(c|d)$ and predict the class c.&lt;br /&gt;
(d) Compute the accuracy of the testing set.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Do at least 3 iterations to compute the average accuracy as your performance metric.  &lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;The output will print results for each iteration, giving key metrics like this:&lt;/p&gt;
&lt;p&gt;iteration 1:&lt;br /&gt;
    num pos test_docs:333&lt;br /&gt;
    num pos training docs:667&lt;br /&gt;
    num pos correct_docs:267&lt;br /&gt;
    num neg test_docs:331&lt;br /&gt;
    num neg training_docs:669&lt;br /&gt;
    num neg correct_docs:261&lt;br /&gt;
    accuracy:79%&lt;br /&gt;
iteration 2:&lt;br /&gt;
    ...&lt;br /&gt;
iteration 3:&lt;br /&gt;
    ...&lt;br /&gt;
ave_accuracy:80.3%  &lt;/p&gt;
&lt;p&gt;Make sure to include the command line parameters &lt;code&gt;python naive-bayes.py -d my_directory&lt;/code&gt; where &lt;code&gt;my_directory&lt;/code&gt; is the path to the directory that holds the positive and negative reviews along with the python script.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;:::python
#!/usr/bin/env python
import argparse
import os
import random
import math
import collections

def parseArgument():
    ### Code for parsing arguments
    parser = argparse.ArgumentParser(description='Parsing a file.')
    parser.add_argument('-d', nargs=1, required=True)
    args = vars(parser.parse_args())
    return args 
###  This function takes the directory path and divides the file names found in the pos / neg directories
###  into the proper proportions, stored into a dict named 'D'.
def CreateD(directory):
    pos_train = []
    pos_test = []
    neg_train = []
    neg_test = []
    pos = directory + '/pos'
    neg = directory + '/neg'
    pos_names = os.listdir(pos)
    neg_names = os.listdir(neg)
    random.shuffle(pos_names)
    random.shuffle(neg_names)
    while pos_names:
        pos_train.append(pos_names.pop())
        if pos_names:
            pos_train.append(pos_names.pop())
        if pos_names:
            pos_test.append(pos_names.pop())
    while neg_names:
        neg_train.append(neg_names.pop())
        if neg_names:
            neg_train.append(neg_names.pop())
        if neg_names:
            neg_test.append(neg_names.pop())
    fileDict = {}
    fileDict["pos_train"] = pos_train
    fileDict["pos_test"] = pos_test
    fileDict["neg_train"] = neg_train
    fileDict["neg_test"] = neg_test
    return fileDict

### This function used a counter object to count the number of documents in the class 'pos' or 'neg'.  This is used
### for printing summary statistics at the end.
def CountDocsInClass(directory,subdir,file_list):
    cntr = collections.Counter()
    for file in file_list:
        f = open(directory+'/'+subdir+'/'+file)#open each File
        cntr = cntr + collections.Counter([t for t in (f.read()).split() if not t in stopWords])#add word counts to counter object
        f.close()#Close each File
    return cntr

def main():
    args = parseArgument()
    directory = args['d'][0]
    # variable for calculating average accuracy
    tot_acc = 0
    # Iterations
    for step in range(1,4):

### Here is the training code:
### First we create the dictionary of filenames using the CreateD function.
        file_dict = CreateD(directory)

### Here we count the number of documents in the 'pos' and 'neg' class using the CountDocsInClass function.
        positive_counter = CountDocsInClass(directory,'pos',file_dict['pos_train'])
        negative_counter = CountDocsInClass(directory,'neg',file_dict['neg_train'])
### These 2 lines find a total count in the counters for each class.
        tot_cnt_pos=float(sum(positive_counter.values()))
        tot_cnt_neg=float(sum(negative_counter.values()))
### We create V, as specified in the Vocabulary list
        V = set(positive_counter.keys()+ negative_counter.keys())
### The final_dict will hold the conditional probabilities for each t in V
        final_dict = {}
        for t in V:
            final_dict[t] = {'pos':(positive_counter[t]+1.0)/(tot_cnt_pos+len(V)+1),'neg':(negative_counter[t]+1.0)/(tot_cnt_neg+len(V)+1)}
### calculating prior probabilities for each class
        pos_prior = len(file_dict['pos_train'])/float(len(file_dict['pos_train']) + float(len(file_dict['neg_train'])))
        neg_prior = len(file_dict['neg_train'])/float(len(file_dict['pos_train']) + float(len(file_dict['neg_train'])))
### This code is for the Testing part of the Naive Bayes algorithm
### We create a list of classes
        C = ['pos','neg']
### initializing filescore dictionary to keep track of test data - has the test file as key and four other associated
        # parameters namely:
        #                   orig    -  is file originally +ve or -ve
        #                   pos     -  sum of log probs for +ve class
        #                   neg     -  sum of log probs for +ve class
        #                   output  -  output file classification after comparing 'pos' and 'neg'
        filescore = {}
        # for all test files combined run loop
        for file in (file_dict['pos_test']+file_dict['neg_test']):
            # initialize  the file dictionary within filescore dictionary
            filescore[file] = {}
            # populate 'orig' attribute for each file i.e. filescore[file]['orig']
            if file in file_dict['pos_test']:
                f = open(directory+'/pos/'+file)#open each File
                filescore[file]['orig'] = 'pos'
            else:
                f = open(directory+'/neg/'+file)#open each File
                filescore[file]['orig'] = 'neg'
            # extract all words for the given file into t_list after removing stopwords
            t_list = [t for t in (f.read()).split() if not t in stopWords]
            # within a file run the below loop for each class to sum the log probabilities for each class
            for clss in C:
                # initializing score variable with prior probbabilities
                if (clss == 'pos'):
                    score = math.log(pos_prior)
                else:
                    score = math.log(neg_prior)
### The code below takes logs as per pseudocode
                for t in t_list:
                    if final_dict.has_key(t):
                        score = score + math.log(final_dict[t][clss])
                    # handling unknown words in test file
                    else:
                        if clss=='pos':
                            score = score + (1/(tot_cnt_pos+len(V)+1))
                        if clss=='neg':
                            score = score + (1/(tot_cnt_neg+len(V)+1))
                filescore[file][clss] = score
###   Counting the results
            if (filescore[file]['pos'] &amp;gt; filescore[file]['neg']):
                filescore[file]['output'] = 'pos'
            else:
                filescore[file]['output'] = 'neg'
            f.close()

###   Create some counters to track the numbers of successes for each class
        count_positive_success = 0
        count_negative_success = 0
        for fl in filescore:
            if ((filescore[fl]['orig'] == 'pos') and (filescore[fl]['output'] == filescore[fl]['orig'])):
                count_positive_success = count_positive_success + 1
            if ((filescore[fl]['orig'] == 'pos') and (filescore[fl]['output'] == filescore[fl]['orig'])):
                count_negative_success = count_negative_success + 1
### Print results to screen
        print "iteration ",step,":"
        print "num_pos_test_docs:",len(file_dict['pos_test'])
        print "num_pos_training_docs:",len(file_dict['pos_train'])
        print "num_pos_correct_docs:",count_positive_success
        print "num_neg_test_docs:",len(file_dict['neg_test'])
        print "num_neg_training_docs:",len(file_dict['neg_train'])
        print "num_neg_correct_docs:",count_negative_success
        acc = 100 * (count_positive_success+count_negative_success)/(len(file_dict['pos_test'])+len(file_dict['neg_test']))
        print "accuracy:",acc,'%'
        tot_acc = tot_acc + acc
    print "ave_accuracy:",tot_acc/3.0

main()
&lt;/code&gt;&lt;/pre&gt;&lt;script type= "text/javascript"&gt;
    if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) {
        var mathjaxscript = document.createElement('script');
        mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#';
        mathjaxscript.type = 'text/javascript';
        mathjaxscript.src = 'https:' == document.location.protocol
                ? 'https://c328740.ssl.cf1.rackcdn.com/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML'
                : 'http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML';
        mathjaxscript[(window.opera ? "innerHTML" : "text")] =
            "MathJax.Hub.Config({" +
            "    config: ['MMLorHTML.js']," +
            "    TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'AMS' } }," +
            "    jax: ['input/TeX','input/MathML','output/HTML-CSS']," +
            "    extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js']," +
            "    displayAlign: 'center'," +
            "    displayIndent: '0em'," +
            "    showMathMenu: true," +
            "    tex2jax: { " +
            "        inlineMath: [ ['$','$'] ], " +
            "        displayMath: [ ['$$','$$'] ]," +
            "        processEscapes: true," +
            "        preview: 'TeX'," +
            "    }, " +
            "    'HTML-CSS': { " +
            "        styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'black ! important'} }" +
            "    } " +
            "}); ";
        (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript);
    }
&lt;/script&gt;
</content><category term="python"></category></entry><entry><title>Set Theory #1</title><link href="http://mattobrien.me/set-theory-1.html" rel="alternate"></link><published>2014-04-10T00:00:00-07:00</published><updated>2014-04-10T00:00:00-07:00</updated><author><name>Matt O'Brien</name></author><id>tag:mattobrien.me,2014-04-10:/set-theory-1.html</id><summary type="html">&lt;p&gt;Set theory proof #1&lt;/p&gt;</summary><content type="html">&lt;p&gt;A great little proof that is simple and a nice way to practice your $\LaTeX$.&lt;/p&gt;
&lt;h3&gt;Demonstrate that this is a false claim: $C \subset A$ and $C \subset B \Leftrightarrow C \subset (A \cup B)$.&lt;/h3&gt;
&lt;p&gt;First we examine the righthand implication, that is:&lt;br /&gt;
$C \subset A$ and $C \subset B \rightarrow C \subset (A \cup B)$.   &lt;/p&gt;
&lt;p&gt;Let $x \in C $. Then $x \in A $. So, $x \in A$ or $x \in B$. Hence $x \in (A \cup B)$.  &lt;/p&gt;
&lt;p&gt;Second, we examine the lefthand implication, that is
$C \subset A$ and $C \subset B \leftarrow C \subset (A \cup B)$.  &lt;/p&gt;
&lt;p&gt;This second statement is false as demonstrated by the following simple counterexample:  &lt;/p&gt;
&lt;p&gt;Choose:  &lt;/p&gt;
&lt;p&gt;$A = [1, 2]$, $B =[1, 3]$, and $C =[2, 3]$.  &lt;/p&gt;
&lt;p&gt;Then, $A\cup B =[1,2,3]$.&lt;br /&gt;
Hence, $C \subset A \cup B$, but, $C \not\subset A$, and $C \not\subset B$.&lt;/p&gt;&lt;script type= "text/javascript"&gt;
    if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) {
        var mathjaxscript = document.createElement('script');
        mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#';
        mathjaxscript.type = 'text/javascript';
        mathjaxscript.src = 'https:' == document.location.protocol
                ? 'https://c328740.ssl.cf1.rackcdn.com/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML'
                : 'http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML';
        mathjaxscript[(window.opera ? "innerHTML" : "text")] =
            "MathJax.Hub.Config({" +
            "    config: ['MMLorHTML.js']," +
            "    TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'AMS' } }," +
            "    jax: ['input/TeX','input/MathML','output/HTML-CSS']," +
            "    extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js']," +
            "    displayAlign: 'center'," +
            "    displayIndent: '0em'," +
            "    showMathMenu: true," +
            "    tex2jax: { " +
            "        inlineMath: [ ['$','$'] ], " +
            "        displayMath: [ ['$$','$$'] ]," +
            "        processEscapes: true," +
            "        preview: 'TeX'," +
            "    }, " +
            "    'HTML-CSS': { " +
            "        styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'black ! important'} }" +
            "    } " +
            "}); ";
        (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript);
    }
&lt;/script&gt;
</content><category term="math"></category></entry><entry><title>using Pi as a pseudorandom number generator</title><link href="http://mattobrien.me/using-pi-as-a-pseudorandom-number-generator.html" rel="alternate"></link><published>2014-03-05T00:00:00-08:00</published><updated>2014-03-05T00:00:00-08:00</updated><author><name>Matt O'Brien</name></author><id>tag:mattobrien.me,2014-03-05:/using-pi-as-a-pseudorandom-number-generator.html</id><summary type="html">&lt;p&gt;Can the digits of Pi be used as a pesudorandom number generator?&lt;/p&gt;</summary><content type="html">&lt;p&gt;The digits of transcendental numbers such as $\pi = 3.14159 \dots$ pass many tests for randomness. So, take the first 1000 digits and use it to simulate 500 tosses of a coin, taking even digits to represent Heads and odd digits to represent Tails. Is this simulation consistent with 500 independent tosses of a fair coin?  &lt;/p&gt;
&lt;p&gt;First, get the digits &lt;a href="https://www.dropbox.com/s/purpzv0tzdsca08/PI.txt"&gt;here:&lt;/a&gt;, download the file and read it into &lt;code&gt;R&lt;/code&gt; and call it PI  &lt;/p&gt;
&lt;p&gt;&lt;code&gt;PI &amp;lt;- read.table("\your_path\PI.txt",quote="\"")  
pi_digits &amp;lt;- unlist(strsplit(as.character(PI[1,]),""))[2:1000]&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;The proportion of even numbers in the first 1000 digits of pi is found as follows:  &lt;/p&gt;
&lt;p&gt;&lt;code&gt;is_even &amp;lt;- function(x) x %% 2 == 0  
is_odd &amp;lt;- function(x) x %% 2 != 0  
pi_digits &amp;lt;- as.numeric(pi_digits)  
indices_for_evens &amp;lt;- pi_digits[is_even(pi_digits)]  
indices_for_odds &amp;lt;- pi_digits[is_odd(pi_digits)]  
length(indices_for_evens) / 1000&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;Now we will do a t-test to see if there is a significant difference between the probability of getting a heads on a coin flip, and getting an even digit of pi, by seeing if there is any significant differene between the mean for a coin flip (0.50) and the mean of getting an even (0.516). We should expect that these aren't significantly different since they are so close:  &lt;/p&gt;
&lt;p&gt;&lt;code&gt;flips &amp;lt;- c(rep(1, 500), rep(0, 500))  
evens_for_t_test &amp;lt;- c(rep(1, each=length(indices_for_evens)),  rep(0, each=length(indices_for_odds)) )  
t.test(flips, evens_for_t_test, alternative="two.sided")&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;The p-value is 0.4881.  At a 0.05 significance level, we fail to reject the null hypothesis.Thus, we infer that the digits of pi have passed a test for randomness.  &lt;/p&gt;
&lt;p&gt;So why aren't the digits of $\pi$ used to generate random numbers?  One problem may be the choice of a seed -- in one sense, each time you re-run your simulation based on the digits of $\pi$, you will have to pick up where you left off last time.  This invariably will lead to the requirement of having to calculated $\pi$ to a huge number of decimal places.  In the end, that computational requirement is the major bottleneck and that bottleneck can probably can be arrived at in a number of novel and unfortunate ways. &lt;/p&gt;&lt;script type= "text/javascript"&gt;
    if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) {
        var mathjaxscript = document.createElement('script');
        mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#';
        mathjaxscript.type = 'text/javascript';
        mathjaxscript.src = 'https:' == document.location.protocol
                ? 'https://c328740.ssl.cf1.rackcdn.com/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML'
                : 'http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML';
        mathjaxscript[(window.opera ? "innerHTML" : "text")] =
            "MathJax.Hub.Config({" +
            "    config: ['MMLorHTML.js']," +
            "    TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'AMS' } }," +
            "    jax: ['input/TeX','input/MathML','output/HTML-CSS']," +
            "    extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js']," +
            "    displayAlign: 'center'," +
            "    displayIndent: '0em'," +
            "    showMathMenu: true," +
            "    tex2jax: { " +
            "        inlineMath: [ ['$','$'] ], " +
            "        displayMath: [ ['$$','$$'] ]," +
            "        processEscapes: true," +
            "        preview: 'TeX'," +
            "    }, " +
            "    'HTML-CSS': { " +
            "        styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'black ! important'} }" +
            "    } " +
            "}); ";
        (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript);
    }
&lt;/script&gt;
</content><category term="simulation"></category><category term="R"></category></entry></feed>