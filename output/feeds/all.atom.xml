<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>Matt O'Brien (dot) Me</title><link href="http://mattobrien.me/" rel="alternate"></link><link href="http://mattobrien.me/feeds/all.atom.xml" rel="self"></link><id>http://mattobrien.me/</id><updated>2017-10-09T00:00:00-07:00</updated><entry><title>Deep Learning for Sport Wagering Part 3 of 3</title><link href="http://mattobrien.me/deep-learning-for-sport-wagering-part-3-of-3.html" rel="alternate"></link><published>2017-10-09T00:00:00-07:00</published><updated>2017-10-09T00:00:00-07:00</updated><author><name>Matt O'Brien</name></author><id>tag:mattobrien.me,2017-10-09:/deep-learning-for-sport-wagering-part-3-of-3.html</id><summary type="html">&lt;p&gt;Predicting&lt;/p&gt;</summary><content type="html">&lt;h4&gt;Part 3: Predicting&lt;/h4&gt;
&lt;p&gt;&lt;a href="http://www.mattobrien.me/deep-learning-for-sport-wagering-part-1-of-3.html"&gt;Part 1: Characteristics of the dataset&lt;/a&gt;&lt;br&gt;
&lt;a href="http://www.mattobrien.me/deep-learning-for-sport-wagering-part-2-of-3.html"&gt;Part 2: Modeling&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;I considered two major betting strategies during this final phase of the project. They are as follows:  &lt;/p&gt;
&lt;p&gt;1) If&lt;br&gt;
$\text{model probability} &amp;gt; \text{some decision threshold}$, and&lt;br&gt;
$\text{model probability} &amp;gt; \text{sportsbook probability}$&lt;br&gt;
then place bet  &lt;/p&gt;
&lt;p&gt;2) If&lt;br&gt;
$\text{model probability} &amp;gt; \text{some decision threshold}$&lt;br&gt;
then place bet&lt;/p&gt;
&lt;p&gt;The first strategy is a more conservative approach in one sense. With this perspective, we include a parameter that indicates if we feel like we have an edge on the casino or sportsbook. &lt;/p&gt;
&lt;p&gt;Allow me a quick foray into the structure of gambling. Sportsbook odds are set, not by information, but by popular sentiment as it is revealed by &lt;a href="https://www.docsports.com/gambling-terms.html"&gt;action&lt;/a&gt;. If some Boxer A gets a large amount of action, then the sportsbook will consider Boxer A to be more likely to win, and consequently, payout on this outcome is reduced. Thus, my model is attempting to answer the question, "When does prediction based on historic data result in a confidence higher than the confidence of the sportsbook -- which is a function of popular sentiment?". In this sense, at it's most stripped down, the model is trying make a totally impartial, data driven decision, and looks for opportunities when public perception is not aligned with historically based signal.  &lt;/p&gt;
&lt;p&gt;This first strategy also has a built in safeguard. If the sportsbook places some Boxer A at a 10% chance of winning, and the model predicts an 11% chance of winning, then without the safeguard, the bet would be place. This is something we don't want. Instead we want to see action whenever the algorithm is confident above some threshold.&lt;/p&gt;
&lt;p&gt;Moving on, the second strategy isn't concerned with the sportsbook's behavior at all; merely concerned with the strength of it's (the model's) own predictions. This strategy might be more successful if it allows more bets to be made, and hopefully more money to be made, quicker. This assumes the model is accurate enough to exhibit this success.&lt;/p&gt;
&lt;p&gt;Let's examine both strategies, and see how they played out. We will start with strategy 1, because is it the more comprehensive one.  &lt;/p&gt;
&lt;h4&gt;Strategy 1&lt;/h4&gt;
&lt;p&gt;To be implemented, the first strategy required a data acquisition step first. Historic sportsbook odds needed to be collected. This is for the purpose of compairing the probability of a win assigned by the model with the probability of a win assigned by a sportsbook.  &lt;/p&gt;
&lt;p&gt;In boxing, the bookmaker's odds come structured into a form which is referred to as the &lt;a href="https://en.wikipedia.org/wiki/Odds#Moneyline_odds"&gt;moneyline&lt;/a&gt;. The moneyline is a little confusing at first. Generally, one fighter who considered favored to win is assigned a negative number. The other fighter is considered the underdog, and is assigned a positive number. &lt;/p&gt;
&lt;p&gt;The best way to remember how to read the moneyline is to always start with the image of a one-hundred dollar bill in your mind.  &lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;A negative number (assocated with the favored fighter) shows how much money you need to bet to win a profit of $100.  &lt;/li&gt;
&lt;li&gt;A positive number (associated with the underdog) shows how much profit a winning wager of $100 would yield.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;So if the moneyline has Boxer A at -130, we know that Boxer A is expected to win. Further, you know you'd have to place a \$130 bet on this fighter to win \$100.&lt;br&gt;
For Boxer B, the moneyline might have them set at +110. This mean Boxer B is the underdog, and if you placed a \$100 bet on this fighter, you'd win \$110.  &lt;/p&gt;
&lt;p&gt;Since Keras is returning the probability of a boxer winning, we now need to convert the moneyline into regular probabilities so we can compare apples to apples.  &lt;/p&gt;
&lt;p&gt;To do this, first the actual numeric values (-130 and +110, on this example above), must be converted to what are referred to as &lt;a href="https://www.sbo.net/strategy/implied-probability/"&gt;implied probabilities&lt;/a&gt; (more about implied probabilities in a second). The formula is as follows:  &lt;/p&gt;
&lt;p&gt;$\text{Implied probability for 'negative' moneyline} = \frac{ - ( \text{'negative' moneyline value})}{- ( \text{'negative' moneyline value} ) + 100}$&lt;br&gt;
and  &lt;/p&gt;
&lt;p&gt;$\text{Implied probability for 'positive' moneyline} = \frac{100}{\text{'positive' moneyline value} + 100}$&lt;/p&gt;
&lt;p&gt;Thus, -130 is converted to 0.56, and +110 is converted to 0.50.  &lt;/p&gt;
&lt;p&gt;But what is an implied probability anyway?&lt;/p&gt;
&lt;p&gt;Implied probability is our usual notion of probability which has actually been modified by what is called either &lt;a href="https://en.wikipedia.org/wiki/Vigorish"&gt;vigorish, or juice&lt;/a&gt;. Both of these terms refer to a built-in modification, by the bookmaker, of the true odds. The modification shifts the moneyline is such a way that the sportsbooks can never ultimately lose money. Usually, the vig amounts to 20 points. It's basically the casino's cut. Fortunately, it's easy to remove the vigorish using this simple formula:  &lt;/p&gt;
&lt;p&gt;Take one of your implied probability. Divide it by the sum of both of your implied probabilities.  &lt;/p&gt;
&lt;p&gt;Thus:  &lt;/p&gt;
&lt;p&gt;$\text{Actual probability } = \frac{\text{Implied probability A}}{\text{Implied probability A} + \text{Implied probability B}}$&lt;/p&gt;
&lt;p&gt;With the math settled, I began searching for a set of historic moneylines for records which I could use in my test set. Using a variety of sources (including laborious searching of the Wayback Machine, and locating an actual broker for assistance), I collected a set of 728 moneylines. After munging, the final size was 679.  &lt;/p&gt;
&lt;p&gt;We now bring our attention back to decision thresholds. What would be the optimal value where our $\text{model probability} &amp;gt; \text{some decision threshold}$?  To determine this, it was merely a matter of looping through thresholds from $[ 0, 1 ]$ by 0.1 and collecting results.  &lt;/p&gt;
&lt;p&gt;The outputs collects as a function of varying decision threshold were as follows:   &lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Number of wagers that satisified the criteria and thus were placed  &lt;/li&gt;
&lt;li&gt;Number of wagers placed which won  &lt;/li&gt;
&lt;li&gt;Number of wagers placed which lost  &lt;/li&gt;
&lt;li&gt;A tabulation of the balance resulting from money won via successful wagers and money lost via unsuccessful wagers  &lt;/li&gt;
&lt;li&gt;ROI (return on investment): simply $\frac{\text{balance}}{\text{total investment}}$  &lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;The iterations assumed that each bet placed was a $100 bet.  &lt;/p&gt;
&lt;p&gt;Here is a plot showing the outcome for the output of #1 listed above:  &lt;/p&gt;
&lt;p&gt;&lt;img alt="ROI" src="https://github.com/mobbSF/blog/blob/master/images/ROI.png?raw=true"&gt;  &lt;/p&gt;
&lt;p&gt;Wagers as a function of dt
ROI showing first hint of high probs
Cash: showing actual dollar amount
All stuff combined&lt;/p&gt;&lt;script type= "text/javascript"&gt;
    if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) {
        var mathjaxscript = document.createElement('script');
        mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#';
        mathjaxscript.type = 'text/javascript';
        mathjaxscript.src = 'https:' == document.location.protocol
                ? 'https://c328740.ssl.cf1.rackcdn.com/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML'
                : 'http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML';
        mathjaxscript[(window.opera ? "innerHTML" : "text")] =
            "MathJax.Hub.Config({" +
            "    config: ['MMLorHTML.js']," +
            "    TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'AMS' } }," +
            "    jax: ['input/TeX','input/MathML','output/HTML-CSS']," +
            "    extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js']," +
            "    displayAlign: 'center'," +
            "    displayIndent: '0em'," +
            "    showMathMenu: true," +
            "    tex2jax: { " +
            "        inlineMath: [ ['$','$'] ], " +
            "        displayMath: [ ['$$','$$'] ]," +
            "        processEscapes: true," +
            "        preview: 'TeX'," +
            "    }, " +
            "    'HTML-CSS': { " +
            "        styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'black ! important'} }" +
            "    } " +
            "}); ";
        (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript);
    }
&lt;/script&gt;
</content><category term="deep learning"></category><category term="sport"></category><category term="wagering"></category></entry><entry><title>Deep Learning for Sport Wagering Part 2 of 3</title><link href="http://mattobrien.me/deep-learning-for-sport-wagering-part-2-of-3.html" rel="alternate"></link><published>2017-09-16T00:00:00-07:00</published><updated>2017-09-16T00:00:00-07:00</updated><author><name>Matt O'Brien</name></author><id>tag:mattobrien.me,2017-09-16:/deep-learning-for-sport-wagering-part-2-of-3.html</id><summary type="html">&lt;p&gt;Modeling&lt;/p&gt;</summary><content type="html">&lt;h4&gt;Part 2: Modeling&lt;/h4&gt;
&lt;p&gt;&lt;a href="http://www.mattobrien.me/deep-learning-for-sport-wagering-part-1-of-3.html"&gt;Part 1: Characteristics of the dataset&lt;/a&gt;&lt;br&gt;
&lt;a href="http://www.mattobrien.me/deep-learning-for-sport-wagering-part-3-of-3.html"&gt;Part 3: Modeling&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;I was fortunate enough to have attended Jeremy Howard's awesome &lt;a href="https://www.usfca.edu/data-institute/certificates/deep-learning-part-one"&gt;deep learning certification program&lt;/a&gt; at University of San Francisco. One of the many insightful things Jeremy said was, and I quote directly, &lt;a href="https://youtu.be/1-NYPQw5THU?t=1h19m11s"&gt;"The first thing I do, is try to get a feature importance plot printed."&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Being just smart enough to recognize when smarter people have smart ideas, this is exactly what I did.&lt;/p&gt;
&lt;p&gt;I built a straightforward Random Forest in scikit-learn (using CV to select hyperparameters and using general best procedures) and retrieved this plot:&lt;/p&gt;
&lt;p&gt;&lt;img alt="VIP" src="https://github.com/mobbSF/blog/blob/master/images/VIP.png?raw=true"&gt;&lt;/p&gt;
&lt;p&gt;The plot doesn't have a strong inflection point, making it difficult to decide where to draw a line in the sand about what is important to include. Let's see if we can deduce where this cutoff might fall, by first let's look at what isn't important:  &lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;We see that the number of Draw outcomes isn't important, which makes sense, as these are rare outcomes and are fairly irrelevant. The number of draws a boxer has doesn't have much bearing on the rest of their records.  &lt;/li&gt;
&lt;li&gt;We see that the permutations of stances across opponents (complimentary or opposite, &lt;a href="https://en.wikipedia.org/wiki/Southpaw_stance"&gt;southpaw&lt;/a&gt; or &lt;a href="https://en.wikipedia.org/wiki/Orthodox_stance"&gt;orthodox&lt;/a&gt;) isn't relevant.  &lt;/li&gt;
&lt;li&gt;Finally, the indicator columns aren't useful, which isn't a major surprise. &lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Next, let's look at what &lt;em&gt;is&lt;/em&gt; important. But first, let's take a little detour to think ahead about what might feel right. Let's ignore the variable importance plot for a moment.&lt;/p&gt;
&lt;p&gt;There is a fundamental axiom in boxing: "Hit and don't get hit." For boxers who fail to adhere to this basic principle, careers will be unnecesarily short, as physical damage sustained will quickly accumulate. So the idea of wear and tear on the body accumulated by a boxer over time seems like a naturally important component of what influences the outcome of a fight. &lt;/p&gt;
&lt;p&gt;This being considered, it should come as no great surprise that the most important feature in the Random Forest is &lt;code&gt;P1_days_since_ff&lt;/code&gt;. Recall, this variable reflects how long it has been since a boxer's career began. This perspective on career length turns out to be a natural fit.&lt;/p&gt;
&lt;p&gt;However, it's possible a boxer could fight once, then fight once again 10 years later. In this scenario,&lt;code&gt;P1_days_since_ff&lt;/code&gt; would be a value around 3,650, but this wouldn't be an accurate measurement of that boxer's accumulated wear and tear. The boxer would only have fought twice within that period. Fortunately for us, the next most important features on the plot corresponds to the aggregated number of rounds the opponents have fought. A long 'ring life' can clearly play a large role in a fighter's success (see &lt;a href="https://www.youtube.com/watch?v=Ja9iovR9B3E"&gt;Ali vs Holmes&lt;/a&gt; for a tragic example). Conversely, too few rounds can also play a role in predicting losing.&lt;/p&gt;
&lt;p&gt;Getting back to the variable importance plot, the two Quality of Opposition (&lt;code&gt;QOO&lt;/code&gt;) metrics are shown to be important, which is nice because they took a lot of effort to construct.&lt;/p&gt;
&lt;p&gt;The &lt;code&gt;last6_L&lt;/code&gt; and &lt;code&gt;last6_W&lt;/code&gt; variables have a large amounts of variance as evidenced by the bars. This most likely ties into the discussion about how records, as they stand alone, don't adequately reflect the quality of the opposition. For some boxers, the last 6 are very important; for some, they aren't. This makes sense.&lt;/p&gt;
&lt;p&gt;Content with the plot and with these features in mind, I experimented with various subsets of features and various configurations when fitting multilayer perceptrons in Keras.&lt;/p&gt;
&lt;p&gt;On a positive note, because of the small file size of the flat dataset (only 1.85 GB), there were no heavy demands on IO or memory. Thus I could rip through each epoch on a basic AWS cloud GPU painlessly, and iterate on models easily. &lt;/p&gt;
&lt;p&gt;Regarding the actual deep architecture of the MLP, I didn't have major overfitting issues, thus didn't get any advantage with a copious amount of dropout. Batch Normalization didn't give me any advantage, so I discarded it. Fundamentally, it's a remarkably simple dataset and most models I built performed very similarly. Epochs around 10 performed just fine.&lt;/p&gt;
&lt;p&gt;A decent final configuration looked like this: &lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;mlp_004 = Sequential()
mlp_004.add(Dense(64, activation=&amp;#39;relu&amp;#39;, input_dim=13))
mlp_004.add(Dense(64, activation=&amp;#39;relu&amp;#39;))
mlp_004.add(Dense(64, activation=&amp;#39;relu&amp;#39;))
mlp_004.add(Dropout(0.2))
mlp_004.add(Dense(64, activation=&amp;#39;relu&amp;#39;))
mlp_004.add(Dense(1, activation=&amp;#39;sigmoid&amp;#39;))

mlp_004.compile(optimizer=&amp;#39;rmsprop&amp;#39;, loss=&amp;#39;binary_crossentropy&amp;#39;, metrics=[&amp;#39;accuracy&amp;#39;])

mlp_004.fit(X_train, y_train, batch_size=64, validation_split=0.2, nb_epoch=10)
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;The validation set accuracy returned was 73%. &lt;/p&gt;
&lt;p&gt;Here's the confusion matrix:&lt;/p&gt;
&lt;p&gt;&lt;img alt="CM" src="https://github.com/mobbSF/blog/blob/master/images/CM.png?raw=true"&gt;&lt;/p&gt;
&lt;p&gt;Here's the ROC curve:  &lt;/p&gt;
&lt;p&gt;&lt;img alt="ROC" src="https://github.com/mobbSF/blog/blob/master/images/ROC.png?raw=true"&gt;&lt;/p&gt;
&lt;p&gt;OK, so how should I feel about such relatively modest scores, in this age of a solved MNIST, self-driving cars, and &lt;a href="https://www.cnbc.com/2017/08/11/elon-musk-issues-a-stark-warning-about-a-i-calls-it-a-bigger-threat-than-north-korea.html"&gt;Elon Musk's dire warnings&lt;/a&gt; of &lt;a href="https://www.youtube.com/watch?v=-WIwQlMesr0"&gt;Arnold coming baaack&lt;/a&gt;?&lt;/p&gt;
&lt;p&gt;I must admit, I feel pretty good about it. It's useful to take a step back here and reiterate that the purpose of this project is to make money gambling on boxing. If we were to use this algorithm to indicate when to place a bet, then we would prefer a larger precision at the expense of recall. What this means it that it's better to avoid betting and miss out on opportunities to win (lower recall), as long as we are more confident that when we &lt;em&gt;DO&lt;/em&gt; bet, we will win. More in the third post about this approach.&lt;/p&gt;
&lt;p&gt;Meanwhile, allow me to wander a bit (yet again!) and discuss one of the many experiments I ran that didn't pay off. I went ahead and went for a moonshot. The reality is that as far as wagering on boxing go, it's one thing to wager on a W or L outcome. But if you can win a bet by predicting a more granular types of outcomes, the payouts are several orders of magnitude better. The actual type of outcome -- either a judges decision, or an actual knockout, or a technical knockout -- that's where the big bucks are. And when it comes to knockouts, if it's possible to predict the actual round? The payouts are huge. &lt;/p&gt;
&lt;p&gt;I changed the labels to represent the granular outcomes mentioned above, and I rebuilt the model and crossed my fingers. Unfortunately, and not too surprisingly, accuracy dropped to around 30%. Hummm...well...worth a shot. And definitely worth revisiting again later.&lt;/p&gt;
&lt;p&gt;Next up...prediction time!&lt;/p&gt;</content><category term="deep learning"></category><category term="sport"></category><category term="wagering"></category></entry><entry><title>Deep Learning for Sport Wagering Part 1 of 3</title><link href="http://mattobrien.me/deep-learning-for-sport-wagering-part-1-of-3.html" rel="alternate"></link><published>2017-09-15T00:00:00-07:00</published><updated>2017-09-15T00:00:00-07:00</updated><author><name>Matt O'Brien</name></author><id>tag:mattobrien.me,2017-09-15:/deep-learning-for-sport-wagering-part-1-of-3.html</id><summary type="html">&lt;p&gt;Characteristics of the dataset&lt;/p&gt;</summary><content type="html">&lt;h4&gt;Part 1: Characteristics of the dataset&lt;/h4&gt;
&lt;p&gt;&lt;a href="http://www.mattobrien.me/deep-learning-for-sport-wagering-part-2-of-3.html"&gt;Part 2 Modeling&lt;/a&gt;&lt;br&gt;
&lt;a href="http://www.mattobrien.me/deep-learning-for-sport-wagering-part-3-of-3.html"&gt;Part 3: Predicting&lt;/a&gt;  &lt;/p&gt;
&lt;p&gt;Not long ago, I was reading Nate Silver's blog, where there was some discussion about basketball. In particular, my hometown's team, the Golden State Warriors. At the time of the writing, the Warriors were surging towards the status of present-day dynasty, and the blog post was examining ways that the team performed that were revolutionary in the sport.&lt;/p&gt;
&lt;p&gt;One particular line in &lt;a href="https://fivethirtyeight.com/features/how-the-golden-state-warriors-are-breaking-the-nba/"&gt;the blog post&lt;/a&gt; stuck out for me: "It’s as if at some point in the past few years, the Warriors solved contemporary basketball..."&lt;/p&gt;
&lt;p&gt;Solved? A bit heavy on the hyperbole, but maybe not too far off.&lt;/p&gt;
&lt;p&gt;This got me thinking about other sports, and their capacity to be understood via data science, analytics, and deep learning. In particular, I became interested in the somewhat marginal and obscure (by major American sport standards, anyway) sport of boxing. I began to think that boxing could lend itself to being 'solved' nicely, because it has many characteristics that lend it to straightforward analysis and modeling.&lt;/p&gt;
&lt;p&gt;At it's heart, boxing has a simple structure.  Unlike many popular sports, it's not a team sport -- so there isn't a dynamic interplay between multiple individuals. It's also not new: the sport became standardized in the late 1600s, via the &lt;a href="https://en.wikipedia.org/wiki/Marquess_of_Queensberry_Rules"&gt;Marquess of Queensberry Rules&lt;/a&gt;. Thus, there is plenty of data available.  Fortunately for me, much of it is available online.&lt;/p&gt;
&lt;p&gt;To make the project more impactful, I decided to set a very specific goal. I've found that often, personal projects such as these will hold up better if there is the possibility of a good payoff at the end --  so I figured, why not try to build an algorithm that would allow me to win money in Vegas? Thus I set the goal of creating a tool for successful wagering on boxing.&lt;/p&gt;
&lt;p&gt;After quite a few long nights and weekends of collecting, reshaping, and modeling the data, I came into posession a pretty good model. The tl;dr is that the model guarantees a result of up to an (fill this in soon) &lt;insert&gt; return on investment. &lt;/p&gt;
&lt;p&gt;So, if you make it through these (hopefully not painful to read) blog posts, then go ahead and check on some upcoming fights. Ask me where to put your money, and I might be able to provide you with the 'nap.' In case you didn't know, the word 'nap' refers to a highly confident bet. That's been a fun side-effect from this project -- I learned a lot of cool new slang terms! &lt;/p&gt;
&lt;p&gt;There will be 3 parts to this blog post:&lt;/p&gt;
&lt;p&gt;1) Characteristics of the data&lt;br&gt;
2) Building models&lt;br&gt;
3) Prediction and Evaluation  &lt;/p&gt;
&lt;h3&gt;Characteristics of the data&lt;/h3&gt;
&lt;p&gt;The project was built on a very substantial dataset. The were two major sources of data. First, I aquired metadata on 373,415 individual boxers. Second, I had a collection of over 3.5 million fights (3,529,624 to be exact). These I imported into two MySQL tables. The dataset spanned the entire history of the sport. It was really fun to dig into. There were fighters from every corner of the globe, competing from the very beginning of the sport to the present day. There were boxers in every weight class from minimumweight upward, possessing all skill levels, at all ages, and exhibiting all levels of success. Perusing revealed some quite obscure fighters: a boxer from Accra, Ghana, who fought only once (unfortunately losing by knockout), back in 1966. Then, there was data on all the modern day multimillionaire heavyweight champions. There were was, for example, &lt;a href="https://en.wikipedia.org/wiki/Wladimir_Klitschko"&gt;Wladamir Klitchko&lt;/a&gt;, nicknamed 'Dr Steelhammer.' &lt;/p&gt;
&lt;p&gt;The dataset definitely possessed depth. The breadth in features for the first source of data, was as such:&lt;/p&gt;
&lt;h5&gt;boxer data&lt;/h5&gt;
&lt;p&gt;name&lt;br&gt;
sex&lt;br&gt;
birth_date&lt;br&gt;
division&lt;br&gt;
stance&lt;br&gt;
height&lt;br&gt;
reach&lt;br&gt;
country&lt;br&gt;
residence&lt;br&gt;
birth_place&lt;br&gt;
world_rank&lt;br&gt;
total_wins&lt;br&gt;
ko_wins&lt;br&gt;
total_losses&lt;br&gt;
ko_losses&lt;br&gt;
draws&lt;br&gt;
rounds&lt;br&gt;
ko_percent  &lt;/p&gt;
&lt;p&gt;Although elements like a boxer's weight are extremely important in real life boxing, some particular features like that and others were not applicable.
For example, Manny Pacquiao's first fight was at 98 pounds, but his most recent fight was at 146. So a single value pulled from the metadata would only reflect the most recent weight, not the weight at each fight.&lt;/p&gt;
&lt;p&gt;It was simple to keep stance (orthodox or southpaw) as a categorical variable.&lt;/p&gt;
&lt;p&gt;The dataset was balanced: 55% Wins, 45% Losses.&lt;/p&gt;
&lt;p&gt;More useful was the second source of data, the specific data for each boxing match:  &lt;/p&gt;
&lt;h5&gt;fight data&lt;/h5&gt;
&lt;p&gt;boxer1_id&lt;br&gt;
boxer2_id&lt;br&gt;
date&lt;br&gt;
location&lt;br&gt;
rounds_planned&lt;br&gt;
rounds_happened&lt;br&gt;
boxer1_mass&lt;br&gt;
boxer2_mass&lt;br&gt;
boxer2_wins&lt;br&gt;
boxer2_loses&lt;br&gt;
boxer2_draws&lt;br&gt;
boxer2_last6_wins&lt;br&gt;
boxer2_last6_loses&lt;br&gt;
boxer2_last6_draws&lt;br&gt;
outcome&lt;br&gt;
outcome_type&lt;br&gt;
rating&lt;br&gt;
time&lt;br&gt;
referee&lt;br&gt;
judge1&lt;br&gt;
judge2&lt;br&gt;
judge3&lt;br&gt;
judge1_score&lt;br&gt;
judge2_score&lt;br&gt;
judge3_score&lt;br&gt;
titles&lt;br&gt;
comments  &lt;/p&gt;
&lt;p&gt;As with the metadata for the boxer, I discarded some features of the fights. Much of it was nice but not functionally applicable, such as the names of the referee and judges, and comments, etc.&lt;/p&gt;
&lt;p&gt;With that being settled, the first important decision I made with respect to transformation of the data was to do a self-join within the fight table in MySQL. Thus, as shown above, each record in the dataset represented one fight. There would be a boxer1 and a boxer2. The target for each row would be Win, Lose, or Draw, with respect to boxer1. There would also be the granular outcome information: the type of W, L or D. After all, there are many ways for a boxing match to end: points, knockout, disqualification, waved off via accidental headbut, quitting on the stool, etc, etc.&lt;/p&gt;
&lt;p&gt;(Quick note on a detail of the sport itself: Notice that although boxing is an individual sport, each fighter also has a whole team behind them. During competition, there is a coach, obviously, and there is the &lt;a href="https://en.wikipedia.org/wiki/Cutman"&gt;cutman&lt;/a&gt; as well. The cutman handles the first aid between rounds. These two team members are called the 'secondaries' -- so in boxing, we'll call the 2 boxers 'primaries'. I quickly renamed boxer1 and boxer2 to P1 and P2.)&lt;/p&gt;
&lt;p&gt;Looking at these data, all seemed promising. But after some more reflection, I started to be concerned with what this rectangular representation was missing.
Really, these fights are all sequences of events that happen for a boxer -- they start with fight #1, then continue forward until the end of their careers. This made me interested in engineering some temporal variables, which I proceed to do in Pandas. Now, each row had these features:  &lt;/p&gt;
&lt;p&gt;P1_ageAtFight&lt;br&gt;
P2_ageAtFight&lt;br&gt;
P1_rounds_fought&lt;br&gt;
P2_rounds_fought  &lt;/p&gt;
&lt;p&gt;These 4 variables are rather self-explanatory given their names.  &lt;/p&gt;
&lt;p&gt;Another engineered feature was basically 'career length', or how many days it had been since the boxer's debut. These became:  &lt;/p&gt;
&lt;p&gt;P1_days_since_ff&lt;br&gt;
P2_days_since_ff  &lt;/p&gt;
&lt;p&gt;where 'ff' is short for 'first fight'.&lt;/p&gt;
&lt;p&gt;Some boxers were missing a birthdate, so I imputed these birthdates by assuming that each boxer's debut was on their 20th birthday. This was a simple subtraction from of 20 years from the date of the first fight.&lt;/p&gt;
&lt;p&gt;But beyond the sequential, temporal perspective, there was still something more to be done. I realized this dataset could also be realized as a graph, with nodes for the boxers and the fights, and nodes for their professional W, L, D records at the time of the fight. So I exported my dataset out of SQL and into Neo4J.&lt;/p&gt;
&lt;p&gt;Once this was done (and it took quite some time, given I had never used Neo4J before), I had a new way of conceptualizing these competitions. The schema is, in ASCI art:&lt;/p&gt;
&lt;p&gt;(A boxer, call them 'P1')--[had a record (W, L, D) on some date] --&amp;gt;(and there was a Fight at some location, with some outcome).&lt;/p&gt;
&lt;p&gt;Now, going the other direction,  &lt;/p&gt;
&lt;p&gt;(and there was a Fight at some location, with some outcome)&amp;lt;--[the opponent had a record, (W, L, D) on that same date]---(The opponent, call them 'P2')&lt;/p&gt;
&lt;p&gt;This actually is more clear when you look at the actual Neo4J graph itself:&lt;/p&gt;
&lt;p&gt;&lt;img alt="Neo4J graph" src="https://github.com/mobbSF/blog/blob/master/images/Neo_000.png?raw=true"&gt;&lt;/p&gt;
&lt;p&gt;Here you see the blue boxer nodes, their records at a given time (red node), the fight node (green), and the complementary information for their opponents. Note that this particular boxer had a few rematches which are visible when two edges touch the same blue P2 (P2 being the opponent), node.&lt;/p&gt;
&lt;p&gt;Actually, it's interesting to see how the graph can be expanded. Take a look a Muhammad Ali's and his career:&lt;/p&gt;
&lt;p&gt;&lt;img alt="Neo4J graph 1" src="https://github.com/mobbSF/blog/blob/master/images/Neo_001.png?raw=true"&gt;&lt;/p&gt;
&lt;p&gt;and here's &lt;a href="https://www.youtube.com/watch?v=-FZBzGhxERg"&gt;Ali's fight with Archie Moore&lt;/a&gt;, and Archie Moore's career: &lt;/p&gt;
&lt;p&gt;&lt;img alt="Neo4J graph 2" src="https://github.com/mobbSF/blog/blob/master/images/Neo_002.png?raw=true"&gt;&lt;/p&gt;
&lt;p&gt;...and here's &lt;a href="https://www.youtube.com/watch?v=MUT71-jyY2s"&gt;Archie Moore's fight with Jimmy Slade&lt;/a&gt;,&lt;/p&gt;
&lt;p&gt;&lt;img alt="Neo4J graph 3" src="https://github.com/mobbSF/blog/blob/master/images/Neo_003.png?raw=true"&gt;&lt;/p&gt;
&lt;p&gt;and so forth.&lt;/p&gt;
&lt;p&gt;Envisioned as a graph, it is insigtful to see the interconnectedness of the sport as a whole. &lt;/p&gt;
&lt;p&gt;Now that the Neo4J database was built, the first metric I focused on creating using Cypher was a 'quality of opposition' (QOO) score.&lt;/p&gt;
&lt;p&gt;QOO is necessary to suss out boxers with inflated records. Interestingly enough, boxing is the only sport (that I can think of, anyway) where a boxer actually gets to choose their opponent. There are no tournaments...no leagues...just arrangements between two boxers and the businesspeople around them, to hold an event. So what is stopping a boxer from inflating their record with &lt;a href="http://boxrec.com/en/boxer/4741"&gt;lousy opposition&lt;/a&gt;? Not much.&lt;/p&gt;
&lt;p&gt;It all really comes down to the quality of a boxer's opponents. If a boxer (say P1) has just been beating up on &lt;a href="https://en.wikipedia.org/wiki/Tomato_can_(sports_idiom)"&gt;tomato cans&lt;/a&gt;, then we need to acknowledge this. 
Because if P2 was battling top-quality opposition, then you'd be wise to put your money on P2. Because they both could have records of 20 Wins, 0 losses.&lt;/p&gt;
&lt;p&gt;(In reality, most successful fighters start competing relatively frequently, against somewhat weak opposition. Later, they increase the quality of opposition as they decrease the frequency of competition. So the above scenario is an exaggeration, in most cases).&lt;/p&gt;
&lt;p&gt;To show how the metric works, let's first start with this made up, simplified visual scenario:&lt;/p&gt;
&lt;p&gt;&lt;img alt="QOO 1" src="https://github.com/mobbSF/blog/blob/master/images/QOO_001.png?raw=true"&gt;&lt;/p&gt;
&lt;p&gt;As you can see, P1 has fought 3 opponents (they live in 'Layer 1'), and each of those opponents had fought 3 opponents themselves (they live in 'Layer 2').&lt;/p&gt;
&lt;p&gt;Now consider Layer 2. For each group of 3 fights, sum up these fighters' records as : count(Wins) / count(fights).&lt;/p&gt;
&lt;p&gt;&lt;img alt="QOO 2" src="https://github.com/mobbSF/blog/blob/master/images/QOO_002.png?raw=true"&gt;&lt;/p&gt;
&lt;p&gt;Now, recursively running back up the graph, let's see how the boxer in Layer 1 performed against this group. This will be count(Wins) / count(opponents) from above, but now multiplied by the previously calculated value. Voila; we have the QOO metric.&lt;/p&gt;
&lt;p&gt;&lt;img alt="QOO 3" src="https://github.com/mobbSF/blog/blob/master/images/QOO_003.png?raw=true"&gt;&lt;/p&gt;
&lt;p&gt;After setting a QOO score for all fights on the nodes in Neo4J, it was easy to put together another quick and dirty metric: QOOP, which for lack of better nomenclature, is 'Quality of opposition prime'. Here, I just took the mean of all a boxer's opponents' QOOs and wrote it to the record node.&lt;/p&gt;
&lt;p&gt;Indicator columns with 0 or 1 were included, in case the QOO metrics couldn't be built. This could happen if, say, a fight was a boxer's debut.&lt;/p&gt;
&lt;p&gt;As a work in progress, I'm still playing with different ways to extract value from the Neo4J implementation. But this was a good start and took me pretty far.&lt;/p&gt;
&lt;p&gt;Now that the data were all cleaned up ready to go, it was time to (finally!!) get to the fun part...building some deep learning models.&lt;/p&gt;</content><category term="deep learning"></category><category term="sport"></category><category term="wagering"></category></entry><entry><title>The 80 Best Boxers; A Career Viewer</title><link href="http://mattobrien.me/the-80-best-boxers-a-career-viewer.html" rel="alternate"></link><published>2016-06-05T00:00:00-07:00</published><updated>2016-06-05T00:00:00-07:00</updated><author><name>Matt O'Brien</name></author><id>tag:mattobrien.me,2016-06-05:/the-80-best-boxers-a-career-viewer.html</id><summary type="html">&lt;p&gt;A visualization of the careers of the top 80 boxers in the last 80 years&lt;/p&gt;</summary><content type="html">&lt;h1&gt;The 80 Best Boxers; A Career Viewer&lt;/h1&gt;
&lt;p&gt;A few years back, the Ring Magazine compiled a list of &lt;a href="http://boxing.about.com/od/history/a/ring_80_best.htm"&gt;The 80 Best Boxers of the Last 80 Years&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;This is a solid list, compiled by the definitive boxing authority. But it is fundamentally just..well, a list. Which is a bit boring. It got me thinking of ways to get a better feel for what these boxers' accomplished throughout the duration of their careers.&lt;/p&gt;
&lt;p&gt;To do that, I created an app which allows us to see where in the world these 80 pugilists plied their trade. We can explore chronologically, or by their opponent's names, and see how the top guys wrecked shop all over the world. There are big 'W', 'L', or 'D' letters plotted directly on a zoomable map, to indicate what happened and where.   &lt;/p&gt;
&lt;p&gt;Here's a screenshot:  &lt;/p&gt;
&lt;p&gt;&lt;img alt="screenshot" src="https://raw.githubusercontent.com/mobbSF/blog/master/content/sport/image_007.png"&gt;&lt;/p&gt;
&lt;p&gt;But you can &lt;a href="https://mattobriendotme.shinyapps.io/top_80_career_viewer/"&gt;click here&lt;/a&gt; to play with it yourself, which is a lot more fun than looking at my screenshots.&lt;/p&gt;
&lt;p&gt;Speaking of screenshots, you can see below, that some fighters travelled all over the place. This is the career of the Old Mongoose himself, &lt;a href="https://en.wikipedia.org/wiki/Archie_Moore"&gt;Archie Moore&lt;/a&gt;: &lt;/p&gt;
&lt;p&gt;&lt;img alt="Archie Moore's career" src="https://raw.githubusercontent.com/mobbSF/blog/master/content/sport/image_005.png"&gt;&lt;/p&gt;
&lt;p&gt;Then we have guys like &lt;a href="https://en.wikipedia.org/wiki/Rocky_Marciano"&gt;Rocky Marciano&lt;/a&gt;, who stuck pretty much to his own backyard during the duration of his short but undefeated career: &lt;/p&gt;
&lt;p&gt;&lt;img alt="Rocky Marcian's career" src="https://raw.githubusercontent.com/mobbSF/blog/master/content/sport/image_006.png"&gt;&lt;/p&gt;
&lt;p&gt;Have a look at &lt;a href="https://mattobriendotme.shinyapps.io/top_80_career_viewer/"&gt;the app&lt;/a&gt; and play with it! Let me know what you think in the comments. I'd also appreciate a heads up on any bugs you might find.  &lt;/p&gt;</content><category term="sport science"></category><category term="boxing"></category></entry><entry><title>A nation by nation look at knockouts in boxing</title><link href="http://mattobrien.me/a-nation-by-nation-look-at-knockouts-in-boxing.html" rel="alternate"></link><published>2016-05-31T00:00:00-07:00</published><updated>2016-05-31T00:00:00-07:00</updated><author><name>Matt O'Brien</name></author><id>tag:mattobrien.me,2016-05-31:/a-nation-by-nation-look-at-knockouts-in-boxing.html</id><summary type="html">&lt;p&gt;Aggregating boxing outcomes by nation of origin&lt;/p&gt;</summary><content type="html">&lt;h1&gt;A nation by nation look at knockouts in boxing&lt;/h1&gt;
&lt;p&gt;Here's a question for you: Who scores more knockouts as a whole, Mexican fighters or Philipino fighters?  &lt;/p&gt;
&lt;p&gt;(tl;dr: click &lt;a href="https://mattobriendotme.shinyapps.io/ko_by_countries/" title="Knockouts by Nation"&gt;here&lt;/a&gt; to find out yourself.)&lt;/p&gt;
&lt;p&gt;It's a good question...and it's one that could certainly stir up some impassioned debate on various online forums. Unfortunately, we'd all be stuck debating based on our intuition. It is impossible to answer this kind of question without looking directly at the numbers. But unlike other sports such as baseball or basketball, the cold hard facts are sometimes harder to come across in boxing. &lt;/p&gt;
&lt;p&gt;In order to answer this question, I collected over 4 million records of fights from all over the world, from all eras. I looked at what country the winners were from, and how they won the fights. I created a tool to help visualize the results. You can play around with it yourself &lt;a href="https://mattobriendotme.shinyapps.io/ko_by_countries/" title="Knockouts by Nation"&gt;by clicking here&lt;/a&gt;. With it, you can compare any number of countries, side by side, and see which one has produced the most knockouts.  &lt;/p&gt;
&lt;p&gt;Forget about compairing Mexico and the Philipines for a second. How about...Ghana and Austrailia?  &lt;/p&gt;
&lt;p&gt;(Now might be a good time to take a break and rewatch the the Ring Magazine's offical 'Upset of the Year' way back in 1992! Yes, of course I'm talking about the rematch between &lt;a href="https://www.youtube.com/watch?v=QsqmNOAw1Sk"&gt;Jeff Fenech and Azumah Nelson&lt;/a&gt;.)  &lt;/p&gt;
&lt;p&gt;Turns out that Austraila, as a whole, doesn't seem to be producing a whole slew of knockout punchers. Their percent of stoppages is well below 50...but on the other hand, Ghana is around 60%.  &lt;/p&gt;
&lt;p&gt;&lt;img alt="Ghana vs. Austraila" src="https://raw.githubusercontent.com/mobbSF/blog/master/content/sport/image_001.png"&gt;  &lt;/p&gt;
&lt;p&gt;&lt;em&gt;Notice that "Other" on the far right of the graph, contains stuff like Draws, No Contests, and other non-definitive outcomes.&lt;/em&gt;  &lt;/p&gt;
&lt;p&gt;The tool gets more fun when you look at side-by-side comparisons between more than 2 nations (the dropdown on the left has over 100 countries to choose from):  &lt;/p&gt;
&lt;p&gt;&lt;img alt="Jamacia, Switzerland, Isreal" src="https://raw.githubusercontent.com/mobbSF/blog/master/content/sport/image_002.png"&gt;  &lt;/p&gt;
&lt;p&gt;Appears that the Israelis have the advantage. Historically, Jamacia doesn't seem to be doing a while lot of winning by KO.  &lt;/p&gt;
&lt;p&gt;What do you think? Did you find this useful or interesting? Let me know in the comments section if you find anything surprising.  &lt;/p&gt;</content><category term="sport science"></category><category term="visualization"></category></entry><entry><title>An analysis of stoppages in boxing</title><link href="http://mattobrien.me/an-analysis-of-stoppages-in-boxing.html" rel="alternate"></link><published>2016-05-18T00:00:00-07:00</published><updated>2016-05-18T00:00:00-07:00</updated><author><name>Matt O'Brien</name></author><id>tag:mattobrien.me,2016-05-18:/an-analysis-of-stoppages-in-boxing.html</id><summary type="html">&lt;p&gt;Some perspectives on knockouts&lt;/p&gt;</summary><content type="html">&lt;h1&gt;An analysis of stoppages in boxing&lt;/h1&gt;
&lt;p&gt;Knockouts are truly the most dramatic, exciting, terrifying, heartbreaking and exhilarating outcome of any sporting event.  Along with the basic knockout, there is also the TKO that occurs when the ref waves it off. A fighter can also retire in between rounds if the fighter (or more likely, their corner) has seen enough and knows there is no decent chance of winning.  &lt;/p&gt;
&lt;p&gt;But what do we really know about these stoppages? No, I don't mean in terms of brain injury and health (that's another topic for another time), but from the big picture?  &lt;/p&gt;
&lt;p&gt;I collected a gigantic set of over 3.3 million boxing matches that spanned all eras of the sport, in every division, with all countries included. I filtered out how many fights ended by knockout, and dove in to see what I could find out. Of these 3.3 million fights, 1,275,316 of them ended in a stoppage.  &lt;/p&gt;
&lt;p&gt;&lt;em&gt;This resulting dataset is a large enough so that we should be confident that insights found within can safely extend to the whole of the sport.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;My three main questions are:  &lt;/p&gt;
&lt;p&gt;1) What percent of fights end in a stoppage?&lt;br&gt;
1) What round do knockout happen more frequently?  &lt;br&gt;
2) What weight classes see the most knockouts?  &lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;&lt;h1&gt;#1:&lt;/h1&gt; &lt;/p&gt;
&lt;p&gt;The first question is the simplest. Clearly not every fight ends in a knockout. I'd say that stoppages are a minority. If you are a boxing fan (and you probably are if you are reading this), then you probably already have a pretty good number in your head. Maybe 20%? 40%?  &lt;/p&gt;
&lt;p&gt;Looking at the data, the number I got was [1275316 /  3330197] * 100  = 38.  &lt;/p&gt;
&lt;p&gt;&lt;strong&gt;So the percentage then is thirty eight.&lt;/strong&gt;  &lt;/p&gt;
&lt;p&gt;Does this match your intuition? For me, it sounds about right. &lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;&lt;h1&gt;#2:&lt;/h1&gt;  &lt;/p&gt;
&lt;p&gt;Next up, let's look at how stoppages are distributed across rounds. Of these 1,275,316 stoppages, here's &lt;em&gt;when&lt;/em&gt; they happen:  &lt;/p&gt;
&lt;p&gt;&lt;img alt="stoppages across rounds" src="https://raw.githubusercontent.com/mobbSF/blog/master/content/sport/image_003.png"&gt; 
&lt;em&gt;The x-axis is the round, and the y-axis is the count.&lt;/em&gt;  &lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Stoppages happen most often in the second round.&lt;/strong&gt;   &lt;/p&gt;
&lt;p&gt;Why might this be? Maybe you could argue that most boxing matches that end in stoppage are by definition a mismatch -- and it happens quick, mostly within 4 rounds.  Maybe it's harder to get a knockout later, because familiarity between fighters grow, and the fight becomes a pattern.  I can only use the numbers to supply the outcome, not the cause. &lt;/p&gt;
&lt;p&gt;No matter what the reason, it's clear that those Chavez Sr vs Taylor 12 round endings are extremely rare indeed!  &lt;/p&gt;
&lt;p&gt;&lt;a href="https://www.youtube.com/watch?v=AgenYK7VaxY"&gt;&lt;img alt="Chavez Sr vs Taylor 12" src="http://img.youtube.com/vi/AgenYK7VaxY/0.jpg"&gt;&lt;/a&gt;&lt;br&gt;
&lt;em&gt;Julio Cesar Chavez Jr KO12 Meldrick Taylor&lt;/em&gt;&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;&lt;h1&gt;#3:&lt;/h1&gt;  &lt;/p&gt;
&lt;p&gt;Finally, what about weight classes? Which division is the most dangerous, where the most knockouts happen? I wouldn't be surprised if the first reaction for most people is 'heavyweight.' Let's see what the numbers say:  &lt;/p&gt;
&lt;p&gt;&lt;img alt="stoppages by division" src="https://raw.githubusercontent.com/mobbSF/blog/master/content/sport/image_004.png"&gt; 
&lt;em&gt;The x-axis is the weight class, and the y-axis is the count.&lt;/em&gt;  &lt;/p&gt;
&lt;p&gt;Turns out, by separating all fights that end in stoppage into their divisions, we find that &lt;strong&gt;welterweight and lightweight, both individually, barely beat out the big guys.&lt;/strong&gt;  &lt;/p&gt;
&lt;p&gt;That's a bit surprising, especially since the heavyweight class includes both cruiserweights and light heavies, which covers a big span of possible weights.  &lt;/p&gt;
&lt;p&gt;It's unfortunate that, to quote  Rishad Marquardt from boxingnews24.com, &lt;a href="http://www.boxingnews24.com/2016/05/revival-interest-heavyweight-division-still-hot-air-least-now/"&gt;"The heavyweight division in boxing has, historically speaking, been the premier division within the sport."&lt;/a&gt;  The big fighters historically tend to dominate mainstream news coverage, but you can get more explosive action (and bigger headlines) if you also set your sights down to include a few more weight classes.&lt;/p&gt;
&lt;p&gt;(Recall, lightweight is between 130 lbs and less than 140 lbs.  Welterweight is between 140 and less than 154 lbs. 'Super' and 'Light' subclasses were folded in.)&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;&lt;h1&gt;So what does it all mean?&lt;/h1&gt; 
 Well, here's two take-home messages. &lt;/p&gt;
&lt;p&gt;Say you just lost all your money playing craps in Vegas, and you've only got $5 left in your pocket.  Go to the nearest sportsbook, and wager $5 on the next lightweight matchup. Pick a knockout in the 2nd round. That's your best chance for a decent payoff.  &lt;/p&gt;
&lt;p&gt;But if you want a safer bet, albeit a smaller payout? Recall that historically, only 38% of boxing matches end prematurely. You'd actually be better off putting your money on a 12 round decision on a pair of 105 lb combatants...so look for a minimumweight fight!  &lt;/p&gt;
&lt;p&gt;Here's another take-home. Say you are a coach. If you want your fighter to be a kayo artist, then consider training them to perform best in the second round (and to be sharpest on defense at that time as well).  Work on interval training where the highest workloads are early. Later intervals could focus more on endurance, footwork and jabs. After all, if there hasn't been a knockout by round 4, then probabistically speaking, the fight is probably going to the cards. Time to pile up points and impress the judges.&lt;/p&gt;&lt;script type= "text/javascript"&gt;
    if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) {
        var mathjaxscript = document.createElement('script');
        mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#';
        mathjaxscript.type = 'text/javascript';
        mathjaxscript.src = 'https:' == document.location.protocol
                ? 'https://c328740.ssl.cf1.rackcdn.com/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML'
                : 'http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML';
        mathjaxscript[(window.opera ? "innerHTML" : "text")] =
            "MathJax.Hub.Config({" +
            "    config: ['MMLorHTML.js']," +
            "    TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'AMS' } }," +
            "    jax: ['input/TeX','input/MathML','output/HTML-CSS']," +
            "    extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js']," +
            "    displayAlign: 'center'," +
            "    displayIndent: '0em'," +
            "    showMathMenu: true," +
            "    tex2jax: { " +
            "        inlineMath: [ ['$','$'] ], " +
            "        displayMath: [ ['$$','$$'] ]," +
            "        processEscapes: true," +
            "        preview: 'TeX'," +
            "    }, " +
            "    'HTML-CSS': { " +
            "        styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'black ! important'} }" +
            "    } " +
            "}); ";
        (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript);
    }
&lt;/script&gt;
</content><category term="sport science"></category></entry><entry><title>a csv defined Shiny structure</title><link href="http://mattobrien.me/a-csv-defined-shiny-structure.html" rel="alternate"></link><published>2016-04-16T00:00:00-07:00</published><updated>2016-04-16T00:00:00-07:00</updated><author><name>Matt O'Brien</name></author><id>tag:mattobrien.me,2016-04-16:/a-csv-defined-shiny-structure.html</id><summary type="html">&lt;p&gt;automatically generate a Shiny visualization in R&lt;/p&gt;</summary><content type="html">&lt;p&gt;This project allows you to use 2 csvs (containing IDs, variables, names, and values) to automatically generate a Shiny structure that you can further customize.&lt;/p&gt;
&lt;p&gt;To fork the project, go to the GitHub page &lt;a href="https://github.com/mobbSF/csv-defined-Shiny-structure"&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Use a csv ('chart_settings.csv') in a form similar to this:  &lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;variable&lt;/th&gt;
&lt;th align="center"&gt;x_axis_labels&lt;/th&gt;
&lt;th align="right"&gt;tab_name&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;var1&lt;/td&gt;
&lt;td align="center"&gt;some_name_var1&lt;/td&gt;
&lt;td align="right"&gt;tab1&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;var2&lt;/td&gt;
&lt;td align="center"&gt;some_name_var2&lt;/td&gt;
&lt;td align="right"&gt;tab1&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;var3&lt;/td&gt;
&lt;td align="center"&gt;some_name_var3&lt;/td&gt;
&lt;td align="right"&gt;tab2&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;var4&lt;/td&gt;
&lt;td align="center"&gt;some_name_var4&lt;/td&gt;
&lt;td align="right"&gt;tab3&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;var5&lt;/td&gt;
&lt;td align="center"&gt;some_name_var5&lt;/td&gt;
&lt;td align="right"&gt;tab3&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;is used along with a csv containing variables and values ('IDs_to_examine.csv'): &lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;ID&lt;/th&gt;
&lt;th align="center"&gt;Date&lt;/th&gt;
&lt;th align="center"&gt;var1&lt;/th&gt;
&lt;th align="center"&gt;var2&lt;/th&gt;
&lt;th align="center"&gt;var3&lt;/th&gt;
&lt;th align="center"&gt;var4&lt;/th&gt;
&lt;th align="center"&gt;var5&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;td align="center"&gt;1/1/11&lt;/td&gt;
&lt;td align="center"&gt;1&lt;/td&gt;
&lt;td align="center"&gt;20&lt;/td&gt;
&lt;td align="center"&gt;5&lt;/td&gt;
&lt;td align="center"&gt;50&lt;/td&gt;
&lt;td align="center"&gt;50&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;td align="center"&gt;1/1/11&lt;/td&gt;
&lt;td align="center"&gt;15&lt;/td&gt;
&lt;td align="center"&gt;3&lt;/td&gt;
&lt;td align="center"&gt;45&lt;/td&gt;
&lt;td align="center"&gt;88&lt;/td&gt;
&lt;td align="center"&gt;100&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;2&lt;/td&gt;
&lt;td align="center"&gt;1/1/13&lt;/td&gt;
&lt;td align="center"&gt;97&lt;/td&gt;
&lt;td align="center"&gt;16&lt;/td&gt;
&lt;td align="center"&gt;5&lt;/td&gt;
&lt;td align="center"&gt;5&lt;/td&gt;
&lt;td align="center"&gt;8&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;2&lt;/td&gt;
&lt;td align="center"&gt;1/1/14&lt;/td&gt;
&lt;td align="center"&gt;55&lt;/td&gt;
&lt;td align="center"&gt;15&lt;/td&gt;
&lt;td align="center"&gt;90&lt;/td&gt;
&lt;td align="center"&gt;75&lt;/td&gt;
&lt;td align="center"&gt;35&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;3&lt;/td&gt;
&lt;td align="center"&gt;1/1/15&lt;/td&gt;
&lt;td align="center"&gt;1&lt;/td&gt;
&lt;td align="center"&gt;76&lt;/td&gt;
&lt;td align="center"&gt;66&lt;/td&gt;
&lt;td align="center"&gt;22&lt;/td&gt;
&lt;td align="center"&gt;1&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;...to create a Shiny with any number of tabs; in this case, 3 ('tab1' to 'tab3').  &lt;/p&gt;
&lt;p&gt;Each tab contains one ggplot, featuring the variables; in this case 'var1' to 'var5'.&lt;/p&gt;
&lt;p&gt;Click &lt;a href="https://mattobriendotme.shinyapps.io/csv-defined-Shiny-structure/"&gt;here&lt;/a&gt; to see it in action.  &lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;Examine the screenshot and map trace each element back to the appropriate csv. For the sake of simplicity and to avoid creating any unnecessarily customized features, the inputs show only two large, unsized and unmodified variables plotted as a histogram:  &lt;/p&gt;
&lt;p&gt;&lt;img alt="alt text" src="https://github.com/mobbSF/csv-defined-Shiny-structure/blob/master/screenshot.png?raw=true" title="Logo Title Text 2"&gt;&lt;/p&gt;</content><category term="visualization"></category><category term="R"></category></entry><entry><title>Mike Tyson's Punchout! as a Neo4j graph</title><link href="http://mattobrien.me/mike-tysons-punchout-as-a-neo4j-graph.html" rel="alternate"></link><published>2016-03-16T00:00:00-07:00</published><updated>2016-03-16T00:00:00-07:00</updated><author><name>Matt O'Brien</name></author><id>tag:mattobrien.me,2016-03-16:/mike-tysons-punchout-as-a-neo4j-graph.html</id><summary type="html">&lt;p&gt;a simple example of a graph database&lt;/p&gt;</summary><content type="html">&lt;p&gt;&lt;img alt="Mike Tyson's Punchout!!" src="http://underratedretro.com/press/wp-content/uploads/2014/08/Mike-Tysons-Punchout.jpg" title="Mike Tyson's Punchout!!"&gt;&lt;/p&gt;
&lt;p&gt;This is a quick and fun little graph of the classic Nintendo game, Mike Tyson's Punch-Out!!.  &lt;/p&gt;
&lt;p&gt;The information for the graph comes directly from the &lt;a href="http://punchout.wikia.com/wiki/Punch-Out_Wiki"&gt;Punchout Wiki&lt;/a&gt;. The graph is based off the NES console from 1987 as opposed to the earlier arcade games or the later release for the Wii. &lt;/p&gt;
&lt;p&gt;I took the liberty of having Little Mac win all his fights by knockout. But then he went up against Iron Mike...  &lt;/p&gt;
&lt;p&gt;&lt;em&gt;Notice that the dataset is read in painlessly via Google Docs as outlined &lt;a href="http://blog.bruggen.com/2014/07/using-loadcsv-to-import-data-from.html"&gt;here&lt;/a&gt;.&lt;/em&gt;&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;Query 1

LOAD CSV WITH HEADERS FROM
&amp;#39;https://docs.google.com/spreadsheets/u/0/d/1Jr5ABoLMrUPQ3Vm9GTOzVmNucfnWq1ELTxv2WxOYOx0/export?format=csv&amp;amp;id=1Jr5ABoLMrUPQ3Vm9GTOzVmNucfnWq1ELTxv2WxOYOx0&amp;amp;gid=0&amp;#39; AS line
MERGE (b1:boxer {
                    boxer_id: line.boxer_id,
                    name: line.name
                })
MERGE (b2:boxer {boxer_id: line.fought
                })
MERGE (f:fight  { fight_id: line.fight_id,
                  notes: line.notes,
                  outcome: line.outcome
                })
//CREATE (b1)-[:AGAINST]-&amp;gt;(b2)
CREATE (b1)-[r:BOXER_STATUS {
                  total_fights: line.total_fights,
                  wins: line.wins,
                  wins_by_KO: line.wins_by_KO,
                  losses: line.losses,
                  weight: line.weight,
                  height: line.height,
                  nationality: line.nationality,
                  age: line.age,
                  rank: line.rank
                         } ]-&amp;gt;(f);  
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Here's what it looks like:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;MATCH (n)
RETURN n
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;img alt="mtpo" src="https://github.com/mobbSF/blog/blob/master/publicfolder/mtpo.png?raw=true"&gt;&lt;/p&gt;
&lt;p&gt;Here's some simple queries to practice with:  &lt;/p&gt;
&lt;p&gt;Query 1: What happened when Little Mac fought opponents ranked #1?  &lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;MATCH &lt;span class="p"&gt;(&lt;/span&gt;result&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;r&lt;span class="o"&gt;:&lt;/span&gt;BOXER_STATUS&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;boxer&lt;span class="p"&gt;)&lt;/span&gt;
WHERE toInt&lt;span class="p"&gt;(&lt;/span&gt;r.rank&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="m"&gt;1&lt;/span&gt;
RETURN result.outcome&lt;span class="p"&gt;,&lt;/span&gt; result.notes
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Query 2: Did Little Mac lose twice to anyone? Or win twice against anyone?&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;START n=node(*), m=node(*)
WHERE
  n.outcome=m.outcome AND
  ID(n) &amp;lt;ID(m)
RETURN n, m
&lt;/pre&gt;&lt;/div&gt;</content><category term="visualization"></category></entry><entry><title>Measurability Proof</title><link href="http://mattobrien.me/measurability-proof.html" rel="alternate"></link><published>2016-01-28T00:00:00-08:00</published><updated>2016-01-28T00:00:00-08:00</updated><author><name>Matt O'Brien</name></author><id>tag:mattobrien.me,2016-01-28:/measurability-proof.html</id><summary type="html">&lt;p&gt;Proof by induction&lt;/p&gt;</summary><content type="html">&lt;p&gt;Note: I can't finish this till I get Dr Ov's book so I can use Thm 2.4i, 2.4iii, 2.48&lt;/p&gt;
&lt;h3&gt;Prove that a function $f $on $[a,b]$ is measurable iff $f$ inverse($U$) is measurable for any open set $U$ of $R$.&lt;/h3&gt;
&lt;p&gt;$\Rightarrow$
\newline
By Theorem 2.4i, and Theorem 2.4iii, we have 2 open sets:
\newline
$ J = { x:  f(x) &lt;j \}$
\newline
$K = \{ x:  f(x) &gt; k } ,$ where $j&lt;k$.
\newline
Consider $J \cap K$ which is also open.
\newline
Let $U = J \bigcap K = \bigcup_{i=1}^{n}. (j_i, k_i)$, so that $f^{-1} \left( \bigcup \{ x \in [a, b] : f(x) \in U  \} \right) = f^{-}(U)$. 
\newline
\newline
$\Leftarrow$
\newline
Let $f^{-1}(U)$ be measurable.
\newline
Let $U = \left( c, \infty \right)$.
\newline
Then, $f^{-1}(U)$ measurable $\rightarrow \left\{x: f(x) &gt; c \right}$ is measurable.
\newline
By Theorem 2.48, $f$ is measurable.&lt;/p&gt;&lt;script type= "text/javascript"&gt;
    if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) {
        var mathjaxscript = document.createElement('script');
        mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#';
        mathjaxscript.type = 'text/javascript';
        mathjaxscript.src = 'https:' == document.location.protocol
                ? 'https://c328740.ssl.cf1.rackcdn.com/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML'
                : 'http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML';
        mathjaxscript[(window.opera ? "innerHTML" : "text")] =
            "MathJax.Hub.Config({" +
            "    config: ['MMLorHTML.js']," +
            "    TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'AMS' } }," +
            "    jax: ['input/TeX','input/MathML','output/HTML-CSS']," +
            "    extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js']," +
            "    displayAlign: 'center'," +
            "    displayIndent: '0em'," +
            "    showMathMenu: true," +
            "    tex2jax: { " +
            "        inlineMath: [ ['$','$'] ], " +
            "        displayMath: [ ['$$','$$'] ]," +
            "        processEscapes: true," +
            "        preview: 'TeX'," +
            "    }, " +
            "    'HTML-CSS': { " +
            "        styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'black ! important'} }" +
            "    } " +
            "}); ";
        (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript);
    }
&lt;/script&gt;
</content><category term="in progress"></category></entry><entry><title>Functions of unbounded variation</title><link href="http://mattobrien.me/functions-of-unbounded-variation.html" rel="alternate"></link><published>2015-11-11T00:00:00-08:00</published><updated>2015-11-11T00:00:00-08:00</updated><author><name>Matt O'Brien</name></author><id>tag:mattobrien.me,2015-11-11:/functions-of-unbounded-variation.html</id><summary type="html">&lt;p&gt;Proof regarding a function of bounded variation&lt;/p&gt;</summary><content type="html">&lt;p&gt;This proof relies on the fact that a harmonic series is divergent.  &lt;/p&gt;
&lt;p&gt;Title:  Functions of unbounded variation
Date: 2015-11-11
Tags: math
Summary: Proof regarding a function of bounded variation&lt;/p&gt;
&lt;p&gt;This is a nice proof that relies on the fact that a harmonic series is divergent.  &lt;/p&gt;
&lt;h3&gt;Show that the function&lt;/h3&gt;
&lt;p&gt;$f(x) = 
\begin{cases}
xcos\frac{\pi}{x}&amp;amp; \text{if }x \in (0,1] \\
0, &amp;amp; \text{if } x =0
\end{cases}$ &lt;/p&gt;
&lt;h3&gt;is not a function of bounded variation.&lt;/h3&gt;
&lt;p&gt;To show this function is not BV, we construct a sequence of partitions as follows:&lt;/p&gt;
&lt;p&gt;For each $m \in \mathbb{N}$ define $P_m = {0, \frac{1}{2m}, \frac{1}{2m-1}, \dots, \frac{1}{3}, \frac{1}{2}, 1 }$.  To check the function we evaluate it at those partition points and find $f(P_m) = {0, \frac{1}{2m}, \frac{1}{2m-1}, \dots, -\frac{1}{3}, -\frac{1}{2}, -1 }$ &lt;/p&gt;
&lt;p&gt;Next we consider the variation of $f$:  &lt;/p&gt;
&lt;p&gt;$\begin{align*}
\sum_{i=1}^{n} \left| f(x_i) - f(x_{i-1} \right| &amp;amp;= \left| \frac{1}{2m} - 0) \right| + \left|-\frac{1}{2m-1} - \frac{1}{2m} \right| + \left|\frac{1}{2m-2} \right| + \dots + \left| -\frac{1}{3} - \frac{1}{4} \right| + \left| \frac{1}{2} + \frac{1}{3} \right| + \left| -1 -\frac{1}{2} \right|
\\ &amp;amp;= \frac{1}{2m} + \frac{1}{2m-1} + \frac{1}{2m} + \frac{1}{2m} + \frac{1}{2m-2m} + \frac{1}{2m-1} + \dots + \frac{1}{3} + \frac{1}{4} + \frac{1}{2} + \frac{1}{3} + 1 + \frac{1}{2}
\\ &amp;amp;= 2(\frac{1}{2m} + \frac{1}{2m-1} + \dots +  \frac{1}{2}) + 1
\end{align*} $  &lt;/p&gt;
&lt;p&gt;This is a harmonic series in the form of $\sum_{n=2}^{\infty} \frac{1}{n}$ which is divergent.  So no matter what $M$ we choose for a bound, we can construct a partition for which the variation is unbounded.&lt;/p&gt;&lt;script type= "text/javascript"&gt;
    if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) {
        var mathjaxscript = document.createElement('script');
        mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#';
        mathjaxscript.type = 'text/javascript';
        mathjaxscript.src = 'https:' == document.location.protocol
                ? 'https://c328740.ssl.cf1.rackcdn.com/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML'
                : 'http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML';
        mathjaxscript[(window.opera ? "innerHTML" : "text")] =
            "MathJax.Hub.Config({" +
            "    config: ['MMLorHTML.js']," +
            "    TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'AMS' } }," +
            "    jax: ['input/TeX','input/MathML','output/HTML-CSS']," +
            "    extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js']," +
            "    displayAlign: 'center'," +
            "    displayIndent: '0em'," +
            "    showMathMenu: true," +
            "    tex2jax: { " +
            "        inlineMath: [ ['$','$'] ], " +
            "        displayMath: [ ['$$','$$'] ]," +
            "        processEscapes: true," +
            "        preview: 'TeX'," +
            "    }, " +
            "    'HTML-CSS': { " +
            "        styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'black ! important'} }" +
            "    } " +
            "}); ";
        (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript);
    }
&lt;/script&gt;
</content><category term="math"></category></entry><entry><title>Proof by induction</title><link href="http://mattobrien.me/proof-by-induction.html" rel="alternate"></link><published>2015-11-11T00:00:00-08:00</published><updated>2015-11-11T00:00:00-08:00</updated><author><name>Matt O'Brien</name></author><id>tag:mattobrien.me,2015-11-11:/proof-by-induction.html</id><summary type="html">&lt;p&gt;Proof by induction&lt;/p&gt;</summary><content type="html">&lt;p&gt;Good example of a proof by induction. The problem is from a chapter in the book &lt;a href="http://bulletin.sfsu.edu/sfstatebulletin/courses/40444"&gt;The Art of Proof&lt;/a&gt;.&lt;/p&gt;
&lt;h3&gt;For $x\not = 1$ and $k \in\mathbb{Z_{{\geq}0}}$, prove that $\displaystyle\sum\limits_{j=0}^k x^j =\frac {1-x^{k+1}}{1-x}$&lt;/h3&gt;
&lt;p&gt;We proceed by proof by Induction.&lt;br&gt;
Let $P(k)$ denote the statement  $\displaystyle\sum\limits_{j=0}^k x^j =\frac {1-x^{k+1}}{1-x}$.&lt;br&gt;
Checking the base case, in this case $k=0$, we show that  \begin{align*}&lt;br&gt;
P(0) &amp;amp;=\displaystyle\sum\limits_{j=0}^0 x^j \\
&amp;amp;=\frac {1-x^{0+1}}{1-x}\\
&amp;amp;=\frac {1-x}{1-x}\\
&amp;amp;=1.
\end{align*}
Now, we assume $P(k)$ to be true, that is $\displaystyle\sum\limits_{j=0}^k x^j =\frac {1-x^{k+1}}{1-x}$. 
Next we show  $P(k+1)$ to be true, that is
\begin{align*}
\displaystyle\sum\limits_{j=0}^{k+1} x^j &amp;amp;= \displaystyle\sum\limits_{j=0}^k x^j + x^{k+1}\\
&amp;amp;= \frac {1-x^{k+1}}{1-k} +   {x^{k+1}}   \text{             by the induction hypothesis}\\
&amp;amp;=  \frac {1-x^{k+1}}{1-x} +  \frac {x^{k+1}*({1-x})}{1-x}\\
&amp;amp;=\frac{1-x^{k+1}+x^{k+1}-x^{k+1+1}}{1-x}\\
&amp;amp;=\frac{1-x^{k+2}}{1-x}.\\
\end{align*}. &lt;/p&gt;&lt;script type= "text/javascript"&gt;
    if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) {
        var mathjaxscript = document.createElement('script');
        mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#';
        mathjaxscript.type = 'text/javascript';
        mathjaxscript.src = 'https:' == document.location.protocol
                ? 'https://c328740.ssl.cf1.rackcdn.com/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML'
                : 'http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML';
        mathjaxscript[(window.opera ? "innerHTML" : "text")] =
            "MathJax.Hub.Config({" +
            "    config: ['MMLorHTML.js']," +
            "    TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'AMS' } }," +
            "    jax: ['input/TeX','input/MathML','output/HTML-CSS']," +
            "    extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js']," +
            "    displayAlign: 'center'," +
            "    displayIndent: '0em'," +
            "    showMathMenu: true," +
            "    tex2jax: { " +
            "        inlineMath: [ ['$','$'] ], " +
            "        displayMath: [ ['$$','$$'] ]," +
            "        processEscapes: true," +
            "        preview: 'TeX'," +
            "    }, " +
            "    'HTML-CSS': { " +
            "        styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'black ! important'} }" +
            "    } " +
            "}); ";
        (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript);
    }
&lt;/script&gt;
</content><category term="math"></category></entry><entry><title>Convex Optimization #1</title><link href="http://mattobrien.me/convex-optimization-1.html" rel="alternate"></link><published>2015-02-08T00:00:00-08:00</published><updated>2015-02-08T00:00:00-08:00</updated><author><name>Matt O'Brien</name></author><id>tag:mattobrien.me,2015-02-08:/convex-optimization-1.html</id><summary type="html">&lt;p&gt;Convext Optimization proof #1&lt;/p&gt;</summary><content type="html">&lt;p&gt;I don't think this is an exceptionally groundbreaking proof, but I was going through some papers from when I took &lt;a href="http://bulletin.sfsu.edu/sfstatebulletin/courses/40444"&gt;mathematical modeling&lt;/a&gt; some time ago.&lt;/p&gt;
&lt;h3&gt;Show from first principles that if $f^1$, $f^2$,...,$f^k$ : $\mathbb{R^n} \rightarrow \mathbb{R}$ are convex (concave) functions with the same domain, and if $\omega_1$,...,$\omega_k$ are non-negative scalars, then the function $\omega_1 f^1 +$...$+ \omega_k f^k$ is also convex (concave).&lt;/h3&gt;
&lt;p&gt;Given $f^1$, $f^2$,...,$f^k$ as convex functions and $\omega_1$,...,$\omega_k$ as non-negative scalars, we need to show that $\omega_1 f^1 +$...$+ \omega_k f^k$ is also convex; that is, $\sum_{i = 1}^k \omega_i f_i$ is a convex function.&lt;/p&gt;
&lt;p&gt;Using first principles, we consider a linear combination $\lambda x + (1 - \lambda)y$ where $\lambda \in [0, 1]$, $x, y \in $ the domain of all $f^k$.&lt;/p&gt;
&lt;p&gt;$$\begin{align*}
f(\lambda x + (1 - \lambda)y &amp;amp;= \sum_{i=1}^k \omega_i f_i (\lambda x + (1 - \lambda )y) 
\\ &amp;amp;\leq \sum_{i=1}^k \omega_i (\lambda f_i (x) + (1- \lambda) f_i(y)) 
\\ &amp;amp;= \lambda \sum_{i =1}^k \omega_i f_i(x) = (1 - \lambda) \sum_{i =1}^k \omega f_i(y)
\\ &amp;amp;= \lambda f(x) + (1 - \lambda) f(x).
\end{align*}$$&lt;/p&gt;
&lt;p&gt;Thus we have shown that convexity holds under this operation.&lt;/p&gt;&lt;script type= "text/javascript"&gt;
    if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) {
        var mathjaxscript = document.createElement('script');
        mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#';
        mathjaxscript.type = 'text/javascript';
        mathjaxscript.src = 'https:' == document.location.protocol
                ? 'https://c328740.ssl.cf1.rackcdn.com/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML'
                : 'http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML';
        mathjaxscript[(window.opera ? "innerHTML" : "text")] =
            "MathJax.Hub.Config({" +
            "    config: ['MMLorHTML.js']," +
            "    TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'AMS' } }," +
            "    jax: ['input/TeX','input/MathML','output/HTML-CSS']," +
            "    extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js']," +
            "    displayAlign: 'center'," +
            "    displayIndent: '0em'," +
            "    showMathMenu: true," +
            "    tex2jax: { " +
            "        inlineMath: [ ['$','$'] ], " +
            "        displayMath: [ ['$$','$$'] ]," +
            "        processEscapes: true," +
            "        preview: 'TeX'," +
            "    }, " +
            "    'HTML-CSS': { " +
            "        styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'black ! important'} }" +
            "    } " +
            "}); ";
        (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript);
    }
&lt;/script&gt;
</content><category term="math"></category></entry><entry><title>Lebesgue measure #2</title><link href="http://mattobrien.me/lebesgue-measure-2.html" rel="alternate"></link><published>2014-07-17T00:00:00-07:00</published><updated>2014-07-17T00:00:00-07:00</updated><author><name>Matt O'Brien</name></author><id>tag:mattobrien.me,2014-07-17:/lebesgue-measure-2.html</id><summary type="html">&lt;p&gt;Lebesgue measure #2&lt;/p&gt;</summary><content type="html">&lt;p&gt;This is a proof of basic closure-type properties with respect to functions of bounded variation. I had the chance to study these when I took a class by Dr. Ovchinnikov, who was in the process of writing a &lt;a href="http://www.amazon.com/Measure-Integral-Derivative-Lebesgues-Universitext/dp/1461471958"&gt;book&lt;/a&gt; on the subject at the time.  &lt;/p&gt;
&lt;h3&gt;Show that the sum, difference and product of two BV-functions is a BV-function.&lt;/h3&gt;
&lt;p&gt;Let  $f$, $g$, be two BV functions over $[a, b]$.  Define a partition, $P = {x_i = 1 \leq i \leq n }.$  Then,  &lt;/p&gt;
&lt;p&gt;$
\begin{align*}
\sum_{i = 1}^{n} | (f + g )(x_i) - (f + g)(x_{i-1}) | &amp;amp;= \sum_{i = 1}^{n} | { f(x_i) + g(x_i) } - { f(x_{i - 1}) + g(x_{i-1}) } | \\  &amp;amp;\leq \sum_{i = 1}^{n} | f(x_i) - f(x_{i - 1}) | + \sum_{i = 1}^{n} | g(x_i) - g(x_{i - 1})|
\\  &amp;amp;\leq  V(f, P) + V(g, P)
\end{align*}$&lt;/p&gt;
&lt;p&gt;$\Rightarrow V(f + g, P) \leq V(f, P) + V(g, P) \leq V(f, P) + V(g, P)
\Rightarrow V(f + g, P) \leq V(f, P) + V(g, P).
$  &lt;/p&gt;
&lt;p&gt;Thus, $(f + g)$ is a function of bounded variation.&lt;/p&gt;
&lt;p&gt;To show that $(f - g)$ is of bounded variation, the proof is the same and $V(f - g) \leq V(f) + V(g)$&lt;/p&gt;
&lt;p&gt;To show that the product of two functions of bounded variation is also of bounded variation, notice that both $f$ and $g$ are bounded, and thus there exists $K \in \mathbb{N}$ such that
$|f(x)| \leq k, |g(x) | \leq k, \forall x \in P$.&lt;/p&gt;
&lt;p&gt;Thus, 
$$\begin{align*}
\sum_{i = 1}^{n} | (fg)(x_i) - (fg)(x_{i - 1}|&amp;amp;= \sum_{i = 1}^{n} | f(x_i)g(x_i) - f(x_{i -1})g(x{i - 1})|
\\ &amp;amp;= \sum_{i = 1}^{n} |f(x_i) {g(x_i) - g(x_{i - 1}) } + g(x_{i-1}) { f(x_i) - f(x_{i - 1}) } |
\\ &amp;amp;\leq \sum_{i = 1}^{n} { | f(x_i) | |g(x_i)  - g(x_{i - 1}) | + | g(x_{i - 1}) | | f(x_i) - f(x_{i - 1}) | }
\\ &amp;amp;\leq k \sum_{i = 1}^{n} |g(x_i) - g(x_{i-1}) | + k \sum_{i = 1}^{n} | f(x_i) - f(x_{i -1})|
\\ &amp;amp;\leq k V(g) + kV(f).
\end{align*}$$
and so the product of two functions of bounded variation is also of bounded variation.&lt;/p&gt;&lt;script type= "text/javascript"&gt;
    if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) {
        var mathjaxscript = document.createElement('script');
        mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#';
        mathjaxscript.type = 'text/javascript';
        mathjaxscript.src = 'https:' == document.location.protocol
                ? 'https://c328740.ssl.cf1.rackcdn.com/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML'
                : 'http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML';
        mathjaxscript[(window.opera ? "innerHTML" : "text")] =
            "MathJax.Hub.Config({" +
            "    config: ['MMLorHTML.js']," +
            "    TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'AMS' } }," +
            "    jax: ['input/TeX','input/MathML','output/HTML-CSS']," +
            "    extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js']," +
            "    displayAlign: 'center'," +
            "    displayIndent: '0em'," +
            "    showMathMenu: true," +
            "    tex2jax: { " +
            "        inlineMath: [ ['$','$'] ], " +
            "        displayMath: [ ['$$','$$'] ]," +
            "        processEscapes: true," +
            "        preview: 'TeX'," +
            "    }, " +
            "    'HTML-CSS': { " +
            "        styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'black ! important'} }" +
            "    } " +
            "}); ";
        (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript);
    }
&lt;/script&gt;
</content><category term="math"></category></entry><entry><title>Word frequencies for web pages</title><link href="http://mattobrien.me/word-frequencies-for-web-pages.html" rel="alternate"></link><published>2014-06-20T00:00:00-07:00</published><updated>2014-06-20T00:00:00-07:00</updated><author><name>Matt O'Brien</name></author><id>tag:mattobrien.me,2014-06-20:/word-frequencies-for-web-pages.html</id><summary type="html">&lt;p&gt;Using a few select Python packages, it's fairly painless to find top word counts&lt;/p&gt;</summary><content type="html">&lt;p&gt;This script will take any particular webpage (in this case, the wikipedia page for Machine Learning) and do a quick a dirty scrape then count of the words on the page. It is not particularly sophisticated and can be further customized and improved for whatever your purpose may be. &lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;urllib&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;bs4&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;BeautifulSoup&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;nltk.corpus&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;stopwords&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;collections&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;Counter&lt;/span&gt;

&lt;span class="c"&gt;## read contents from webpage&lt;/span&gt;
&lt;span class="n"&gt;f&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;urllib&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;urlopen&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;http://en.wikipedia.org/wiki/Machine_learning&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;contents&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;read&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;

&lt;span class="c"&gt;# create BS object&lt;/span&gt;
&lt;span class="n"&gt;soup&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;BeautifulSoup&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;contents&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="c"&gt;# clean text: lower case, remove trailing commas, remove words less than 2 characters long &lt;/span&gt;
&lt;span class="n"&gt;mytext&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;soup&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;get_text&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;span class="n"&gt;mytext&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;mytext&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;lower&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;span class="n"&gt;mytext&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;mytext&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;replace&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;,&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;&amp;quot; &amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;mytext&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s"&gt;&amp;#39; &amp;#39;&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;join&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;word&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;word&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;mytext&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;split&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt; &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;word&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="c"&gt;# remove stopwords&lt;/span&gt;
&lt;span class="n"&gt;filtered_words&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;w&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;w&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;mytext&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;split&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt; &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="ow"&gt;not&lt;/span&gt; &lt;span class="n"&gt;w&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;stopwords&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;words&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;english&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)]&lt;/span&gt;

&lt;span class="c"&gt;# return counts using counter object&lt;/span&gt;
&lt;span class="n"&gt;mycounts&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;Counter&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;filtered_words&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="k"&gt;print&lt;/span&gt; &lt;span class="n"&gt;mycounts&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;most_common&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;10&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;</content><category term="text"></category><category term="python"></category></entry><entry><title>pbinom for binomial distribution in R</title><link href="http://mattobrien.me/pbinom-for-binomial-distribution-in-r.html" rel="alternate"></link><published>2014-06-05T00:00:00-07:00</published><updated>2014-06-05T00:00:00-07:00</updated><author><name>Matt O'Brien</name></author><id>tag:mattobrien.me,2014-06-05:/pbinom-for-binomial-distribution-in-r.html</id><summary type="html">&lt;p&gt;A quick pop quiz to test your memory for working with probability distributions in R&lt;/p&gt;</summary><content type="html">&lt;p&gt;I love R. But it does has some things that are a bit irksome.  For example, I have found it somewhat difficult to remember which prefix corresponds to which function, when working with distributions. &lt;/p&gt;
&lt;p&gt;Here is a quick quiz:  &lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Given a binomial distribution:&lt;/strong&gt;&lt;br&gt;
&lt;strong&gt;dbinom ---&amp;gt; ?&lt;/strong&gt;&lt;br&gt;
&lt;strong&gt;pbinom ---&amp;gt;  ?&lt;/strong&gt;  &lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;probability mass function&lt;br&gt;
cumulative distribution function&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;cumulative distribution function&lt;br&gt;
 probability mass function  &lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;em&gt;Answer:  1&lt;/em&gt;  &lt;/p&gt;
&lt;p&gt;I am temped to choose 2, since pbinom feels like it should correspond with pdf.  After all, ‘p’ is the first initial of the first word in the phrase “probability mass function.”  However, that is not the case.&lt;/p&gt;</content><category term="statistics"></category><category term="R"></category></entry><entry><title>Lebesgue measure #1</title><link href="http://mattobrien.me/lebesgue-measure-1.html" rel="alternate"></link><published>2014-05-29T00:00:00-07:00</published><updated>2014-05-29T00:00:00-07:00</updated><author><name>Matt O'Brien</name></author><id>tag:mattobrien.me,2014-05-29:/lebesgue-measure-1.html</id><summary type="html">&lt;p&gt;Lebesgue measure #1&lt;/p&gt;</summary><content type="html">&lt;p&gt;Here is a fun proof that illuminates an important property of Lebesgue measure.  Note that the function $m()$ refers to measure.&lt;/p&gt;
&lt;h3&gt;Let $X$ be a closed subset of $[0,1]$ such that $m(X) = 1$.  Prove that $X = [0, 1]$.&lt;/h3&gt;
&lt;p&gt;Let $X$ be closed subset of $[0,1]$ such that $m(X) = 1$.  We need to show that $X= [0,1]$.  Let $a=inf(X)$ and let $b=sup(X)$.  Suppose, by contradiction, that $X \neq [0, 1]$.  Then, there are 3 cases for which $X=[0, 1]$.  &lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Case 1:&lt;/strong&gt;  $a &amp;gt; 0$.  By definition of measure, $m(X) = (b -a) - m([a, b]\backslash X) = 1$, but $(b - a) &amp;lt; 1$ and $m(X)$ cannot equal $1$.  &lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Case 2:&lt;/strong&gt;  $b &amp;gt; 1$.  Again, be definition of measure, we fnd that $(b - a) &amp;lt; 1$ and $m(X)$ cannot equal $1$.  &lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Case 3:&lt;/strong&gt;  $a = 0$, and b = $0$, since $b - a = 1$, and since $X = [0, 1]$, then $[0, 1]$ \ $X = 0$ which implies that $X$ must be equal to $[0, 1]$.&lt;/p&gt;&lt;script type= "text/javascript"&gt;
    if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) {
        var mathjaxscript = document.createElement('script');
        mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#';
        mathjaxscript.type = 'text/javascript';
        mathjaxscript.src = 'https:' == document.location.protocol
                ? 'https://c328740.ssl.cf1.rackcdn.com/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML'
                : 'http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML';
        mathjaxscript[(window.opera ? "innerHTML" : "text")] =
            "MathJax.Hub.Config({" +
            "    config: ['MMLorHTML.js']," +
            "    TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'AMS' } }," +
            "    jax: ['input/TeX','input/MathML','output/HTML-CSS']," +
            "    extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js']," +
            "    displayAlign: 'center'," +
            "    displayIndent: '0em'," +
            "    showMathMenu: true," +
            "    tex2jax: { " +
            "        inlineMath: [ ['$','$'] ], " +
            "        displayMath: [ ['$$','$$'] ]," +
            "        processEscapes: true," +
            "        preview: 'TeX'," +
            "    }, " +
            "    'HTML-CSS': { " +
            "        styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'black ! important'} }" +
            "    } " +
            "}); ";
        (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript);
    }
&lt;/script&gt;
</content><category term="math"></category></entry><entry><title>Muay Thai kick to the body</title><link href="http://mattobrien.me/muay-thai-kick-to-the-body.html" rel="alternate"></link><published>2014-05-21T00:00:00-07:00</published><updated>2014-05-21T00:00:00-07:00</updated><author><name>Matt O'Brien</name></author><id>tag:mattobrien.me,2014-05-21:/muay-thai-kick-to-the-body.html</id><summary type="html">&lt;p&gt;Biomechanics of a body kick&lt;/p&gt;</summary><content type="html">&lt;p&gt;My interest in human movement led me to doing some 3D modeling. I purchased an 8 strobe Optitrack system and asked an amateur fighter to put on the reflective suit and demonstrate his body kick. After I captured the movement, I discussed some of the findings in this animation.  &lt;/p&gt;
&lt;p&gt;The most interesting thing about the clip is the overhead view. I realized that nobody has ever considered what a kick looks like from the top: when you observe it from this position, it quickly becomes clear that the kick is generated from the top down -- the shoulder girdle clearly rotates first and reaches it's peak torque prior to the completion of the rotation of the pelvis. If you go train in muay thai, it's not uncommon to hear a reguritated coaching dogma, namely, "Turn your hip over", which is somewhat true but really just betrays a lack of ability to consider the kick as a movement that is fundamentally a top-down kinetic chain.   &lt;/p&gt;
&lt;p&gt;&lt;a href="http://www.youtube.com/watch?feature=player_embedded&amp;v=OPdRX5Poqo4
" target="_blank"&gt;&lt;img src="http://img.youtube.com/vi/OPdRX5Poqo4/0.jpg" 
alt="muay thai kick tutorial" width="240" height="180" border="10" /&gt;&lt;/a&gt;&lt;/p&gt;</content><category term="sport science"></category></entry><entry><title>Visualization in RShiny</title><link href="http://mattobrien.me/visualization-in-rshiny.html" rel="alternate"></link><published>2014-05-18T00:00:00-07:00</published><updated>2014-05-18T00:00:00-07:00</updated><author><name>Matt O'Brien</name></author><id>tag:mattobrien.me,2014-05-18:/visualization-in-rshiny.html</id><summary type="html">&lt;p&gt;Visualizing and interacting with data science jobs in the United States&lt;/p&gt;</summary><content type="html">&lt;p&gt;Using data from a popular job search website, I gathered a set of 2036 jobs for positions open for individuals proficient in data science. The motivation for this project is to visualize where data science jobs are in the United States as well as how much they pay.  &lt;/p&gt;
&lt;p&gt;You can find this visualization hosted &lt;a href="https://mattobriendotme.shinyapps.io/shinyapp/"&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;h1&gt;THE PROJECT:&lt;/h1&gt;
&lt;p&gt;Using data from a popular job search website, I gathered a set of 2036 jobs for positions open for individuals proficient in data science.   &lt;/p&gt;
&lt;p&gt;The fields in the data consisted of job description, company name, salary, city, state and zipcode.  &lt;/p&gt;
&lt;p&gt;The motivation for this project is to visualize where data science jobs are in the United States as well as how much they pay.  &lt;/p&gt;
&lt;h1&gt;VISUALIZATION #1: COUNTRY MAP&lt;/h1&gt;
&lt;p&gt;The first visualization is of a map of the continental United States.  The idea here was to obtain a broad overview of which areas in which states have the most jobs.  &lt;/p&gt;
&lt;p&gt;You can interact with this map in a number of ways:  &lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Select which states you want to see and don't want to see  &lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Use a slider to narrow the results down to jobs that pay within a specific salary range&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;You can manage overplotting by adjusting the alpha value&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;You can mange overplotting by introducing jitter to the points&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The data began as zipcode information.  Using the &lt;code&gt;library(zipcode)&lt;/code&gt; package, the zipcode data was transformed into longitude and latitude coordinates.  &lt;/p&gt;
&lt;p&gt;The data showed me that most of the jobs reside in the Bay Area of California.  There aren't many jobs in the Midwest or South, and there are a good amount of jobs in Washington and Texas.  &lt;/p&gt;
&lt;p&gt;Originally I was using red dots (it looked like the map had chicken pox).  I changed to circles and changed the color to green.  I also added state initials, even though it required me to post a question on StackOverflow which you can view &lt;a href="http://stackoverflow.com/questions/23447760/include-borders-and-state-abbreviations-when-using-the-map-function-with-the-map"&gt;here&lt;/a&gt;.  &lt;/p&gt;
&lt;p&gt;This map has good data density and data-to-ink ratio.  The lie factor is increased when the jitter is used, considerably.  Sometimes, some points in Washington jump into Canada.  &lt;/p&gt;
&lt;p&gt;The interactivity enhances the visualization in the sense that it makes the locations visible and simple to view.  &lt;/p&gt;
&lt;p&gt;I also am happy all four methods of interaction.  Here is a screenshot of the visualization with and without jitter:  &lt;/p&gt;
&lt;p&gt;&lt;img alt="vis" src="https://github.com/mobbSF/msan622/blob/master/final-project/001.png?raw=true"&gt;&lt;/p&gt;
&lt;p&gt;One problem is the inability to adjust all states.  I chose a checkbox for the States, and as much as I wanted to, I wasn't able include all 48 states due, simply, to lack of space.  A better control would have allowed me to subset on certain important States.  To me, this is a major, major flaw in my visualization.  The question remains, how can a user intuitively and easily select any combination of 48 states when there is limited space on the graphic?  My solution is to remove control from the user, which is not ideal.  &lt;/p&gt;
&lt;h1&gt;VISUALIZATION #2:  CLOROPLETH&lt;/h1&gt;
&lt;p&gt;This map is a cloropleth, which is somewhat of a combination of a heatmap and geographic map.  &lt;/p&gt;
&lt;p&gt;&lt;img alt="vis" src="https://github.com/mobbSF/msan622/blob/master/final-project/002.png?raw=true"&gt;&lt;/p&gt;
&lt;p&gt;When you think of a cloropleth, or even a heatmap in general, trying to incorporate interactivity can be a difficult task.  After all, a heatmap pretty much shows everything...perhaps the granularity of binning can be adjusted, but what else?  &lt;/p&gt;
&lt;p&gt;I chose to approach this in a way that made sense to me.  The way this map works, is the view all of the states together to see how they relate to each other.  Now, we slow remove states, one by one, and each time, watch the choropleth regenerate, and rescale itself to show how the remaining states are distributed.  So, if you didn't want to live in CA, you could remove it, and see a "new" heatmap, based on the remaining parts of the country.  &lt;/p&gt;
&lt;p&gt;Here, the colors are mapped to the total sum of all salaries.  For example, there is about 5 million dollars worth of salary to be earned in California, which makes the color dark green.  &lt;/p&gt;
&lt;p&gt;This plot is really another attempt to see how many jobs in each state exist.  The first visualization, naturally suffers from intense overplotting.  The choropleth generalizes the jobs to fit within a state, not just a tiny point surrounded by a hollow circle.  In retrospect, this plot is a little more general in nature than plot 1, and maybe I should have switched the order of these plots to guarantee that the plots are in general --&amp;gt; specific order.   &lt;/p&gt;
&lt;p&gt;I like the creative way to burrow deep into specific combinations of jobs, depending on which states you choose to exclude.  Once you get used to this idea, it makes a lot of sense.  &lt;/p&gt;
&lt;p&gt;I had to use the &lt;code&gt;choroplethr&lt;/code&gt; package, which is so different than the first plot.  Making the two of them match was difficult.  Even matching the colors (which is still imperfect) was a major challenge and required me to get creative.  &lt;/p&gt;
&lt;h1&gt;VISUALIZATION #3: SINGLE STATE BUBBLEPLOT&lt;/h1&gt;
&lt;p&gt;Visualization 3 moves us into looking at single states, where we can see more clearly exactly where the jobs reside.  Here is an example of just one of the states you can zoom in on, Washington:  &lt;/p&gt;
&lt;p&gt;&lt;img alt="vis" src="https://github.com/mobbSF/msan622/blob/master/final-project/003.png?raw=true"&gt;&lt;/p&gt;
&lt;p&gt;Here, we have:  &lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Selecting the particular state in a dropdown menu  &lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Adjusting salary as in the first map  &lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Adjusting alpha  &lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Adding jitter &lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The data was encoded in the same way as the first plot, just further subsetted by state, and more importantly, salary was mapped to the size of the circular point.  &lt;/p&gt;
&lt;p&gt;This visualization is nice, since now we get a better feel for which specific areas these jobs are in.  As the visualizations go, they attempt to get more and granular in nature, and this plot makes a big jump in that direction.  Also, it is really important to realize this is a bubbleplot, and now we can see the salary related to specific jobs, which was prior not easy to see on such an individualized basis.  &lt;/p&gt;
&lt;p&gt;Since the states are just simple polygons, they aren't very exciting.  I added some fill as color (grey90) which helped.  &lt;/p&gt;
&lt;p&gt;This plot, due to the lack of color and texture, clearly has a fantastic data to ink ratio. The lie factor is fine and the data density is good too.  In retrospect, I could have removed the jitter option, which would have kept the lie factor down.  I am not convinced that jitter is useful at this level anyways.  It could easily move a job from one city to another.  &lt;/p&gt;
&lt;p&gt;The alpha is always necessary, I suspect, except for sparse states like Kansas where there aren't any overlapping jobs.  The ability to zoom in by selecting a particular state is crucial.  Jitter, as mentioned prior, isn't exceptionally important.  &lt;/p&gt;
&lt;p&gt;The plot generates single states, which is a somewhat unorthodox way to create a plot.  I like the dropdown menu and I am glad that I was able to make all the plots resize to fill up the space, even though I finally had to post another StackOverflow question &lt;a href="http://stackoverflow.com/questions/23449033/how-to-resize-a-state-when-using-the-map-function-in-the-mapproj-library-in-r"&gt;here&lt;/a&gt;.  &lt;/p&gt;
&lt;p&gt;I originally wanted to find some way to 'grey out' the controls that aren't being used in this plot, since it's hard to even find the dropdown menu way at the bottom.  &lt;/p&gt;
&lt;h1&gt;VISUALIZATION #4: BAR PLOT&lt;/h1&gt;
&lt;p&gt;This chart can be sorted as seen below:  &lt;/p&gt;
&lt;p&gt;&lt;img alt="vis" src="https://github.com/mobbSF/msan622/blob/master/final-project/004.png?raw=true"&gt;  &lt;/p&gt;
&lt;p&gt;The data was summed and encoded as scalars with which to plot the number of jobs in each state.  &lt;/p&gt;
&lt;p&gt;Strangely enough, a simple bar chart might be the most interesting plot of all 4.  Why? Because, finally, we get a numeric representation of the distribution of jobs out there.  Up until now, we've had to rely on color, shape, and space to do so.  Now, we finally hit the nail on the head and with this bar chart, we can see exactly what the job market looked like at this given time, across the country.  &lt;/p&gt;
&lt;p&gt;Of course ordering in a bar chart is always a good idea when it comes to interactivity (or at least I suspect this is true).  It only takes a glance to see the relationship between the states and how they come together.  &lt;/p&gt;
&lt;p&gt;I was glad that I was able to remove that annoying area between the x and y axis, remove the tickmarks as I wanted, and otherwise to the customary cleanup on ggplot that we've practiced up to now.  &lt;/p&gt;
&lt;p&gt;There is no end to how much work you can put into a good visualization -- this project provided me with lots of appreciation as to how difficult a good vis really is to construct.  For example, was it worth the hours it took to figure out how to give this custom error message?  &lt;/p&gt;
&lt;p&gt;&lt;img alt="vis" src="https://github.com/mobbSF/msan622/blob/master/final-project/005.gif?raw=true"&gt;  &lt;/p&gt;
&lt;p&gt;Who knows.  But, I also now have more appreciation for why lots of visualizations are hard to read.  This is a large and deep field.  &lt;/p&gt;</content><category term="visualization"></category></entry><entry><title>sentiment prediction with Naive Bayes</title><link href="http://mattobrien.me/sentiment-prediction-with-naive-bayes.html" rel="alternate"></link><published>2014-05-01T00:00:00-07:00</published><updated>2014-05-01T00:00:00-07:00</updated><author><name>Matt O'Brien</name></author><id>tag:mattobrien.me,2014-05-01:/sentiment-prediction-with-naive-bayes.html</id><summary type="html">&lt;p&gt;Predicting positive or negative Amazon movie reviews&lt;/p&gt;</summary><content type="html">&lt;p&gt;This project consists of two sets of labelled text reviews (&lt;a href="https://www.dropbox.com/sh/n2r4e929ahzx84o/AABdDVQ1Rlygs-XkjTytn3bAa"&gt;positive&lt;/a&gt; and &lt;a href="https://www.dropbox.com/sh/scnnjiotbltm2za/AAAGz7NsEoG61ojzgZZQPfV-a"&gt;negative&lt;/a&gt;) for movies.  &lt;/p&gt;
&lt;p&gt;These are used as the training set; the words are split into unigrams, and the words are classified as either positive or negative given their frequencies. &lt;/p&gt;
&lt;p&gt;Once the model is built, the test set is used to help determine the accuracy of the model.  &lt;/p&gt;
&lt;p&gt;This is an early project I did some time ago, please forgive some of the less graceful elements.  &lt;/p&gt;
&lt;p&gt;The algorithm uses these steps:  &lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;For each iteration&lt;br&gt;
(a) Randomly divide your data in training and testing using 1/3 for
testing and 2/3 for training.&lt;br&gt;
(b) Use the training set to estimate the parameters $P(w|c)$ and $P(c)$ as per the naive bayes statement&lt;br&gt;
(c) For every document in the training set use the equation $$c^{*}=argmax_{c}log(P(c)) + \sum_{i=1}^{M}n_{i}(d) * log(P(w_{i}|c))$$ to compute $P(c|d)$ and predict the class c.&lt;br&gt;
(d) Compute the accuracy of the testing set.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Do at least 3 iterations to compute the average accuracy as your performance metric.  &lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;The output will print results for each iteration, giving key metrics like this:&lt;/p&gt;
&lt;p&gt;iteration 1:&lt;br&gt;
    num pos test_docs:333&lt;br&gt;
    num pos training docs:667&lt;br&gt;
    num pos correct_docs:267&lt;br&gt;
    num neg test_docs:331&lt;br&gt;
    num neg training_docs:669&lt;br&gt;
    num neg correct_docs:261&lt;br&gt;
    accuracy:79%&lt;br&gt;
iteration 2:&lt;br&gt;
    ...&lt;br&gt;
iteration 3:&lt;br&gt;
    ...&lt;br&gt;
ave_accuracy:80.3%  &lt;/p&gt;
&lt;p&gt;Make sure to include the command line parameters &lt;code&gt;python naive-bayes.py -d my_directory&lt;/code&gt; where &lt;code&gt;my_directory&lt;/code&gt; is the path to the directory that holds the positive and negative reviews along with the python script.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="c"&gt;#!/usr/bin/env python&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;argparse&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;os&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;random&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;math&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;collections&lt;/span&gt;

&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;parseArgument&lt;/span&gt;&lt;span class="p"&gt;():&lt;/span&gt;
    &lt;span class="c"&gt;### Code for parsing arguments&lt;/span&gt;
    &lt;span class="n"&gt;parser&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;argparse&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;ArgumentParser&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;description&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;Parsing a file.&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;parser&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;add_argument&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;-d&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;nargs&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;required&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="bp"&gt;True&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;args&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nb"&gt;vars&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;parser&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;parse_args&lt;/span&gt;&lt;span class="p"&gt;())&lt;/span&gt;
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;args&lt;/span&gt; 
&lt;span class="c"&gt;###  This function takes the directory path and divides the file names found in the pos / neg directories&lt;/span&gt;
&lt;span class="c"&gt;###  into the proper proportions, stored into a dict named &amp;#39;D&amp;#39;.&lt;/span&gt;
&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;CreateD&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;directory&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="n"&gt;pos_train&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[]&lt;/span&gt;
    &lt;span class="n"&gt;pos_test&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[]&lt;/span&gt;
    &lt;span class="n"&gt;neg_train&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[]&lt;/span&gt;
    &lt;span class="n"&gt;neg_test&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[]&lt;/span&gt;
    &lt;span class="n"&gt;pos&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;directory&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="s"&gt;&amp;#39;/pos&amp;#39;&lt;/span&gt;
    &lt;span class="n"&gt;neg&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;directory&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="s"&gt;&amp;#39;/neg&amp;#39;&lt;/span&gt;
    &lt;span class="n"&gt;pos_names&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;os&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;listdir&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;pos&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;neg_names&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;os&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;listdir&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;neg&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;random&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;shuffle&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;pos_names&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;random&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;shuffle&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;neg_names&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="k"&gt;while&lt;/span&gt; &lt;span class="n"&gt;pos_names&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="n"&gt;pos_train&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;append&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;pos_names&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;pop&lt;/span&gt;&lt;span class="p"&gt;())&lt;/span&gt;
        &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;pos_names&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
            &lt;span class="n"&gt;pos_train&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;append&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;pos_names&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;pop&lt;/span&gt;&lt;span class="p"&gt;())&lt;/span&gt;
        &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;pos_names&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
            &lt;span class="n"&gt;pos_test&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;append&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;pos_names&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;pop&lt;/span&gt;&lt;span class="p"&gt;())&lt;/span&gt;
    &lt;span class="k"&gt;while&lt;/span&gt; &lt;span class="n"&gt;neg_names&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="n"&gt;neg_train&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;append&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;neg_names&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;pop&lt;/span&gt;&lt;span class="p"&gt;())&lt;/span&gt;
        &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;neg_names&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
            &lt;span class="n"&gt;neg_train&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;append&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;neg_names&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;pop&lt;/span&gt;&lt;span class="p"&gt;())&lt;/span&gt;
        &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;neg_names&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
            &lt;span class="n"&gt;neg_test&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;append&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;neg_names&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;pop&lt;/span&gt;&lt;span class="p"&gt;())&lt;/span&gt;
    &lt;span class="n"&gt;fileDict&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;{}&lt;/span&gt;
    &lt;span class="n"&gt;fileDict&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;pos_train&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;pos_train&lt;/span&gt;
    &lt;span class="n"&gt;fileDict&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;pos_test&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;pos_test&lt;/span&gt;
    &lt;span class="n"&gt;fileDict&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;neg_train&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;neg_train&lt;/span&gt;
    &lt;span class="n"&gt;fileDict&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;neg_test&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;neg_test&lt;/span&gt;
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;fileDict&lt;/span&gt;

&lt;span class="c"&gt;### This function used a counter object to count the number of documents in the class &amp;#39;pos&amp;#39; or &amp;#39;neg&amp;#39;.  This is used&lt;/span&gt;
&lt;span class="c"&gt;### for printing summary statistics at the end.&lt;/span&gt;
&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;CountDocsInClass&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;directory&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;subdir&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;file_list&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="n"&gt;cntr&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;collections&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Counter&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
    &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="nb"&gt;file&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;file_list&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="n"&gt;f&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nb"&gt;open&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;directory&lt;/span&gt;&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;/&amp;#39;&lt;/span&gt;&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="n"&gt;subdir&lt;/span&gt;&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;/&amp;#39;&lt;/span&gt;&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="nb"&gt;file&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="c"&gt;#open each File&lt;/span&gt;
        &lt;span class="n"&gt;cntr&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;cntr&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;collections&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Counter&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="n"&gt;t&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;t&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;read&lt;/span&gt;&lt;span class="p"&gt;())&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;split&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt; &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="ow"&gt;not&lt;/span&gt; &lt;span class="n"&gt;t&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;stopWords&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;&lt;span class="c"&gt;#add word counts to counter object&lt;/span&gt;
        &lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;close&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;&lt;span class="c"&gt;#Close each File&lt;/span&gt;
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;cntr&lt;/span&gt;

&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;main&lt;/span&gt;&lt;span class="p"&gt;():&lt;/span&gt;
    &lt;span class="n"&gt;args&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;parseArgument&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
    &lt;span class="n"&gt;directory&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;args&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;d&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;][&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
    &lt;span class="c"&gt;# variable for calculating average accuracy&lt;/span&gt;
    &lt;span class="n"&gt;tot_acc&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;
    &lt;span class="c"&gt;# Iterations&lt;/span&gt;
    &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;step&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="nb"&gt;range&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;4&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;

&lt;span class="c"&gt;### Here is the training code:&lt;/span&gt;
&lt;span class="c"&gt;### First we create the dictionary of filenames using the CreateD function.&lt;/span&gt;
        &lt;span class="n"&gt;file_dict&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;CreateD&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;directory&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="c"&gt;### Here we count the number of documents in the &amp;#39;pos&amp;#39; and &amp;#39;neg&amp;#39; class using the CountDocsInClass function.&lt;/span&gt;
        &lt;span class="n"&gt;positive_counter&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;CountDocsInClass&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;directory&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;pos&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;file_dict&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;pos_train&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
        &lt;span class="n"&gt;negative_counter&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;CountDocsInClass&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;directory&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;neg&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;file_dict&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;neg_train&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
&lt;span class="c"&gt;### These 2 lines find a total count in the counters for each class.&lt;/span&gt;
        &lt;span class="n"&gt;tot_cnt_pos&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="nb"&gt;float&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;sum&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;positive_counter&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;values&lt;/span&gt;&lt;span class="p"&gt;()))&lt;/span&gt;
        &lt;span class="n"&gt;tot_cnt_neg&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="nb"&gt;float&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;sum&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;negative_counter&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;values&lt;/span&gt;&lt;span class="p"&gt;()))&lt;/span&gt;
&lt;span class="c"&gt;### We create V, as specified in the Vocabulary list&lt;/span&gt;
        &lt;span class="n"&gt;V&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nb"&gt;set&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;positive_counter&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;keys&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;&lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;negative_counter&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;keys&lt;/span&gt;&lt;span class="p"&gt;())&lt;/span&gt;
&lt;span class="c"&gt;### The final_dict will hold the conditional probabilities for each t in V&lt;/span&gt;
        &lt;span class="n"&gt;final_dict&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;{}&lt;/span&gt;
        &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;t&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;V&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
            &lt;span class="n"&gt;final_dict&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;t&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;pos&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;:(&lt;/span&gt;&lt;span class="n"&gt;positive_counter&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;t&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="mf"&gt;1.0&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;tot_cnt_pos&lt;/span&gt;&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;V&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;neg&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;:(&lt;/span&gt;&lt;span class="n"&gt;negative_counter&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;t&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="mf"&gt;1.0&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;tot_cnt_neg&lt;/span&gt;&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;V&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)}&lt;/span&gt;
&lt;span class="c"&gt;### calculating prior probabilities for each class&lt;/span&gt;
        &lt;span class="n"&gt;pos_prior&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;file_dict&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;pos_train&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="nb"&gt;float&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;file_dict&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;pos_train&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="nb"&gt;float&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;file_dict&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;neg_train&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;])))&lt;/span&gt;
        &lt;span class="n"&gt;neg_prior&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;file_dict&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;neg_train&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="nb"&gt;float&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;file_dict&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;pos_train&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="nb"&gt;float&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;file_dict&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;neg_train&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;])))&lt;/span&gt;
&lt;span class="c"&gt;### This code is for the Testing part of the Naive Bayes algorithm&lt;/span&gt;
&lt;span class="c"&gt;### We create a list of classes&lt;/span&gt;
        &lt;span class="n"&gt;C&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;pos&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;neg&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;span class="c"&gt;### initializing filescore dictionary to keep track of test data - has the test file as key and four other associated&lt;/span&gt;
        &lt;span class="c"&gt;# parameters namely:&lt;/span&gt;
        &lt;span class="c"&gt;#                   orig    -  is file originally +ve or -ve&lt;/span&gt;
        &lt;span class="c"&gt;#                   pos     -  sum of log probs for +ve class&lt;/span&gt;
        &lt;span class="c"&gt;#                   neg     -  sum of log probs for +ve class&lt;/span&gt;
        &lt;span class="c"&gt;#                   output  -  output file classification after comparing &amp;#39;pos&amp;#39; and &amp;#39;neg&amp;#39;&lt;/span&gt;
        &lt;span class="n"&gt;filescore&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;{}&lt;/span&gt;
        &lt;span class="c"&gt;# for all test files combined run loop&lt;/span&gt;
        &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="nb"&gt;file&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;file_dict&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;pos_test&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="n"&gt;file_dict&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;neg_test&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]):&lt;/span&gt;
            &lt;span class="c"&gt;# initialize  the file dictionary within filescore dictionary&lt;/span&gt;
            &lt;span class="n"&gt;filescore&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="nb"&gt;file&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;{}&lt;/span&gt;
            &lt;span class="c"&gt;# populate &amp;#39;orig&amp;#39; attribute for each file i.e. filescore[file][&amp;#39;orig&amp;#39;]&lt;/span&gt;
            &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="nb"&gt;file&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;file_dict&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;pos_test&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]:&lt;/span&gt;
                &lt;span class="n"&gt;f&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nb"&gt;open&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;directory&lt;/span&gt;&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;/pos/&amp;#39;&lt;/span&gt;&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="nb"&gt;file&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="c"&gt;#open each File&lt;/span&gt;
                &lt;span class="n"&gt;filescore&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="nb"&gt;file&lt;/span&gt;&lt;span class="p"&gt;][&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;orig&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s"&gt;&amp;#39;pos&amp;#39;&lt;/span&gt;
            &lt;span class="k"&gt;else&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
                &lt;span class="n"&gt;f&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nb"&gt;open&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;directory&lt;/span&gt;&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;/neg/&amp;#39;&lt;/span&gt;&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="nb"&gt;file&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="c"&gt;#open each File&lt;/span&gt;
                &lt;span class="n"&gt;filescore&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="nb"&gt;file&lt;/span&gt;&lt;span class="p"&gt;][&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;orig&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s"&gt;&amp;#39;neg&amp;#39;&lt;/span&gt;
            &lt;span class="c"&gt;# extract all words for the given file into t_list after removing stopwords&lt;/span&gt;
            &lt;span class="n"&gt;t_list&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;t&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;t&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;read&lt;/span&gt;&lt;span class="p"&gt;())&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;split&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt; &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="ow"&gt;not&lt;/span&gt; &lt;span class="n"&gt;t&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;stopWords&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
            &lt;span class="c"&gt;# within a file run the below loop for each class to sum the log probabilities for each class&lt;/span&gt;
            &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;clss&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;C&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
                &lt;span class="c"&gt;# initializing score variable with prior probbabilities&lt;/span&gt;
                &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;clss&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="s"&gt;&amp;#39;pos&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
                    &lt;span class="n"&gt;score&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;math&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;log&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;pos_prior&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
                &lt;span class="k"&gt;else&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
                    &lt;span class="n"&gt;score&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;math&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;log&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;neg_prior&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="c"&gt;### The code below takes logs as per pseudocode&lt;/span&gt;
                &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;t&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;t_list&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
                    &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;final_dict&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;has_key&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;t&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
                        &lt;span class="n"&gt;score&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;score&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;math&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;log&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;final_dict&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;t&lt;/span&gt;&lt;span class="p"&gt;][&lt;/span&gt;&lt;span class="n"&gt;clss&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
                    &lt;span class="c"&gt;# handling unknown words in test file&lt;/span&gt;
                    &lt;span class="k"&gt;else&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
                        &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;clss&lt;/span&gt;&lt;span class="o"&gt;==&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;pos&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
                            &lt;span class="n"&gt;score&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;score&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;tot_cnt_pos&lt;/span&gt;&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;V&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
                        &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;clss&lt;/span&gt;&lt;span class="o"&gt;==&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;neg&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
                            &lt;span class="n"&gt;score&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;score&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;tot_cnt_neg&lt;/span&gt;&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;V&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
                &lt;span class="n"&gt;filescore&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="nb"&gt;file&lt;/span&gt;&lt;span class="p"&gt;][&lt;/span&gt;&lt;span class="n"&gt;clss&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;score&lt;/span&gt;
&lt;span class="c"&gt;###   Counting the results&lt;/span&gt;
            &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;filescore&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="nb"&gt;file&lt;/span&gt;&lt;span class="p"&gt;][&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;pos&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;&amp;gt;&lt;/span&gt; &lt;span class="n"&gt;filescore&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="nb"&gt;file&lt;/span&gt;&lt;span class="p"&gt;][&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;neg&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]):&lt;/span&gt;
                &lt;span class="n"&gt;filescore&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="nb"&gt;file&lt;/span&gt;&lt;span class="p"&gt;][&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;output&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s"&gt;&amp;#39;pos&amp;#39;&lt;/span&gt;
            &lt;span class="k"&gt;else&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
                &lt;span class="n"&gt;filescore&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="nb"&gt;file&lt;/span&gt;&lt;span class="p"&gt;][&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;output&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s"&gt;&amp;#39;neg&amp;#39;&lt;/span&gt;
            &lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;close&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;

&lt;span class="c"&gt;###   Create some counters to track the numbers of successes for each class&lt;/span&gt;
        &lt;span class="n"&gt;count_positive_success&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;
        &lt;span class="n"&gt;count_negative_success&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;
        &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;fl&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;filescore&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
            &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="p"&gt;((&lt;/span&gt;&lt;span class="n"&gt;filescore&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;fl&lt;/span&gt;&lt;span class="p"&gt;][&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;orig&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="s"&gt;&amp;#39;pos&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="ow"&gt;and&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;filescore&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;fl&lt;/span&gt;&lt;span class="p"&gt;][&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;output&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="n"&gt;filescore&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;fl&lt;/span&gt;&lt;span class="p"&gt;][&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;orig&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;])):&lt;/span&gt;
                &lt;span class="n"&gt;count_positive_success&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;count_positive_success&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;
            &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="p"&gt;((&lt;/span&gt;&lt;span class="n"&gt;filescore&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;fl&lt;/span&gt;&lt;span class="p"&gt;][&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;orig&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="s"&gt;&amp;#39;pos&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="ow"&gt;and&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;filescore&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;fl&lt;/span&gt;&lt;span class="p"&gt;][&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;output&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="n"&gt;filescore&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;fl&lt;/span&gt;&lt;span class="p"&gt;][&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;orig&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;])):&lt;/span&gt;
                &lt;span class="n"&gt;count_negative_success&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;count_negative_success&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;
&lt;span class="c"&gt;### Print results to screen&lt;/span&gt;
        &lt;span class="k"&gt;print&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;iteration &amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;step&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;:&amp;quot;&lt;/span&gt;
        &lt;span class="k"&gt;print&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;num_pos_test_docs:&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;file_dict&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;pos_test&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
        &lt;span class="k"&gt;print&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;num_pos_training_docs:&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;file_dict&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;pos_train&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
        &lt;span class="k"&gt;print&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;num_pos_correct_docs:&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;count_positive_success&lt;/span&gt;
        &lt;span class="k"&gt;print&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;num_neg_test_docs:&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;file_dict&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;neg_test&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
        &lt;span class="k"&gt;print&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;num_neg_training_docs:&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;file_dict&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;neg_train&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
        &lt;span class="k"&gt;print&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;num_neg_correct_docs:&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;count_negative_success&lt;/span&gt;
        &lt;span class="n"&gt;acc&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;100&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;count_positive_success&lt;/span&gt;&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="n"&gt;count_negative_success&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;file_dict&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;pos_test&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;file_dict&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;neg_test&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]))&lt;/span&gt;
        &lt;span class="k"&gt;print&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;accuracy:&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;acc&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;%&amp;#39;&lt;/span&gt;
        &lt;span class="n"&gt;tot_acc&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tot_acc&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;acc&lt;/span&gt;
    &lt;span class="k"&gt;print&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;ave_accuracy:&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;tot_acc&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="mf"&gt;3.0&lt;/span&gt;

&lt;span class="n"&gt;main&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;&lt;script type= "text/javascript"&gt;
    if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) {
        var mathjaxscript = document.createElement('script');
        mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#';
        mathjaxscript.type = 'text/javascript';
        mathjaxscript.src = 'https:' == document.location.protocol
                ? 'https://c328740.ssl.cf1.rackcdn.com/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML'
                : 'http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML';
        mathjaxscript[(window.opera ? "innerHTML" : "text")] =
            "MathJax.Hub.Config({" +
            "    config: ['MMLorHTML.js']," +
            "    TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'AMS' } }," +
            "    jax: ['input/TeX','input/MathML','output/HTML-CSS']," +
            "    extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js']," +
            "    displayAlign: 'center'," +
            "    displayIndent: '0em'," +
            "    showMathMenu: true," +
            "    tex2jax: { " +
            "        inlineMath: [ ['$','$'] ], " +
            "        displayMath: [ ['$$','$$'] ]," +
            "        processEscapes: true," +
            "        preview: 'TeX'," +
            "    }, " +
            "    'HTML-CSS': { " +
            "        styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'black ! important'} }" +
            "    } " +
            "}); ";
        (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript);
    }
&lt;/script&gt;
</content><category term="python"></category></entry><entry><title>Set Theory #1</title><link href="http://mattobrien.me/set-theory-1.html" rel="alternate"></link><published>2014-04-10T00:00:00-07:00</published><updated>2014-04-10T00:00:00-07:00</updated><author><name>Matt O'Brien</name></author><id>tag:mattobrien.me,2014-04-10:/set-theory-1.html</id><summary type="html">&lt;p&gt;Set theory proof #1&lt;/p&gt;</summary><content type="html">&lt;p&gt;A great little proof that is simple and a nice way to practice your $\LaTeX$.&lt;/p&gt;
&lt;h3&gt;Demonstrate that this is a false claim: $C \subset A$ and $C \subset B \Leftrightarrow C \subset (A \cup B)$.&lt;/h3&gt;
&lt;p&gt;First we examine the righthand implication, that is:&lt;br&gt;
$C \subset A$ and $C \subset B \rightarrow C \subset (A \cup B)$.   &lt;/p&gt;
&lt;p&gt;Let $x \in C $. Then $x \in A $. So, $x \in A$ or $x \in B$. Hence $x \in (A \cup B)$.  &lt;/p&gt;
&lt;p&gt;Second, we examine the lefthand implication, that is
$C \subset A$ and $C \subset B \leftarrow C \subset (A \cup B)$.  &lt;/p&gt;
&lt;p&gt;This second statement is false as demonstrated by the following simple counterexample:  &lt;/p&gt;
&lt;p&gt;Choose:  &lt;/p&gt;
&lt;p&gt;$A = [1, 2]$, $B =[1, 3]$, and $C =[2, 3]$.  &lt;/p&gt;
&lt;p&gt;Then, $A\cup B =[1,2,3]$.&lt;br&gt;
Hence, $C \subset A \cup B$, but, $C \not\subset A$, and $C \not\subset B$.&lt;/p&gt;&lt;script type= "text/javascript"&gt;
    if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) {
        var mathjaxscript = document.createElement('script');
        mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#';
        mathjaxscript.type = 'text/javascript';
        mathjaxscript.src = 'https:' == document.location.protocol
                ? 'https://c328740.ssl.cf1.rackcdn.com/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML'
                : 'http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML';
        mathjaxscript[(window.opera ? "innerHTML" : "text")] =
            "MathJax.Hub.Config({" +
            "    config: ['MMLorHTML.js']," +
            "    TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'AMS' } }," +
            "    jax: ['input/TeX','input/MathML','output/HTML-CSS']," +
            "    extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js']," +
            "    displayAlign: 'center'," +
            "    displayIndent: '0em'," +
            "    showMathMenu: true," +
            "    tex2jax: { " +
            "        inlineMath: [ ['$','$'] ], " +
            "        displayMath: [ ['$$','$$'] ]," +
            "        processEscapes: true," +
            "        preview: 'TeX'," +
            "    }, " +
            "    'HTML-CSS': { " +
            "        styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'black ! important'} }" +
            "    } " +
            "}); ";
        (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript);
    }
&lt;/script&gt;
</content><category term="math"></category></entry><entry><title>using Pi as a pseudorandom number generator</title><link href="http://mattobrien.me/using-pi-as-a-pseudorandom-number-generator.html" rel="alternate"></link><published>2014-03-05T00:00:00-08:00</published><updated>2014-03-05T00:00:00-08:00</updated><author><name>Matt O'Brien</name></author><id>tag:mattobrien.me,2014-03-05:/using-pi-as-a-pseudorandom-number-generator.html</id><summary type="html">&lt;p&gt;Can the digits of Pi be used as a pesudorandom number generator?&lt;/p&gt;</summary><content type="html">&lt;p&gt;The digits of transcendental numbers such as $\pi = 3.14159 \dots$ pass many tests for randomness. So, take the first 1000 digits and use it to simulate 500 tosses of a coin, taking even digits to represent Heads and odd digits to represent Tails. Is this simulation consistent with 500 independent tosses of a fair coin?  &lt;/p&gt;
&lt;p&gt;First, get the digits &lt;a href="https://www.dropbox.com/s/purpzv0tzdsca08/PI.txt"&gt;here:&lt;/a&gt;, download the file and read it into &lt;code&gt;R&lt;/code&gt; and call it PI  &lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;PI &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; read.table&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;\your_path\PI.txt&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;quote&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;\&amp;quot;&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;  
pi_digits &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; &lt;span class="kp"&gt;unlist&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="kp"&gt;strsplit&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="kp"&gt;as.character&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;PI&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="m"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,]),&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;))[&lt;/span&gt;&lt;span class="m"&gt;2&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;&lt;span class="m"&gt;1000&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;  
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;The proportion of even numbers in the first 1000 digits of pi is found as follows:  &lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="nx"&gt;is_even&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; &lt;span class="kd"&gt;function&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nx"&gt;x&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="nx"&gt;x&lt;/span&gt; &lt;span class="o"&gt;%%&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;  
&lt;span class="nx"&gt;is_odd&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; &lt;span class="kd"&gt;function&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nx"&gt;x&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="nx"&gt;x&lt;/span&gt; &lt;span class="o"&gt;%%&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt; &lt;span class="o"&gt;!=&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;  
&lt;span class="nx"&gt;pi_digits&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; &lt;span class="nx"&gt;as&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;numeric&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nx"&gt;pi_digits&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;  
&lt;span class="nx"&gt;indices_for_evens&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; &lt;span class="nx"&gt;pi_digits&lt;/span&gt;&lt;span class="cp"&gt;[&lt;/span&gt;&lt;span class="nx"&gt;is_even&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nx"&gt;pi_digits&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="cp"&gt;]&lt;/span&gt;  
&lt;span class="nx"&gt;indices_for_odds&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; &lt;span class="nx"&gt;pi_digits&lt;/span&gt;&lt;span class="cp"&gt;[&lt;/span&gt;&lt;span class="nx"&gt;is_odd&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nx"&gt;pi_digits&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="cp"&gt;]&lt;/span&gt;  
&lt;span class="nx"&gt;length&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nx"&gt;indices_for_evens&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt; &lt;span class="mi"&gt;1000&lt;/span&gt;  
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Now we will do a t-test to see if there is a significant difference between the probability of getting a heads on a coin flip, and getting an even digit of pi, by seeing if there is any significant differene between the mean for a coin flip (0.50) and the mean of getting an even (0.516). We should expect that these aren't significantly different since they are so close:  &lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;flips &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; &lt;span class="kt"&gt;c&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="kp"&gt;rep&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="m"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="m"&gt;500&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="kp"&gt;rep&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="m"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="m"&gt;500&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;  
evens_for_t_test &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; &lt;span class="kt"&gt;c&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="kp"&gt;rep&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="m"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; each&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="kp"&gt;length&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;indices_for_evens&lt;span class="p"&gt;)),&lt;/span&gt;  &lt;span class="kp"&gt;rep&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="m"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; each&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="kp"&gt;length&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;indices_for_odds&lt;span class="p"&gt;))&lt;/span&gt; &lt;span class="p"&gt;)&lt;/span&gt;  
t.test&lt;span class="p"&gt;(&lt;/span&gt;flips&lt;span class="p"&gt;,&lt;/span&gt; evens_for_t_test&lt;span class="p"&gt;,&lt;/span&gt; alternative&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;two.sided&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;  
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;The p-value is 0.4881.  At a 0.05 significance level, we fail to reject the null hypothesis.Thus, we infer that the digits of pi have passed a test for randomness.  &lt;/p&gt;
&lt;p&gt;So why aren't the digits of $\pi$ used to generate random numbers?  One problem may be the choice of a seed -- in one sense, each time you re-run your simulation based on the digits of $\pi$, you will have to pick up where you left off last time.  This invariably will lead to the requirement of having to calculated $\pi$ to a huge number of decimal places.  In the end, that computational requirement is the major bottleneck and that bottleneck can probably can be arrived at in a number of novel and unfortunate ways. &lt;/p&gt;&lt;script type= "text/javascript"&gt;
    if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) {
        var mathjaxscript = document.createElement('script');
        mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#';
        mathjaxscript.type = 'text/javascript';
        mathjaxscript.src = 'https:' == document.location.protocol
                ? 'https://c328740.ssl.cf1.rackcdn.com/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML'
                : 'http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML';
        mathjaxscript[(window.opera ? "innerHTML" : "text")] =
            "MathJax.Hub.Config({" +
            "    config: ['MMLorHTML.js']," +
            "    TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'AMS' } }," +
            "    jax: ['input/TeX','input/MathML','output/HTML-CSS']," +
            "    extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js']," +
            "    displayAlign: 'center'," +
            "    displayIndent: '0em'," +
            "    showMathMenu: true," +
            "    tex2jax: { " +
            "        inlineMath: [ ['$','$'] ], " +
            "        displayMath: [ ['$$','$$'] ]," +
            "        processEscapes: true," +
            "        preview: 'TeX'," +
            "    }, " +
            "    'HTML-CSS': { " +
            "        styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'black ! important'} }" +
            "    } " +
            "}); ";
        (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript);
    }
&lt;/script&gt;
</content><category term="simulation"></category><category term="R"></category></entry></feed>